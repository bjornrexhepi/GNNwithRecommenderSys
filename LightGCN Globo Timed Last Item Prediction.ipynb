{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "32615a2b-49a3-447f-bfa3-ef8f427eda5e",
   "metadata": {},
   "source": [
    "# LightGCN with Globo Dataset and TimedLastItemPrediction Scenario"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26045094-6f9f-43b3-8473-808b22f2c14d",
   "metadata": {},
   "source": [
    "In this notebook, the implementation of LightGCN in RecPack and the experimental part to generate the results of the algorithm will be presented. \n",
    "The notebook contains:\n",
    "1. The implementation of LightGCN in RecPack.\n",
    "2. The 10% of Globo Dataset from RecPack and the TimedLastItemPrediction Scenario has been used to split the data.\n",
    "3. The TimedLastItemPrediction Scenario to split the data.\n",
    "4. The RecPack Pipeline Builder to run the experiments, including the splitted dataset, the algorithms and metrics to run. Hyperparameter has been performed in the Pipeline.\n",
    "\n",
    "Please make sure you have installed all the latest libraries in your Python environment, in order to have a successful run of the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1cde07fa-6d38-494d-b8e7-b8dcf83a0a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98de5207-1f90-441c-a7d0-4823af3ba234",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_sparse import SparseTensor, matmul"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27d6605f-a085-43cf-9005-bcabf4322e81",
   "metadata": {},
   "source": [
    "## LightGCN implementation in RecPack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c7dc8a2-fbb5-4309-bb75-7274fd8fd280",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch_geometric.nn import MessagePassing\n",
    "from torch_geometric.utils import add_self_loops, degree\n",
    "import time\n",
    "from typing import List, Tuple, Optional\n",
    "from tqdm import tqdm\n",
    "from recpack.algorithms.base import TorchMLAlgorithm\n",
    "from recpack.matrix.interaction_matrix import InteractionMatrix\n",
    "from recpack.matrix import to_csr_matrix\n",
    "from recpack.algorithms.loss_functions import bpr_loss\n",
    "from recpack.algorithms.samplers import PositiveNegativeSampler\n",
    "from scipy.sparse import csr_matrix, lil_matrix\n",
    "import torch.optim as optim\n",
    "import logging\n",
    "\n",
    "# logger = logging.getLogger(__name__)\n",
    "\n",
    "# LightGCN model definition using MessagePassing from PyTorch Geometric\n",
    "class LightGCN(MessagePassing):\n",
    "    def __init__(self, num_users, num_items, embedding_dim=64, K=3, add_self_loops=False):\n",
    "        \"\"\"\n",
    "        Initialize the LightGCN model with user and item embeddings.\n",
    "\n",
    "        Args:\n",
    "            num_users (int): Number of users.\n",
    "            num_items (int): Number of items.\n",
    "            embedding_dim (int): Dimension of the embedding vectors.\n",
    "            K (int): Number of propagation layers.\n",
    "            add_self_loops (bool): Whether to add self-loops to the adjacency matrix.\n",
    "        \"\"\"\n",
    "        super(LightGCN, self).__init__(aggr='add')\n",
    "        self.num_users, self.num_items = num_users, num_items\n",
    "        self.embedding_dim, self.K = embedding_dim, K\n",
    "        self.add_self_loops = add_self_loops\n",
    "\n",
    "        # Initialize user and item embeddings\n",
    "        self.users_emb = nn.Embedding(num_embeddings=self.num_users, embedding_dim=self.embedding_dim)\n",
    "        self.items_emb = nn.Embedding(num_embeddings=self.num_items, embedding_dim=self.embedding_dim)\n",
    "\n",
    "        # Initialize embeddings with normal distribution\n",
    "        nn.init.normal_(self.users_emb.weight, std=0.1)\n",
    "        nn.init.normal_(self.items_emb.weight, std=0.1)\n",
    "\n",
    "    def forward(self, edge_index: SparseTensor):\n",
    "        \"\"\"\n",
    "        Forward pass for the LightGCN model.\n",
    "\n",
    "        Args:\n",
    "            edge_index (SparseTensor): Sparse tensor representing the adjacency matrix.\n",
    "\n",
    "        Returns:\n",
    "            Tuple: Final user and item embeddings after propagation, and the initial embeddings.\n",
    "        \"\"\"\n",
    "        if self.add_self_loops:\n",
    "            edge_index, _ = add_self_loops(edge_index, num_nodes=self.num_users + self.num_items)\n",
    "        \n",
    "        # Normalize the adjacency matrix\n",
    "        edge_index_norm = self.normalize_adj(edge_index)\n",
    "        \n",
    "        # Concatenate user and item embeddings\n",
    "        emb_0 = torch.cat([self.users_emb.weight, self.items_emb.weight])\n",
    "        embs = [emb_0]\n",
    "        emb_k = emb_0\n",
    "\n",
    "        # Perform K propagation steps\n",
    "        for i in range(self.K):\n",
    "            # Preventing CUDA/Library version error\n",
    "            try:\n",
    "                emb_k = self.propagate(edge_index_norm, x=emb_k)\n",
    "            except RuntimeError as e:\n",
    "                break\n",
    "            embs.append(emb_k)\n",
    "\n",
    "        # Stack and average embeddings from each propagation step\n",
    "        embs = torch.stack(embs, dim=1)\n",
    "        emb_final = torch.mean(embs, dim=1)\n",
    "\n",
    "        # Split the final embeddings back into user and item embeddings\n",
    "        users_emb_final, items_emb_final = torch.split(emb_final, [self.num_users, self.num_items])\n",
    "\n",
    "        return users_emb_final, self.users_emb.weight, items_emb_final, self.items_emb.weight\n",
    "\n",
    "    def message(self, x_j: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Message function that aggregates messages from neighboring nodes.\n",
    "\n",
    "        Args:\n",
    "            x_j (torch.Tensor): Features of the neighboring nodes.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Aggregated messages.\n",
    "        \"\"\"\n",
    "        return x_j\n",
    "\n",
    "    def message_and_aggregate(self, adj_t: SparseTensor, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Message and aggregate function using matrix multiplication.\n",
    "\n",
    "        Args:\n",
    "            adj_t (SparseTensor): Transposed adjacency matrix.\n",
    "            x (torch.Tensor): Node features.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Result of multiplying adjacency matrix with node features.\n",
    "        \"\"\"\n",
    "        return matmul(adj_t, x)\n",
    "\n",
    "    def normalize_adj(self, edge_index: SparseTensor) -> SparseTensor:\n",
    "        \"\"\"\n",
    "        Normalize the adjacency matrix.\n",
    "\n",
    "        Args:\n",
    "            edge_index (SparseTensor): Sparse tensor representing the adjacency matrix.\n",
    "\n",
    "        Returns:\n",
    "            SparseTensor: Normalized adjacency matrix.\n",
    "        \"\"\"\n",
    "        row, col, value = edge_index.coo()\n",
    "        row = row.long()  # Ensure indices are long type\n",
    "        col = col.long()  # Ensure indices are long type\n",
    "        deg = degree(row, num_nodes=edge_index.size(0), dtype=value.dtype)\n",
    "        deg_inv_sqrt = deg.pow(-0.5)\n",
    "        deg_inv_sqrt[deg_inv_sqrt == float('inf')] = 0\n",
    "        value = deg_inv_sqrt[row] * value * deg_inv_sqrt[col]\n",
    "        return SparseTensor(row=row, col=col, value=value, sparse_sizes=edge_index.sparse_sizes())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "383f2777-5652-4d39-a111-9f8f71865f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from recpack.algorithms.base import TorchMLAlgorithm\n",
    "from recpack.matrix import Matrix\n",
    "from recpack.matrix.interaction_matrix import InteractionMatrix\n",
    "from recpack.algorithms.loss_functions import bpr_loss, bpr_max_loss\n",
    "from recpack.algorithms.samplers import PositiveNegativeSampler\n",
    "from recpack.algorithms.stopping_criterion import (\n",
    "    EarlyStoppingException,\n",
    "    StoppingCriterion,\n",
    ")\n",
    "from typing import List, Tuple, Optional\n",
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix, lil_matrix, coo_matrix\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import tempfile\n",
    "import time\n",
    "import logging\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Implementation of the LightGCN algorithm using TorchMLAlgorithm as a base class\n",
    "class LightGCNAlgorithm(TorchMLAlgorithm):\n",
    "    def __init__(\n",
    "        self,\n",
    "        batch_size: int = 256,\n",
    "        max_epochs: int = 100,\n",
    "        learning_rate: float = 0.001,\n",
    "        embedding_dim: int = 64,\n",
    "        n_layers: int = 3,\n",
    "        reg_weight: float = 1e-5,\n",
    "        stopping_criterion: str = \"bpr\",\n",
    "        stop_early: bool = True,\n",
    "        max_iter_no_change: int = 5,\n",
    "        min_improvement: float = 0.01,\n",
    "        seed: Optional[int] = None,\n",
    "        save_best_to_file: bool = False,\n",
    "        keep_last: bool = False,\n",
    "        predict_topK: Optional[int] = None,\n",
    "        validation_sample_size: Optional[int] = None,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Initialize the LightGCNAlgorithm with various hyperparameters.\n",
    "\n",
    "        Args:\n",
    "            batch_size (int): Number of samples per batch.\n",
    "            max_epochs (int): Maximum number of training epochs.\n",
    "            learning_rate (float): Learning rate for the optimizer.\n",
    "            embedding_dim (int): Dimension of the embedding vectors.\n",
    "            n_layers (int): Number of LightGCN layers.\n",
    "            reg_weight (float): Regularization weight.\n",
    "            stopping_criterion (str): Criterion to stop training early.\n",
    "            stop_early (bool): Whether to enable early stopping.\n",
    "            max_iter_no_change (int): Maximum iterations with no improvement for early stopping.\n",
    "            min_improvement (float): Minimum improvement required for early stopping.\n",
    "            seed (Optional[int]): Random seed for reproducibility.\n",
    "            save_best_to_file (bool): Whether to save the best model to a file.\n",
    "            keep_last (bool): Whether to keep the last model.\n",
    "            predict_topK (Optional[int]): Number of top-K predictions to consider.\n",
    "            validation_sample_size (Optional[int]): Size of the validation sample.\n",
    "        \"\"\"\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.n_layers = n_layers\n",
    "        self.reg_weight = reg_weight\n",
    "        super().__init__(\n",
    "            batch_size=batch_size,\n",
    "            max_epochs=max_epochs,\n",
    "            learning_rate=learning_rate,\n",
    "            stopping_criterion=stopping_criterion,\n",
    "            stop_early=stop_early,\n",
    "            max_iter_no_change=max_iter_no_change,\n",
    "            min_improvement=min_improvement,\n",
    "            seed=seed,\n",
    "            save_best_to_file=save_best_to_file,\n",
    "            keep_last=keep_last,\n",
    "            predict_topK=predict_topK,\n",
    "            validation_sample_size=validation_sample_size,\n",
    "        )\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    def _init_model(self, train: InteractionMatrix) -> None:\n",
    "        \"\"\"\n",
    "        Initialize the LightGCN model and optimizer.\n",
    "\n",
    "        Args:\n",
    "            train (InteractionMatrix): The training interaction matrix.\n",
    "        \"\"\"\n",
    "        num_users, num_items = train.shape\n",
    "        self.model_ = LightGCN(num_users, num_items, self.embedding_dim, self.n_layers).to(self.device)\n",
    "        self.optimizer = optim.Adam(self.model_.parameters(), lr=self.learning_rate)\n",
    "\n",
    "    def _create_sparse_graph(self, interaction_matrix: csr_matrix, num_users: int, num_items: int) -> SparseTensor:\n",
    "        \"\"\"\n",
    "        Create a sparse graph from the interaction matrix.\n",
    "\n",
    "        Args:\n",
    "            interaction_matrix (csr_matrix): The interaction matrix in CSR format.\n",
    "            num_users (int): Number of users.\n",
    "            num_items (int): Number of items.\n",
    "\n",
    "        Returns:\n",
    "            SparseTensor: A sparse tensor representing the graph.\n",
    "        \"\"\"\n",
    "        coo = interaction_matrix.tocoo()\n",
    "        row = torch.tensor(coo.row, dtype=torch.long)\n",
    "        col = torch.tensor(coo.col, dtype=torch.long)\n",
    "        value = torch.tensor(coo.data, dtype=torch.float32)\n",
    "        print(f\"Graph - Rows: {row.shape}, Cols: {col.shape}, Values: {value.shape}\")  # Debugging information\n",
    "        return SparseTensor(row=row, col=col, value=value, sparse_sizes=(num_users + num_items, num_users + num_items)).to(self.device)\n",
    "\n",
    "    def _train_epoch(self, train: csr_matrix) -> List[float]:\n",
    "        \"\"\"\n",
    "        Train the model for one epoch.\n",
    "\n",
    "        Args:\n",
    "            train (csr_matrix): The training interaction matrix.\n",
    "\n",
    "        Returns:\n",
    "            List[float]: A list of losses for each batch.\n",
    "        \"\"\"\n",
    "        self.model_.train()\n",
    "        graph = self._create_sparse_graph(train, train.shape[0], train.shape[1]).to(self.device)\n",
    "        total_loss = 0\n",
    "        losses = []\n",
    "\n",
    "        sampler = PositiveNegativeSampler(num_negatives=1, batch_size=self.batch_size)\n",
    "\n",
    "        for user_indices, pos_item_indices, neg_item_indices in sampler.sample(train):\n",
    "            user_indices = torch.tensor(user_indices).to(self.device)\n",
    "            pos_item_indices = torch.tensor(pos_item_indices).to(self.device)\n",
    "            neg_item_indices = torch.tensor(neg_item_indices).to(self.device).squeeze()\n",
    "\n",
    "            self.optimizer.zero_grad()\n",
    "            users_emb_final, _, items_emb_final, _ = self.model_(graph)  # Call model only once\n",
    "            pos_scores = users_emb_final[user_indices] @ items_emb_final[pos_item_indices].t()\n",
    "            neg_scores = users_emb_final[user_indices] @ items_emb_final[neg_item_indices].t()\n",
    "\n",
    "            loss = bpr_loss(pos_scores, neg_scores)\n",
    "\n",
    "            if torch.isnan(loss).any() or torch.isinf(loss).any():\n",
    "                continue\n",
    "\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(self.model_.parameters(), max_norm=1.0)  # Gradient clipping\n",
    "            self.optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            losses.append(loss.item())\n",
    "\n",
    "        if len(losses) == 0:\n",
    "            return [float('nan')]\n",
    "\n",
    "        return losses\n",
    "\n",
    "    def _batch_predict(self, X: csr_matrix, users: List[int]) -> csr_matrix:\n",
    "        \"\"\"\n",
    "        Make batch predictions for a list of users.\n",
    "\n",
    "        Args:\n",
    "            X (csr_matrix): The interaction matrix.\n",
    "            users (List[int]): List of user indices to make predictions for.\n",
    "\n",
    "        Returns:\n",
    "            csr_matrix: A sparse matrix with the prediction scores.\n",
    "        \"\"\"\n",
    "        self.model_.eval()\n",
    "        graph = self._create_sparse_graph(X, X.shape[0], X.shape[1]).to(self.device)\n",
    "        user_indices = torch.tensor(users).to(self.device)\n",
    "        item_indices = torch.arange(X.shape[1]).to(self.device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            user_emb_final, _, item_emb_final, _ = self.model_(graph)\n",
    "            scores = user_emb_final[user_indices] @ item_emb_final.t()\n",
    "            scores = scores.cpu().numpy()\n",
    "        \n",
    "        result = lil_matrix((X.shape[0], X.shape[1]))\n",
    "        for i, user in enumerate(users):\n",
    "            result[user] = scores[i]\n",
    "        \n",
    "        return result.tocsr()\n",
    "\n",
    "    def fit(self, X: csr_matrix, validation_data: tuple):\n",
    "        \"\"\"\n",
    "        Fit the model to the training data.\n",
    "\n",
    "        Args:\n",
    "            X (csr_matrix): The training interaction matrix.\n",
    "            validation_data (tuple): Validation data used for early stopping.\n",
    "        \"\"\"\n",
    "        super().fit(X, validation_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e87fd90c-f8ae-4fcc-a455-90fb8f2335c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from recpack.datasets import Netflix, DummyDataset\n",
    "from recpack.pipelines import PipelineBuilder\n",
    "from recpack.scenarios import StrongGeneralization, TimedLastItemPrediction, WeakGeneralization\n",
    "from recpack.pipelines import ALGORITHM_REGISTRY\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "03a047ff-a58e-4ffb-bb09-247622834b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "ALGORITHM_REGISTRY.register(\"LightGCNAlgorithm1\", LightGCNAlgorithm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "979bcd25-d6de-49d8-9aae-eb5ca4dfe798",
   "metadata": {},
   "source": [
    "## RecPack Dataset Importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "288305e2-e570-4286-8468-c902e9d7ca25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from recpack.datasets import Globo\n",
    "dataset = Globo(path=\"\", filename=\"archive.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9c73499f-1c14-4241-a0bd-e3412b4efd34",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.fetch_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "25bb2d15-0f4f-4142-8d5d-e06a6ea3c024",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<recpack.datasets.globo.Globo at 0x7facf4ceb610>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a290f199-0a3d-4c2b-bc30-c82b5254ab34",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dataset._load_dataframe()\n",
    "#df = dataset.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c62813-2e27-4462-acad-ee013b3fd860",
   "metadata": {},
   "source": [
    "## Datasets with Timestamps sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1023a063-a2c2-4344-a1b5-65faadd0c9d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA20AAAIhCAYAAADdH1JpAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/TGe4hAAAACXBIWXMAAA9hAAAPYQGoP6dpAABfnElEQVR4nO3df3yPdf////vLbK/9MC+ztc38GClDmxLvGBWS+TWSOikZK6lO+iFTZ/pl+uG35Yx+n0IoUvgWJfIzZUImq1FnYZMN04wN22zH9w+fHaeXzdhsdrDb9XJ5Xc5ex/E4juN5PF+HnbvveB7Pl80wDEMAAAAAAEuqVtkNAAAAAACcH6ENAAAAACyM0AYAAAAAFkZoAwAAAAALI7QBAAAAgIUR2gAAAADAwghtAAAAAGBhhDYAAAAAsDBCGwAAAABYGKENwGUze/Zs2Ww2bd26tdj1kZGRatiwodOyhg0bKjo6ulTH+eGHHxQbG6ujR4+WraFV0MKFC3XDDTfIw8NDNptNCQkJRWoaNmwom812wdfs2bMVGxsrm812+U/kIn311VeKjY2t7GZUuI4dO6pjx47ltr9ff/1VsbGx2rt3b7HHCg0NLbdjXciyZct01113KSgoSG5ubvL29lbLli01ZswYJScnF2lbWfvBZrPp8ccfL4cWl+zsf1/VqlWTw+FQs2bNNGjQIK1cufKS9v32229r9uzZ5dPQcjBu3DgtXbq0spsBXFGqV3YDAKAkS5YsUc2aNUu1zQ8//KCxY8cqOjpatWrVqpiGXUUOHz6sqKgodevWTW+//bbsdruaNGlSpG7JkiXKyckx3//nP//RzJkztWLFCjkcDnN548aNlZOTo27dul2W9pfFV199pbfeeuuqD25vv/12ue7v119/1dixY9WxY8cif2C5XAoKCvTggw/qo48+Uvfu3TV+/Hg1bNhQJ0+e1JYtWzRr1ix9+OGHSklJqZT2XYr27dtrypQpkqSsrCzt3r1bCxYsUNeuXXXPPffok08+kaura6n3+/bbb8vPz6/UfwCrKOPGjdO9996rPn36VHZTgCsGoQ2ApbVs2bKym1BqeXl5stlsql79yvgR+9tvvykvL08DBw5Uhw4dzlt37mexYsUKSVKrVq3k5+dXpL5evXrl21CUWvPmzSu7CeVu4sSJ+uijjzR+/Hg999xzTuu6deum0aNH67333quk1l2aWrVqqW3btub7O++8U8OHD1dsbKzGjh2rF198URMnTqzEFgKoLAyPBGBp5w6PLCgo0GuvvaaQkBB5eHioVq1aatGihf79739LkmJjY/XMM89Ikho1amQON1q3bp25/aRJk9S0aVPZ7Xb5+/tr0KBB2r9/v9NxDcPQuHHjFBwcLHd3d7Vu3VqrVq0qMsxq3bp1stlsmjt3rmJiYlS3bl3Z7Xb997//1eHDhzVs2DA1b95cNWrUkL+/v+644w599913Tsfau3evbDabJk+erIkTJ6phw4by8PBQx44dzUD13HPPKSgoSA6HQ3fffbcOHTp0Uf33xRdfKDw8XJ6envL29laXLl20adMmc310dLRuvfVWSVL//v1ls9nKZThdccMjGzZsqMjISC1btkwtW7aUh4eHmjVrpmXLlkk6M3y2WbNm8vLy0i233FLsMNqtW7eqd+/eql27ttzd3dWyZUt9+umnTjUnTpzQqFGj1KhRI7m7u6t27dpq3bq1PvnkE/Oc33rrLUlyGtZZOOTvrbfe0u233y5/f395eXkpLCxMkyZNUl5entNxCocDbtq0Se3atZOHh4caNmyoWbNmSZKWL1+um2++WZ6engoLCzND7rl9tH37dvXt21c1a9aUw+HQwIEDdfjwYafaNWvWqGPHjvL19ZWHh4caNGige+65RydOnCjxczj3ei281qZMmaK4uDg1atRINWrUUHh4uOLj40vc1+zZs/WPf/xDktSpUyen4bBn27Jli2677TZ5enrq2muv1YQJE1RQUOBUc+zYMfMzcnNzU926dTVixAhlZ2eX2Ibc3FxNmjRJoaGhRQJboerVq2v48OEl7keS/v77bw0bNkx169aVm5ubrr32Wr3wwgtOd5PP9t5776lJkyay2+1q3ry5FixYUKQmMTFRd911l3x8fOTu7q6bbrpJc+bMuWBbLiQ2NlY33HCDZsyYoVOnTpnLx44dqzZt2qh27dqqWbOmbr75Zs2cOVOGYZg1DRs21C+//KL169ebn1nhXdJTp04pJiZGN910kxwOh2rXrq3w8HD9f//f/1ekDYsWLVKbNm3kcDjMz/ahhx5yqrmYz9Vmsyk7O1tz5swx21OeQ3iBq9WV8WdgAFeV/Px8nT59usjys3/ROJ9JkyYpNjZWL774om6//Xbl5eVp165d5vNrDz/8sP7++29Nnz5dixcvVp06dST9747DP//5T73//vt6/PHHFRkZqb179+qll17SunXr9NNPP5l3jF544QWNHz9ejzzyiPr27auUlBQ9/PDDysvLK3bo4OjRoxUeHq53331X1apVk7+/v/mL95gxYxQYGKisrCwtWbJEHTt21OrVq4v8ovLWW2+pRYsWeuutt3T06FHFxMSoV69eatOmjVxdXfXhhx9q3759GjVqlB5++GF98cUXJfbVxx9/rAceeEARERH65JNPlJOTo0mTJpnHv/XWW/XSSy/plltu0fDhwzVu3Dh16tSp1MNRS2PHjh0aPXq0XnjhBTkcDo0dO1Z9+/bV6NGjtXr1ao0bN042m03/+te/FBkZqT179sjDw0OStHbtWnXr1k1t2rTRu+++K4fDoQULFqh///46ceKEGe5HjhypuXPn6rXXXlPLli2VnZ2txMREHTlyRJL00ksvKTs7W5999plTgC28Vv744w8NGDDA/MVzx44dev3117Vr1y59+OGHTueTlpamBx98UM8++6zq1aun6dOn66GHHlJKSoo+++wzPf/883I4HHrllVfUp08f/fnnnwoKCnLax913361+/frpscce0y+//KKXXnpJv/76qzZv3ixXV1ft3btXPXv21G233aYPP/xQtWrV0l9//aUVK1YoNzdXnp6epf4c3nrrLTVt2lTTpk0z+6RHjx7as2eP01DXs/Xs2VPjxo3T888/r7feeks333yzpDPDYc/ujwceeEAxMTEaM2aMlixZotGjRysoKEiDBg2SdCZUd+jQQfv379fzzz+vFi1a6JdfftHLL7+snTt36ttvvz3v85Bbt27V0aNH9c9//rPU53y2U6dOqVOnTvrjjz80duxYtWjRQt99953Gjx+vhIQELV++3Kn+iy++0Nq1a/XKK6/Iy8tLb7/9tu6//35Vr15d9957ryRp9+7dateunfz9/fXmm2/K19dX8+bNU3R0tA4ePKhnn332ktrcq1cvTZgwQVu3bjX/0LJ37149+uijatCggSQpPj5eTzzxhP766y+9/PLLks4Ma7733nvlcDjM4bJ2u12SlJOTo7///lujRo1S3bp1lZubq2+//VZ9+/bVrFmzzM9s06ZN6t+/v/r376/Y2Fi5u7tr3759WrNmjdm+i/1cN23apDvuuEOdOnXSSy+9JEkV+jMHuGoYAHCZzJo1y5BU4is4ONhpm+DgYGPw4MHm+8jISOOmm24q8TiTJ082JBl79uxxWp6UlGRIMoYNG+a0fPPmzYYk4/nnnzcMwzD+/vtvw263G/3793eq27RpkyHJ6NChg7ls7dq1hiTj9ttvv+D5nz592sjLyzM6d+5s3H333ebyPXv2GJKMG2+80cjPzzeXT5s2zZBk9O7d22k/I0aMMCQZmZmZ5z1Wfn6+ERQUZISFhTnt8/jx44a/v7/Rrl27IuewaNGiC57D2caMGWNIMg4fPnzedWcLDg42PDw8jP3795vLEhISDElGnTp1jOzsbHP50qVLDUnGF198YS5r2rSp0bJlSyMvL89pv5GRkUadOnXM8wwNDTX69OlTYtuHDx9epH3Fyc/PN/Ly8oyPPvrIcHFxMf7++29zXYcOHQxJxtatW81lR44cMVxcXAwPDw/jr7/+KnKeb775prmssI+efvppp2POnz/fkGTMmzfPMAzD+OyzzwxJRkJCwgXbe64OHTo4Xa+F11pYWJhx+vRpc/mPP/5oSDI++eSTEve3aNEiQ5Kxdu3aYo8lydi8ebPT8ubNmxtdu3Y1348fP96oVq2asWXLFqe6wvP86quvznv8BQsWGJKMd999t8i6vLw8p9e5bTu7H959911DkvHpp5861U2cONGQZKxcudJcJsnw8PAw0tLSzGWnT582mjZtalx33XXmsvvuu8+w2+1GcnKy0z67d+9ueHp6GkePHj3veRnGmX8fPXv2PO/6d955x5BkLFy4sNj1hdfqK6+8Yvj6+hoFBQXmuhtuuMHp/M+n8GfUkCFDjJYtW5rLp0yZYkgq8RxK87l6eXk5/VwHcGEMjwRw2X300UfasmVLkVfhX49Lcsstt2jHjh0aNmyYvvnmGx07duyij7t27VpJKvIw/i233KJmzZpp9erVks78tTonJ0f9+vVzqmvbtu15J1+45557il3+7rvv6uabb5a7u7uqV68uV1dXrV69WklJSUVqe/TooWrV/vdjuVmzZpLO3OE4W+Hyc2fIO9vu3bt14MABRUVFOe2zRo0auueeexQfH3/BoXUV4aabblLdunXN94Xn0rFjR6c7RoXL9+3bJ0n673//q127dumBBx6QJJ0+fdp89ejRQ6mpqdq9e7ekM5/n119/reeee07r1q3TyZMnS9XG7du3q3fv3vL19ZWLi4tcXV01aNAg5efn67fffnOqrVOnjlq1amW+r127tvz9/XXTTTc53VE793zOVnhOhfr166fq1aub1+tNN90kNzc3PfLII5ozZ47+/PPPUp1PcXr27CkXFxfzfYsWLc7bvtIIDAzULbfc4rSsRYsWTvtdtmyZQkNDddNNNzl9jl27dnUaylwaR48elaurq9PrfLPUSmeGm3p5eZl3yQoV/mwo/FlQqHPnzgoICDDfu7i4qH///vrvf/9rDq1es2aNOnfurPr16xfZ54kTJ5zu6paFUcxIhDVr1ujOO++Uw+Ewr9WXX35ZR44cuegh1IsWLVL79u1Vo0YN82fUzJkznX5G/d///Z+kM9fmp59+qr/++qvIfiricwXwP4Q2AJdds2bN1Lp16yKv8w3LOtvo0aM1ZcoUxcfHq3v37vL19VXnzp1L/AWtUOHwuMJhcGcLCgoy1xf+79m/pBUqbtn59hkXF6d//vOfatOmjT7//HPFx8dry5Yt6tatW7FBonbt2k7v3dzcSlx+9rMt57rQuRYUFCgjI+O821eUsp7jwYMHJUmjRo0q8sv5sGHDJEnp6emSpDfffFP/+te/tHTpUnXq1Em1a9dWnz599Pvvv1+wfcnJybrtttv0119/6d///re+++47bdmyxXwG7tzP7dx2F7a9NJ9ZYGCg0/vq1avL19fX/AwbN26sb7/9Vv7+/ho+fLgaN26sxo0bm89xloWvr6/T+8LhcqUNuBfab+G+z97vwYMH9fPPPxf5HL29vWUYhvk5FqdwGOC54dLb29v848+YMWMu2M4jR44oMDCwyDBMf39/Va9e3ez7Qud+RmcvO/vnxvn+vZ1dV1aF51y4vx9//FERERGSpA8++EDff/+9tmzZohdeeEHSxX2WixcvVr9+/VS3bl3NmzdPmzZt0pYtW/TQQw85Xau33367li5dqtOnT2vQoEGqV6+eQkNDzedEpUv7XAFcGM+0AbiiVK9eXSNHjtTIkSN19OhRffvtt3r++efVtWtXpaSklPh8T+EvlKmpqUVmNjxw4ID5PFthXWFQOFtaWlqxd9uKewZn3rx56tixo9555x2n5cePHy/5JMvB2ed6rgMHDqhatWry8fGp8HaUl8LPZvTo0erbt2+xNSEhIZIkLy8vjR07VmPHjtXBgwfNu269evXSrl27SjzO0qVLlZ2drcWLFys4ONhcXtz31pWXtLQ0p7uPp0+f1pEjR5wC0G233abbbrtN+fn52rp1q6ZPn64RI0YoICBA9913X4W1rSL4+fnJw8OjyPOBZ68/n1atWsnHx0dffvmlxo0bZy53cXFR69atJZ2ZDORCfH19tXnzZhmG4fRv99ChQzp9+nSRNqSlpRXZR+Gyws/J19f3vP/eLnReF2IYhr788kt5eXmZ57lgwQK5urpq2bJlcnd3N2tL8/1n8+bNU6NGjbRw4UKnfihuMpa77rpLd911l3JychQfH6/x48drwIABatiwocLDwy/pcwVwYdxpA3DFqlWrlu69914NHz5cf//9tzn73/nuGtxxxx2SzvyicrYtW7YoKSlJnTt3liS1adNGdrtdCxcudKqLj48v1fAxm81mtqXQzz//fMnDpC5GSEiI6tatq48//thpWFV2drY+//xzc0bJK0VISIiuv/567dixo9i7tK1bt5a3t3eR7QICAhQdHa37779fu3fvNoeEnu8aKfzF9ezPzTAMffDBBxV1apo/f77T+08//VSnT58udkY9FxcXtWnTxrzz99NPP1VYu4pTHnfkIiMj9ccff8jX17fYz7Gk739zc3PTM888o8TExEua+r5z587KysoqEnA++ugjc/3ZVq9e7fRHnPz8fC1cuFCNGzc2/wDUuXNnrVmzxgxpZ+/T09PTaSr/0ho7dqx+/fVXPfXUU2ZAK/xakbOHuZ48eVJz584tsv25dzsL2Ww2ubm5OQW2tLS0YmePPHtfHTp0MPt/+/btkkr3uZ6vPQDOjzttAK4ovXr1UmhoqFq3bq1rrrlG+/bt07Rp0xQcHKzrr79ekhQWFiZJ+ve//63BgwfL1dVVISEhCgkJ0SOPPKLp06erWrVq6t69uzl7ZP369fX0009LOjPkbeTIkRo/frx8fHx09913a//+/Ro7dqzq1Knj9IxYSSIjI/Xqq69qzJgx6tChg3bv3q1XXnlFjRo1Knb2zPJUrVo1TZo0SQ888IAiIyP16KOPKicnR5MnT9bRo0c1YcKECj1+RXjvvffUvXt3de3aVdHR0apbt67+/vtvJSUl6aefftKiRYsknQndkZGRatGihXx8fJSUlKS5c+c6BdXCa2TixInq3r27XFxc1KJFC3Xp0kVubm66//779eyzz+rUqVN65513KnQo6eLFi1W9enV16dLFnD3yxhtvNJ+pfPfdd7VmzRr17NlTDRo00KlTp8y7GXfeeWeFtas4oaGhkqT3339f3t7ecnd3V6NGjYodFnk+I0aM0Oeff67bb79dTz/9tFq0aKGCggIlJydr5cqViomJUZs2bc67/b/+9S/t2rVLzz33nDZs2KD+/furYcOGysnJ0Z9//qn//Oc/cnFxKfGPEoMGDdJbb72lwYMHa+/evQoLC9PGjRs1btw49ejRo0i/+vn56Y477tBLL71kzh65a9cup2n/x4wZo2XLlqlTp056+eWXVbt2bc2fP1/Lly/XpEmTLmr499GjR82vXsjOzja/XPu7775Tv379NHbsWLO2Z8+eiouL04ABA/TII4/oyJEjmjJlSpE/FElnrvcFCxZo4cKFuvbaa+Xu7q6wsDBFRkZq8eLFGjZsmO69916lpKTo1VdfVZ06dZyGE7/88svav3+/OnfurHr16uno0aP697//LVdXV/O7HUvzuYaFhWndunX68ssvVadOHXl7e5t3ygGcRyVOggKgiimcPfLc2cUK9ezZ84KzR06dOtVo166d4efnZ7i5uRkNGjQwhgwZYuzdu9dpu9GjRxtBQUFGtWrVnGa7y8/PNyZOnGg0adLEcHV1Nfz8/IyBAwcaKSkpTtsXFBQYr732mlGvXj3Dzc3NaNGihbFs2TLjxhtvdJr5saSZF3NycoxRo0YZdevWNdzd3Y2bb77ZWLp0qTF48GCn8yyc0W/y5MlO259v3xfqx7MtXbrUaNOmjeHu7m54eXkZnTt3Nr7//vuLOs6FlGX2yOJmx5NkDB8+3GnZ+fpkx44dRr9+/Qx/f3/D1dXVCAwMNO644w6n2QSfe+45o3Xr1oaPj49ht9uNa6+91nj66aeN9PR0syYnJ8d4+OGHjWuuucaw2WxOs41++eWXxo033mi4u7sbdevWNZ555hnj66+/LjJrYocOHYwbbrihyPlc7HkW9tG2bduMXr16GTVq1DC8vb2N+++/3zh48KBZt2nTJuPuu+82goODDbvdbvj6+hodOnRwmlnzfM43e+S5/VrYvjFjxlxwn9OmTTMaNWpkuLi4GJKMWbNmmccqrj/Ovd4NwzCysrKMF1980QgJCTHc3NwMh8NhhIWFGU8//bTTLI0l+eKLL4xevXoZAQEBRvXq1Q1vb2/jpptuMmJiYoxdu3Y51Z7bD4ZxZqbPxx57zKhTp45RvXp1Izg42Bg9erRx6tQpp7rCz+3tt982GjdubLi6uhpNmzY15s+fX6RNO3fuNHr16mU4HA7Dzc3NuPHGG83+uZDg4GBzFl2bzWbUqFHDCAkJMaKiooxvvvmm2G0+/PBDIyQkxLzOx48fb8ycObPI7Ll79+41IiIiDG9v7yKz9E6YMMFo2LChYbfbjWbNmhkffPBBkX+/y5YtM7p3727UrVvXcHNzM/z9/Y0ePXoY3333nVN7LvZzTUhIMNq3b294enoWmZEXQPFshnERX4wEANCePXvUtGlTjRkzRs8//3xlNwdXuNjYWI0dO1aHDx/meR8AQIkYHgkAxdixY4c++eQTtWvXTjVr1tTu3bs1adIk1axZU0OGDKns5gEAgCqE0AYAxfDy8tLWrVs1c+ZMHT16VA6HQx07dtTrr79+3mn/AQAAKgLDIwEAAADAwpjyHwAAAAAsjNAGAAAAABZGaAMAAAAAC2MiksusoKBABw4ckLe3t2w2W2U3BwAAAEAlMQxDx48fV1BQkKpVO//9NELbZXbgwAHVr1+/spsBAAAAwCJSUlJUr169864ntF1m3t7eks58MDVr1qzk1gAAAACoLMeOHVP9+vXNjHA+hLbLrHBIZM2aNQltAAAAAC742BQTkQAAAACAhRHaAAAAAMDCCG0AAAAAYGGENgAAAACwMEIbAAAAAFgYoQ0AAAAALIzQBgAAAAAWRmgDAAAAAAsjtAEAAACAhRHaAAAAAMDCCG0AAAAAYGGENgAAAACwMEIbAAAAAFgYoQ0AAAAALKxSQ9v48eP1f//3f/L29pa/v7/69Omj3bt3O9VER0fLZrM5vdq2betUk5OToyeeeEJ+fn7y8vJS7969tX//fqeajIwMRUVFyeFwyOFwKCoqSkePHnWqSU5OVq9eveTl5SU/Pz89+eSTys3NdarZuXOnOnToIA8PD9WtW1evvPKKDMMov04BAAAAgLNUamhbv369hg8frvj4eK1atUqnT59WRESEsrOzneq6deum1NRU8/XVV185rR8xYoSWLFmiBQsWaOPGjcrKylJkZKTy8/PNmgEDBighIUErVqzQihUrlJCQoKioKHN9fn6+evbsqezsbG3cuFELFizQ559/rpiYGLPm2LFj6tKli4KCgrRlyxZNnz5dU6ZMUVxcXAX1EAAAAICqzmZY6DbR4cOH5e/vr/Xr1+v222+XdOZO29GjR7V06dJit8nMzNQ111yjuXPnqn///pKkAwcOqH79+vrqq6/UtWtXJSUlqXnz5oqPj1ebNm0kSfHx8QoPD9euXbsUEhKir7/+WpGRkUpJSVFQUJAkacGCBYqOjtahQ4dUs2ZNvfPOOxo9erQOHjwou90uSZowYYKmT5+u/fv3y2azXfAcjx07JofDoczMTNWsWfNSuwwAAADAFepis4GlnmnLzMyUJNWuXdtp+bp16+Tv768mTZpo6NChOnTokLlu27ZtysvLU0REhLksKChIoaGh+uGHHyRJmzZtksPhMAObJLVt21YOh8OpJjQ01AxsktS1a1fl5ORo27ZtZk2HDh3MwFZYc+DAAe3du7fYc8rJydGxY8ecXgAAAABwsapXdgMKGYahkSNH6tZbb1VoaKi5vHv37vrHP/6h4OBg7dmzRy+99JLuuOMObdu2TXa7XWlpaXJzc5OPj4/T/gICApSWliZJSktLk7+/f5Fj+vv7O9UEBAQ4rffx8ZGbm5tTTcOGDYscp3Bdo0aNihxj/PjxGjt2bCl74+qVnJys9PT0Um/n5+enBg0aVECLAAAAAGuzTGh7/PHH9fPPP2vjxo1OywuHPEpSaGioWrdureDgYC1fvlx9+/Y97/4Mw3Aarljc0MXyqCkcXXq+oZGjR4/WyJEjzffHjh1T/fr1z9vuq1lycrJCmjbTqZMnSr2tu4endu9KIrgBAACgyrFEaHviiSf0xRdfaMOGDapXr16JtXXq1FFwcLB+//13SVJgYKByc3OVkZHhdLft0KFDateunVlz8ODBIvs6fPiweacsMDBQmzdvdlqfkZGhvLw8p5rCu25nH0dSkbt0hex2u9NwyqosPT1dp06ekG9kjFx9Lz645h1J0ZFlU5Wenk5oAwAAQJVTqc+0GYahxx9/XIsXL9aaNWuKHV54riNHjiglJUV16tSRJLVq1Uqurq5atWqVWZOamqrExEQztIWHhyszM1M//vijWbN582ZlZmY61SQmJio1NdWsWblypex2u1q1amXWbNiwwelrAFauXKmgoKAiwyZxfq6+9WUPvO6iX6UJeAAAAMDVplJD2/DhwzVv3jx9/PHH8vb2VlpamtLS0nTy5ElJUlZWlkaNGqVNmzZp7969WrdunXr16iU/Pz/dfffdkiSHw6EhQ4YoJiZGq1ev1vbt2zVw4ECFhYXpzjvvlCQ1a9ZM3bp109ChQxUfH6/4+HgNHTpUkZGRCgkJkSRFRESoefPmioqK0vbt27V69WqNGjVKQ4cONWdyGTBggOx2u6Kjo5WYmKglS5Zo3LhxGjly5EXNHAkAAAAApVWpoe2dd95RZmamOnbsqDp16pivhQsXSpJcXFy0c+dO3XXXXWrSpIkGDx6sJk2aaNOmTfL29jb388Ybb6hPnz7q16+f2rdvL09PT3355ZdycXExa+bPn6+wsDBFREQoIiJCLVq00Ny5c831Li4uWr58udzd3dW+fXv169dPffr00ZQpU8wah8OhVatWaf/+/WrdurWGDRumkSNHOj2zBgAAAADlyVLf01YVVOXvafvpp5/UqlUrBQ6eJnvgdRe9XU7af5U2Z4S2bdumm2++uQJbCAAAAFw+V+T3tAEAAAAAnBHaAAAAAMDCCG0AAAAAYGGENgAAAACwMEIbAAAAAFhY9cpuAK5MycnJSk9PL9U2SUlJFdQaAAAA4OpFaEOpJScnK6RpM506eaKymwIAAABc9QhtKLX09HSdOnlCvpExcvWtf9HbnfxzqzK/m1eBLQMAAACuPoQ2lJmrb/1SfUl23pGUCmwNAAAAcHViIhIAAAAAsDBCGwAAAABYGMMjAZRKWWYOlSQ/Pz81aNCgAloEAABwdSO0AbholzJzqLuHp3bvSiK4AQAAlBKhDcBFK+vMoXlHUnRk2VSlp6cT2gAAAEqJ0Aag1Eo7cygAAADKjolIAAAAAMDCCG0AAAAAYGGENgAAAACwMEIbAAAAAFgYoQ0AAAAALIzQBgAAAAAWRmgDAAAAAAsjtAEAAACAhRHaAAAAAMDCCG0AAAAAYGGENgAAAACwMEIbAAAAAFgYoQ0AAAAALIzQBgAAAAAWRmgDAAAAAAsjtAEAAACAhRHaAAAAAMDCCG0AAAAAYGGENgAAAACwMEIbAAAAAFgYoQ0AAAAALIzQBgAAAAAWRmgDAAAAAAsjtAEAAACAhRHaAAAAAMDCCG0AAAAAYGGENgAAAACwMEIbAAAAAFgYoQ0AAAAALIzQBgAAAAAWRmgDAAAAAAsjtAEAAACAhRHaAAAAAMDCCG0AAAAAYGGENgAAAACwMEIbAAAAAFgYoQ0AAAAALIzQBgAAAAAWRmgDAAAAAAsjtAEAAACAhRHaAAAAAMDCCG0AAAAAYGGENgAAAACwMEIbAAAAAFgYoQ0AAAAALIzQBgAAAAAWRmgDAAAAAAurXtkNAFA5kpOTlZ6eXqptkpKSKqg1AAAAOB9CG1AFJScnK6RpM506eaKymwIAAIALILQBVVB6erpOnTwh38gYufrWv+jtTv65VZnfzavAlgEAAOBchDagCnP1rS974HUXXZ93JKUCWwMAAIDiMBEJAAAAAFgYoQ0AAAAALIzQBgAAAAAWRmgDAAAAAAtjIhKgHJXlu88kyc/PTw0aNKiAFgEAAOBKR2gDysmlfPeZu4endu9KIrgBAACgCEIbUE7K+t1neUdSdGTZVKWnpxPaAAAAUAShDShnpf3uMwAAAKAkTEQCAAAAABZGaAMAAAAACyO0AQAAAICFEdoAAAAAwMIqNbSNHz9e//d//ydvb2/5+/urT58+2r17t1ONYRiKjY1VUFCQPDw81LFjR/3yyy9ONTk5OXriiSfk5+cnLy8v9e7dW/v373eqycjIUFRUlBwOhxwOh6KionT06FGnmuTkZPXq1UteXl7y8/PTk08+qdzcXKeanTt3qkOHDvLw8FDdunX1yiuvyDCM8usUAAAAADhLpYa29evXa/jw4YqPj9eqVat0+vRpRUREKDs726yZNGmS4uLiNGPGDG3ZskWBgYHq0qWLjh8/btaMGDFCS5Ys0YIFC7Rx40ZlZWUpMjJS+fn5Zs2AAQOUkJCgFStWaMWKFUpISFBUVJS5Pj8/Xz179lR2drY2btyoBQsW6PPPP1dMTIxZc+zYMXXp0kVBQUHasmWLpk+frilTpiguLq6CewoAAABAVVWpU/6vWLHC6f2sWbPk7++vbdu26fbbb5dhGJo2bZpeeOEF9e3bV5I0Z84cBQQE6OOPP9ajjz6qzMxMzZw5U3PnztWdd94pSZo3b57q16+vb7/9Vl27dlVSUpJWrFih+Ph4tWnTRpL0wQcfKDw8XLt371ZISIhWrlypX3/9VSkpKQoKCpIkTZ06VdHR0Xr99ddVs2ZNzZ8/X6dOndLs2bNlt9sVGhqq3377TXFxcRo5cqRsNluRc8zJyVFOTo75/tixYxXSlwAAAACuTpZ6pi0zM1OSVLt2bUnSnj17lJaWpoiICLPGbrerQ4cO+uGHHyRJ27ZtU15enlNNUFCQQkNDzZpNmzbJ4XCYgU2S2rZtK4fD4VQTGhpqBjZJ6tq1q3JycrRt2zazpkOHDrLb7U41Bw4c0N69e4s9p/Hjx5tDMh0Oh+rXv/gvXQYAAAAAy4Q2wzA0cuRI3XrrrQoNDZUkpaWlSZICAgKcagMCAsx1aWlpcnNzk4+PT4k1/v7+RY7p7+/vVHPucXx8fOTm5lZiTeH7wppzjR49WpmZmeYrJSXlAj0BAAAAAP9TqcMjz/b444/r559/1saNG4usO3fYoWEYxQ5FLKmmuPryqCmchOR87bHb7U535gAAAACgNCxxp+2JJ57QF198obVr16pevXrm8sDAQElF72IdOnTIvMMVGBio3NxcZWRklFhz8ODBIsc9fPiwU825x8nIyFBeXl6JNYcOHZJU9G4gAAAAAJSHSg1thmHo8ccf1+LFi7VmzRo1atTIaX2jRo0UGBioVatWmctyc3O1fv16tWvXTpLUqlUrubq6OtWkpqYqMTHRrAkPD1dmZqZ+/PFHs2bz5s3KzMx0qklMTFRqaqpZs3LlStntdrVq1cqs2bBhg9PXAKxcuVJBQUFq2LBhOfUKAAAAAPxPpYa24cOHa968efr444/l7e2ttLQ0paWl6eTJk5LODDkcMWKExo0bpyVLligxMVHR0dHy9PTUgAEDJEkOh0NDhgxRTEyMVq9ere3bt2vgwIEKCwszZ5Ns1qyZunXrpqFDhyo+Pl7x8fEaOnSoIiMjFRISIkmKiIhQ8+bNFRUVpe3bt2v16tUaNWqUhg4dqpo1a0o687UBdrtd0dHRSkxM1JIlSzRu3LjzzhwJAAAAAJeqUp9pe+eddyRJHTt2dFo+a9YsRUdHS5KeffZZnTx5UsOGDVNGRobatGmjlStXytvb26x/4403VL16dfXr108nT55U586dNXv2bLm4uJg18+fP15NPPmnOMtm7d2/NmDHDXO/i4qLly5dr2LBhat++vTw8PDRgwABNmTLFrHE4HFq1apWGDx+u1q1by8fHRyNHjtTIkSPLu2sAAAAAQFIlh7bCSTxKYrPZFBsbq9jY2PPWuLu7a/r06Zo+ffp5a2rXrq158+aVeKwGDRpo2bJlJdaEhYVpw4YNJdYAAAAAQHmxxEQkAAAAAIDiEdoAAAAAwMIIbQAAAABgYYQ2AAAAALAwQhsAAAAAWBihDQAAAAAsjNAGAAAAABZGaAMAAAAACyO0AQAAAICFEdoAAAAAwMKqV3YDACtKTk5Wenp6qbZJSkqqoNYAAACgKiO0AedITk5WSNNmOnXyRGU3BQAAACC0AedKT0/XqZMn5BsZI1ff+he93ck/tyrzu3kV2LIrX1nuRvr5+alBgwYV0BoAAIArA6ENOA9X3/qyB1530fV5R1IqsDVXtvysDMlm08CBA0u9rbuHp3bvSiK4AQCAKovQBqDCFeRkSYZR6ruXeUdSdGTZVKWnpxPaAABAlUVoA3DZlPbuJQAAAJjyHwAAAAAsjdAGAAAAABZGaAMAAAAACyO0AQAAAICFEdoAAAAAwMIIbQAAAABgYYQ2AAAAALAwQhsAAAAAWBihDQAAAAAsjNAGAAAAABZWvbIbAAAXkpSUVOpt/Pz81KBBgwpoDQAAwOVFaANgWflZGZLNpoEDB5Z6W3cPT+3elURwAwAAVzxCGwDLKsjJkgxDvpExcvWtf9Hb5R1J0ZFlU5Wenk5oAwAAVzxCGwDLc/WtL3vgdZXdDAAAgErBRCQAAAAAYGGENgAAAACwMEIbAAAAAFgYoQ0AAAAALIzQBgAAAAAWRmgDAAAAAAsjtAEAAACAhRHaAAAAAMDCCG0AAAAAYGGENgAAAACwsOqV3QAAsJLk5GSlp6eXejs/Pz81aNCgAloEAACqOkIbAPw/ycnJCmnaTKdOnij1tu4entq9K4ngBgAAyh2hDQD+n/T0dJ06eUK+kTFy9a1/0dvlHUnRkWVTlZ6eTmgDAADljtAGAOdw9a0ve+B1ld0MAAAASUxEAgAAAACWxp02ALgCMWEKAABVB6ENAK4wTJgCAEDVQmgDgCsME6YAAFC1ENpwxUhKSir1NgwFw9WMCVMAAKgaCG2wvPysDMlm08CBA0u9LUPBAAAAcKUjtMHyCnKyJMNgKBgAAACqJEIbrhgMBQMAAEBVxPe0AQAAAICFEdoAAAAAwMIIbQAAAABgYYQ2AAAAALAwQhsAAAAAWBihDQAAAAAsjNAGAAAAABZGaAMAAAAACyO0AQAAAICFEdoAAAAAwMIIbQAAAABgYYQ2AAAAALAwQhsAAAAAWBihDQAAAAAsjNAGAAAAABZGaAMAAAAACyO0AQAAAICFEdoAAAAAwMIIbQAAAABgYYQ2AAAAALAwQhsAAAAAWBihDQAAAAAsrHplNwCoaElJSRVaDwAAAFQkQhuuWvlZGZLNpoEDB1Z2UwAAAIAyI7ThqlWQkyUZhnwjY+TqW/+itzv551ZlfjevAlsGAAAAXLxKfaZtw4YN6tWrl4KCgmSz2bR06VKn9dHR0bLZbE6vtm3bOtXk5OToiSeekJ+fn7y8vNS7d2/t37/fqSYjI0NRUVFyOBxyOByKiorS0aNHnWqSk5PVq1cveXl5yc/PT08++aRyc3Odanbu3KkOHTrIw8NDdevW1SuvvCLDMMqtP1AxXH3ryx543UW/qjsCKrvJAAAAgKlSQ1t2drZuvPFGzZgx47w13bp1U2pqqvn66quvnNaPGDFCS5Ys0YIFC7Rx40ZlZWUpMjJS+fn5Zs2AAQOUkJCgFStWaMWKFUpISFBUVJS5Pj8/Xz179lR2drY2btyoBQsW6PPPP1dMTIxZc+zYMXXp0kVBQUHasmWLpk+frilTpiguLq4cewQAAAAAnFXq8Mju3bure/fuJdbY7XYFBgYWuy4zM1MzZ87U3Llzdeedd0qS5s2bp/r16+vbb79V165dlZSUpBUrVig+Pl5t2rSRJH3wwQcKDw/X7t27FRISopUrV+rXX39VSkqKgoKCJElTp05VdHS0Xn/9ddWsWVPz58/XqVOnNHv2bNntdoWGhuq3335TXFycRo4cKZvNVmwbc3JylJOTY74/duxYqfsJAAAAQNVl+Sn/161bJ39/fzVp0kRDhw7VoUOHzHXbtm1TXl6eIiIizGVBQUEKDQ3VDz/8IEnatGmTHA6HGdgkqW3btnI4HE41oaGhZmCTpK5duyonJ0fbtm0zazp06CC73e5Uc+DAAe3du/e87R8/frw5LNPhcKh+/Yt/tgoAAAAAyhTa9uzZU97tKFb37t01f/58rVmzRlOnTtWWLVt0xx13mHeu0tLS5ObmJh8fH6ftAgIClJaWZtb4+/sX2be/v79TTUCA83NMPj4+cnNzK7Gm8H1hTXFGjx6tzMxM85WSklKaLgAAAABQxZVpeOR1112n22+/XUOGDNG9994rd3f38m6XJKl///7mf4eGhqp169YKDg7W8uXL1bdv3/NuZxiG03DF4oYulkdN4SQk5xsaKZ0Z3nn23TkAAAAAKI0y3WnbsWOHWrZsqZiYGAUGBurRRx/Vjz/+WN5tK6JOnToKDg7W77//LkkKDAxUbm6uMjIynOoOHTpk3gULDAzUwYMHi+zr8OHDTjXn3i3LyMhQXl5eiTWFQzXPvQMHAAAAAOWlTKEtNDRUcXFx+uuvvzRr1iylpaXp1ltv1Q033KC4uDgdPny4vNspSTpy5IhSUlJUp04dSVKrVq3k6uqqVatWmTWpqalKTExUu3btJEnh4eHKzMx0CpWbN29WZmamU01iYqJSU1PNmpUrV8put6tVq1ZmzYYNG5y+BmDlypUKCgpSw4YNK+R8AQAAAOCSJiKpXr267r77bn366aeaOHGi/vjjD40aNUr16tXToEGDnEJQcbKyspSQkKCEhARJZ56VS0hIUHJysrKysjRq1Cht2rRJe/fu1bp169SrVy/5+fnp7rvvliQ5HA4NGTJEMTExWr16tbZv366BAwcqLCzMnE2yWbNm6tatm4YOHar4+HjFx8dr6NChioyMVEhIiCQpIiJCzZs3V1RUlLZv367Vq1dr1KhRGjp0qGrWrCnpzNcG2O12RUdHKzExUUuWLNG4ceNKnDkSAAAAAC7VJYW2rVu3atiwYapTp47i4uI0atQo/fHHH1qzZo3++usv3XXXXRfcvmXLlmrZsqUkaeTIkWrZsqVefvllubi4aOfOnbrrrrvUpEkTDR48WE2aNNGmTZvk7e1t7uONN95Qnz591K9fP7Vv316enp768ssv5eLiYtbMnz9fYWFhioiIUEREhFq0aKG5c+ea611cXLR8+XK5u7urffv26tevn/r06aMpU6aYNQ6HQ6tWrdL+/fvVunVrDRs2TCNHjtTIkSMvpQsBAAAAoERlmogkLi5Os2bN0u7du9WjRw999NFH6tGjh6pVO5MBGzVqpPfee09NmzYtcT8dO3Y0J/MozjfffHPBtri7u2v69OmaPn36eWtq166tefPmlbifBg0aaNmyZSXWhIWFacOGDRdsEwAAAACUlzKFtnfeeUcPPfSQHnzwwfN+8XWDBg00c+bMS2ocAAAAAFR1ZQpthbM3lsTNzU2DBw8uy+4BAAAAAP9PmZ5pmzVrlhYtWlRk+aJFizRnzpxLbhQAAAAA4IwyhbYJEybIz8+vyHJ/f3+NGzfukhsFAAAAADijTKFt3759atSoUZHlwcHBSk5OvuRGAQAAAADOKFNo8/f3188//1xk+Y4dO+Tr63vJjQIAAAAAnFGm0HbffffpySef1Nq1a5Wfn6/8/HytWbNGTz31lO67777ybiMAAAAAVFllmj3ytdde0759+9S5c2dVr35mFwUFBRo0aBDPtAEAAABAOSpTaHNzc9PChQv16quvaseOHfLw8FBYWJiCg4PLu30AAAAAUKWVKbQVatKkiZo0aVJebQEAAAAAnKNMoS0/P1+zZ8/W6tWrdejQIRUUFDitX7NmTbk0DgAAAACqujKFtqeeekqzZ89Wz549FRoaKpvNVt7tAgAAAACojKFtwYIF+vTTT9WjR4/ybg8AAAAA4CxlmvLfzc1N1113XXm3BQAAAABwjjKFtpiYGP373/+WYRjl3R4AAAAAwFnKNDxy48aNWrt2rb7++mvdcMMNcnV1dVq/ePHicmkcAAAAAFR1ZQpttWrV0t13313ebQEAAAAAnKNMoW3WrFnl3Q4AAAAAQDHK9EybJJ0+fVrffvut3nvvPR0/flySdODAAWVlZZVb4wAAAACgqivTnbZ9+/apW7duSk5OVk5Ojrp06SJvb29NmjRJp06d0rvvvlve7QQAAACAKqlMd9qeeuoptW7dWhkZGfLw8DCX33333Vq9enW5NQ4AAAAAqroyzx75/fffy83NzWl5cHCw/vrrr3JpGAAAAACgjHfaCgoKlJ+fX2T5/v375e3tfcmNAgAAAACcUabQ1qVLF02bNs18b7PZlJWVpTFjxqhHjx7l1TYAAAAAqPLKNDzyjTfeUKdOndS8eXOdOnVKAwYM0O+//y4/Pz998skn5d1GAAAAAKiyyhTagoKClJCQoE8++UQ//fSTCgoKNGTIED3wwANOE5MAAAAAAC5NmUKbJHl4eOihhx7SQw89VJ7tAQAAAACcpUyh7aOPPipx/aBBg8rUGAAAAACAszKFtqeeesrpfV5enk6cOCE3Nzd5enoS2gAAAACgnJRp9siMjAynV1ZWlnbv3q1bb72ViUgAAAAAoByVKbQV5/rrr9eECROK3IUDAAAAAJRduYU2SXJxcdGBAwfKc5cAAAAAUKWV6Zm2L774wum9YRhKTU3VjBkz1L59+3JpGAAAAACgjKGtT58+Tu9tNpuuueYa3XHHHZo6dWp5tAsAAAAAoDKGtoKCgvJuBwAAAACgGOX6TBsAAAAAoHyV6U7byJEjL7o2Li6uLIcAAAAAAKiMoW379u366aefdPr0aYWEhEiSfvvtN7m4uOjmm28262w2W/m0EgAAAACqqDKFtl69esnb21tz5syRj4+PpDNfuP3ggw/qtttuU0xMTLk2EgAAAACqqjI90zZ16lSNHz/eDGyS5OPjo9dee43ZIwEAAACgHJUptB07dkwHDx4ssvzQoUM6fvz4JTcKAAAAAHBGmULb3XffrQcffFCfffaZ9u/fr/379+uzzz7TkCFD1Ldv3/JuIwAAAABUWWV6pu3dd9/VqFGjNHDgQOXl5Z3ZUfXqGjJkiCZPnlyuDQSqiqSkpFJv4+fnpwYNGlRAawAAAGAVZQptnp6eevvttzV58mT98ccfMgxD1113nby8vMq7fcBVLz8rQ7LZNHDgwFJv6+7hqd27kghuAAAAV7EyhbZCqampSk1N1e233y4PDw8ZhsE0/0ApFeRkSYYh38gYufrWv+jt8o6k6MiyqUpPTye0AQAAXMXKFNqOHDmifv36ae3atbLZbPr999917bXX6uGHH1atWrWYQRIoA1ff+rIHXlfZzQAAAIDFlGkikqefflqurq5KTk6Wp6enubx///5asWJFuTUOAAAAAKq6Mt1pW7lypb755hvVq1fPafn111+vffv2lUvDAAAAAABlvNOWnZ3tdIetUHp6uux2+yU3CgAAAABwRplC2+23366PPvrIfG+z2VRQUKDJkyerU6dO5dY4AAAAAKjqyjQ8cvLkyerYsaO2bt2q3NxcPfvss/rll1/0999/6/vvvy/vNgIAAABAlVWmO23NmzfXzz//rFtuuUVdunRRdna2+vbtq+3bt6tx48bl3UYAAAAAqLJKfactLy9PEREReu+99zR27NiKaBMAAAAA4P8p9Z02V1dXJSYm8iXaAAAAAHAZlGl45KBBgzRz5szybgsAAAAA4BxlmogkNzdX//nPf7Rq1Sq1bt1aXl5eTuvj4uLKpXEAAAAAUNWVKrT9+eefatiwoRITE3XzzTdLkn777TenGoZNAgAAAED5KVVou/7665Wamqq1a9dKkvr3768333xTAQEBFdI4AAAAAKjqSvVMm2EYTu+//vprZWdnl2uDAAAAAAD/U6aJSAqdG+IAAAAAAOWrVKHNZrMVeWaNZ9gAAAAAoOKU6pk2wzAUHR0tu90uSTp16pQee+yxIrNHLl68uPxaCAAAAABVWKlC2+DBg53eDxw4sFwbAwAAAABwVqrQNmvWrIpqBwAAAACgGJc0EQkAAAAAoGIR2gAAAADAwghtAAAAAGBhhDYAAAAAsDBCGwAAAABYGKENAAAAACyM0AYAAAAAFkZoAwAAAAALK9WXawPAlSQpKalC6wEAAC4HQhuAq05+VoZks2ngwIGV3RQAAIBLRmgDcNUpyMmSDEO+kTFy9a1/0dud/HOrMr+bV4EtAwAAKD1CG4CrlqtvfdkDr7vo+rwjKRXYGgAAgLJhIhIAAAAAsLBKDW0bNmxQr169FBQUJJvNpqVLlzqtNwxDsbGxCgoKkoeHhzp27KhffvnFqSYnJ0dPPPGE/Pz85OXlpd69e2v//v1ONRkZGYqKipLD4ZDD4VBUVJSOHj3qVJOcnKxevXrJy8tLfn5+evLJJ5Wbm+tUs3PnTnXo0EEeHh6qW7euXnnlFRmGUW79AQAAAADnqtTQlp2drRtvvFEzZswodv2kSZMUFxenGTNmaMuWLQoMDFSXLl10/Phxs2bEiBFasmSJFixYoI0bNyorK0uRkZHKz883awYMGKCEhAStWLFCK1asUEJCgqKiosz1+fn56tmzp7Kzs7Vx40YtWLBAn3/+uWJiYsyaY8eOqUuXLgoKCtKWLVs0ffp0TZkyRXFxcRXQMwAAAABwRqU+09a9e3d179692HWGYWjatGl64YUX1LdvX0nSnDlzFBAQoI8//liPPvqoMjMzNXPmTM2dO1d33nmnJGnevHmqX7++vv32W3Xt2lVJSUlasWKF4uPj1aZNG0nSBx98oPDwcO3evVshISFauXKlfv31V6WkpCgoKEiSNHXqVEVHR+v1119XzZo1NX/+fJ06dUqzZ8+W3W5XaGiofvvtN8XFxWnkyJGy2WyXoccAAAAAVDWWfaZtz549SktLU0REhLnMbrerQ4cO+uGHHyRJ27ZtU15enlNNUFCQQkNDzZpNmzbJ4XCYgU2S2rZtK4fD4VQTGhpqBjZJ6tq1q3JycrRt2zazpkOHDrLb7U41Bw4c0N69e897Hjk5OTp27JjTCwAAAAAulmVDW1pamiQpICDAaXlAQIC5Li0tTW5ubvLx8Smxxt/fv8j+/f39nWrOPY6Pj4/c3NxKrCl8X1hTnPHjx5vP0jkcDtWvf/HTjwMAAACAZUNboXOHHRqGccGhiOfWFFdfHjWFk5CU1J7Ro0crMzPTfKWkMKU4AAAAgItn2dAWGBgoqehdrEOHDpl3uAIDA5Wbm6uMjIwSaw4ePFhk/4cPH3aqOfc4GRkZysvLK7Hm0KFDkoreDTyb3W5XzZo1nV4AAAAAcLEsG9oaNWqkwMBArVq1ylyWm5ur9evXq127dpKkVq1aydXV1akmNTVViYmJZk14eLgyMzP1448/mjWbN29WZmamU01iYqJSU1PNmpUrV8put6tVq1ZmzYYNG5y+BmDlypUKCgpSw4YNy78DAAAAAECVHNqysrKUkJCghIQESWcmH0lISFBycrJsNptGjBihcePGacmSJUpMTFR0dLQ8PT01YMAASZLD4dCQIUMUExOj1atXa/v27Ro4cKDCwsLM2SSbNWumbt26aejQoYqPj1d8fLyGDh2qyMhIhYSESJIiIiLUvHlzRUVFafv27Vq9erVGjRqloUOHmnfGBgwYILvdrujoaCUmJmrJkiUaN24cM0cCAAAAqFCVOuX/1q1b1alTJ/P9yJEjJUmDBw/W7Nmz9eyzz+rkyZMaNmyYMjIy1KZNG61cuVLe3t7mNm+88YaqV6+ufv366eTJk+rcubNmz54tFxcXs2b+/Pl68sknzVkme/fu7fTdcC4uLlq+fLmGDRum9u3by8PDQwMGDNCUKVPMGofDoVWrVmn48OFq3bq1fHx8NHLkSLPNAAAAAFARKjW0dezY0ZzMozg2m02xsbGKjY09b427u7umT5+u6dOnn7emdu3amjdvXoltadCggZYtW1ZiTVhYmDZs2FBiDQAAAACUJ8s+0wYAAAAAILQBAAAAgKVV6vBIVL7k5GSlp6eXapukpKQKag0AAACAcxHaqrDk5GSFNG2mUydPVHZTcAnKEqIJ3gAAAFcOQlsVlp6erlMnT8g3MkauvvUveruTf25V5nclT+yCipeflSHZbBo4cGBlNwUAAAAViNAGufrWlz3wuouuzzuSUoGtwcUqyMmSDKPUoVsieAMAAFxJCG3AFa60oVsieAMAAFxJmD0SAAAAACyM0AYAAAAAFkZoAwAAAAALI7QBAAAAgIUR2gAAAADAwghtAAAAAGBhhDYAAAAAsDBCGwAAAABYGKENAAAAACyM0AYAAAAAFkZoAwAAAAALI7QBAAAAgIUR2gAAAADAwqpXdgMA4GqRlJRU6m38/PzUoEGDCmgNAAC4WhDaAOAS5WdlSDabBg4cWOpt3T08tXtXEsENAACcF6ENAC5RQU6WZBjyjYyRq2/9i94u70iKjiybqvT0dEIbAAA4L0IbAJQTV9/6sgdeV9nNAAAAVxkmIgEAAAAACyO0AQAAAICFEdoAAAAAwMIIbQAAAABgYUxEAgCVrLTf71aW74MDAABXLkIbAFSSS/l+NwAAUHUQ2gCgkpT1+91O/rlVmd/Nq8CWAQAAKyG0AUAlK+33u+UdSanA1gAAAKthIhIAAAAAsDBCGwAAAABYGKENAAAAACyM0AYAAAAAFkZoAwAAAAALI7QBAAAAgIUR2gAAAADAwghtAAAAAGBhhDYAAAAAsDBCGwAAAABYGKENAAAAACyM0AYAAAAAFkZoAwAAAAALI7QBAAAAgIUR2gAAAADAwghtAAAAAGBhhDYAAAAAsDBCGwAAAABYGKENAAAAACyM0AYAAAAAFkZoAwAAAAALI7QBAAAAgIUR2gAAAADAwghtAAAAAGBhhDYAAAAAsDBCGwAAAABYGKENAAAAACyM0AYAAAAAFkZoAwAAAAALI7QBAAAAgIUR2gAAAADAwghtAAAAAGBhhDYAAAAAsDBCGwAAAABYGKENAAAAACyM0AYAAAAAFkZoAwAAAAALI7QBAAAAgIUR2gAAAADAwghtAAAAAGBhhDYAAAAAsDBCGwAAAABYGKENAAAAACyM0AYAAAAAFkZoAwAAAAALs3Roi42Nlc1mc3oFBgaa6w3DUGxsrIKCguTh4aGOHTvql19+cdpHTk6OnnjiCfn5+cnLy0u9e/fW/v37nWoyMjIUFRUlh8Mhh8OhqKgoHT161KkmOTlZvXr1kpeXl/z8/PTkk08qNze3ws4dAAAAACSLhzZJuuGGG5Sammq+du7caa6bNGmS4uLiNGPGDG3ZskWBgYHq0qWLjh8/btaMGDFCS5Ys0YIFC7Rx40ZlZWUpMjJS+fn5Zs2AAQOUkJCgFStWaMWKFUpISFBUVJS5Pj8/Xz179lR2drY2btyoBQsW6PPPP1dMTMzl6QQAAAAAVVb1ym7AhVSvXt3p7lohwzA0bdo0vfDCC+rbt68kac6cOQoICNDHH3+sRx99VJmZmZo5c6bmzp2rO++8U5I0b9481a9fX99++626du2qpKQkrVixQvHx8WrTpo0k6YMPPlB4eLh2796tkJAQrVy5Ur/++qtSUlIUFBQkSZo6daqio6P1+uuvq2bNmpepNwAAAABUNZa/0/b7778rKChIjRo10n333ac///xTkrRnzx6lpaUpIiLCrLXb7erQoYN++OEHSdK2bduUl5fnVBMUFKTQ0FCzZtOmTXI4HGZgk6S2bdvK4XA41YSGhpqBTZK6du2qnJwcbdu2rcT25+Tk6NixY04vAAAAALhYlg5tbdq00UcffaRvvvlGH3zwgdLS0tSuXTsdOXJEaWlpkqSAgACnbQICAsx1aWlpcnNzk4+PT4k1/v7+RY7t7+/vVHPucXx8fOTm5mbWnM/48ePNZ+UcDofq169fih4AAAAAUNVZOrR1795d99xzj8LCwnTnnXdq+fLlks4Mgyxks9mctjEMo8iyc51bU1x9WWqKM3r0aGVmZpqvlJSUEusBAAAA4GyWDm3n8vLyUlhYmH7//XfzObdz73QdOnTIvCsWGBio3NxcZWRklFhz8ODBIsc6fPiwU825x8nIyFBeXl6RO3DnstvtqlmzptMLAAAAAC7WFRXacnJylJSUpDp16qhRo0YKDAzUqlWrzPW5ublav3692rVrJ0lq1aqVXF1dnWpSU1OVmJho1oSHhyszM1M//vijWbN582ZlZmY61SQmJio1NdWsWblypex2u1q1alWh5wwAAACgarP07JGjRo1Sr1691KBBAx06dEivvfaajh07psGDB8tms2nEiBEaN26crr/+el1//fUaN26cPD09NWDAAEmSw+HQkCFDFBMTI19fX9WuXVujRo0yh1tKUrNmzdStWzcNHTpU7733niTpkUceUWRkpEJCQiRJERERat68uaKiojR58mT9/fffGjVqlIYOHcqdMwAAAAAVytKhbf/+/br//vuVnp6ua665Rm3btlV8fLyCg4MlSc8++6xOnjypYcOGKSMjQ23atNHKlSvl7e1t7uONN95Q9erV1a9fP508eVKdO3fW7Nmz5eLiYtbMnz9fTz75pDnLZO/evTVjxgxzvYuLi5YvX65hw4apffv28vDw0IABAzRlypTL1BMAAAAAqipLh7YFCxaUuN5msyk2NlaxsbHnrXF3d9f06dM1ffr089bUrl1b8+bNK/FYDRo00LJly0qsAQAAAIDydkU90wYAAAAAVQ2hDQAAAAAsjNAGAAAAABZGaAMAAAAACyO0AQAAAICFEdoAAAAAwMIsPeU/AKD8JSUllXobPz8/NWjQoAJaAwAALoTQBgBVRH5WhmSzaeDAgaXe1t3DU7t3JRHcAACoBIQ2AKgiCnKyJMOQb2SMXH3rX/R2eUdSdGTZVKWnpxPaAACoBIQ2AKhiXH3ryx54XWU3AwAAXCQmIgEAAAAACyO0AQAAAICFEdoAAAAAwMIIbQAAAABgYYQ2AAAAALAwQhsAAAAAWBihDQAAAAAsjNAGAAAAABZGaAMAAAAACyO0AQAAAICFEdoAAAAAwMIIbQAAAABgYYQ2AAAAALAwQhsAAAAAWBihDQAAAAAsjNAGAAAAABZGaAMAAAAACyO0AQAAAICFEdoAAAAAwMIIbQAAAABgYYQ2AAAAALAwQhsAAAAAWBihDQAAAAAsjNAGAAAAABZGaAMAAAAACyO0AQAAAICFEdoAAAAAwMIIbQAAAABgYYQ2AAAAALAwQhsAAAAAWBihDQAAAAAsjNAGAAAAABZGaAMAAAAACyO0AQAAAICFEdoAAAAAwMIIbQAAAABgYYQ2AAAAALAwQhsAAAAAWBihDQAAAAAsjNAGAAAAABZGaAMAAAAACyO0AQAAAICFEdoAAAAAwMIIbQAAAABgYYQ2AAAAALAwQhsAAAAAWBihDQAAAAAsjNAGAAAAABZGaAMAAAAACyO0AQAAAICFEdoAAAAAwMIIbQAAAABgYYQ2AAAAALAwQhsAAAAAWBihDQAAAAAsjNAGAAAAABZGaAMAAAAACyO0AQAAAICFEdoAAAAAwMIIbQAAAABgYYQ2AAAAALAwQhsAAAAAWBihDQAAAAAsjNAGAAAAABZGaAMAAAAACyO0AQAAAICFEdoAAAAAwMIIbWXw9ttvq1GjRnJ3d1erVq303XffVXaTAAAAAFylCG2ltHDhQo0YMUIvvPCCtm/frttuu03du3dXcnJyZTcNAAAAwFWoemU34EoTFxenIUOG6OGHH5YkTZs2Td98843eeecdjR8/vpJbBwAVJykpqUzb5eTkyG63l3o7Pz8/NWjQoEzHBADgakJoK4Xc3Fxt27ZNzz33nNPyiIgI/fDDD8Vuk5OTo5ycHPN9ZmamJOnYsWMV19CLlJWVJUnKSfuvCnJPXfR2eUdS2O4K3q4yjsl2V/Z2OQfOhLWBAwde9DbObJKMUm/lZnfXvLkfKSAgoFTbVatWTQUFBaU+Httd2dtVxjHZrmpuVxnHZLvy3S4wMFCBgYGl3q4iFGYCwyj5/ydtxoUqYDpw4IDq1q2r77//Xu3atTOXjxs3TnPmzNHu3buLbBMbG6uxY8dezmYCAAAAuIKkpKSoXr16513PnbYysNlsTu8NwyiyrNDo0aM1cuRI831BQYH+/vtv+fr6nnebquLYsWOqX7++UlJSVLNmzcpuTpVAn1cO+v3yo88vP/r88qPPKwf9fvldzX1uGIaOHz+uoKCgEusIbaXg5+cnFxcXpaWlOS0/dOjQeYfv2O32Is9y1KpVq6KaeEWqWbPmVfcP0Oro88pBv19+9PnlR59ffvR55aDfL7+rtc8dDscFa5g9shTc3NzUqlUrrVq1ymn5qlWrnIZLAgAAAEB54U5bKY0cOVJRUVFq3bq1wsPD9f777ys5OVmPPfZYZTcNAAAAwFWI0FZK/fv315EjR/TKK68oNTVVoaGh+uqrrxQcHFzZTbvi2O12jRkzpkxTgaNs6PPKQb9ffvT55UefX370eeWg3y8/+pzZIwEAAADA0nimDQAAAAAsjNAGAAAAABZGaAMAAAAACyO0AQAAAICFEdpwQRs2bFCvXr0UFBQkm82mpUuXlli/bt062Wy2Iq9du3Y51X3++edq3ry57Ha7mjdvriVLljitb9iwYbH7GT58uFljGIZiY2MVFBQkDw8PdezYUb/88ku5nXtlsnK/R0dHF1nftm3bcjv3ylJZfX769Gm9+OKLatSokTw8PHTttdfqlVdeUUFBgVlztV7rVu5zrvMzyqvPjx8/rhEjRig4OFgeHh5q166dtmzZ4lRztV7nkrX7nWv9jIvp819++UX33HOP+f+V06ZNK3Zfb7/9tho1aiR3d3e1atVK3333ndP6q/Vat3KfX+nXOaENF5Sdna0bb7xRM2bMKNV2u3fvVmpqqvm6/vrrzXWbNm1S//79FRUVpR07digqKkr9+vXT5s2bzZotW7Y4bV/4peb/+Mc/zJpJkyYpLi5OM2bM0JYtWxQYGKguXbro+PHjl3jWlc/K/S5J3bp1c6r76quvLuFsraGy+nzixIl69913NWPGDCUlJWnSpEmaPHmypk+fbtZcrde6lftc4jo/26X2+cMPP6xVq1Zp7ty52rlzpyIiInTnnXfqr7/+Mmuu1utcsna/S1zrZyupz0+cOKFrr71WEyZMUGBgYLHbL1y4UCNGjNALL7yg7du367bbblP37t2VnJxs1lyt17qV+1y6wq9zAygFScaSJUtKrFm7dq0hycjIyDhvTb9+/Yxu3bo5Levatatx3333nXebp556ymjcuLFRUFBgGIZhFBQUGIGBgcaECRPMmlOnThkOh8N49913L3wyVxAr9bthGMbgwYONu+6662KafsW6nH3es2dP46GHHnKq6du3rzFw4EDDMKrOtW6lPjcMrvNC5dHnJ06cMFxcXIxly5Y51dx4443GCy+8YBhG1bnODcNa/W4YXOuFLqbPzxYcHGy88cYbRZbfcsstxmOPPea0rGnTpsZzzz1nGEbVudat1OeGceVf59xpQ4Vp2bKl6tSpo86dO2vt2rVO6zZt2qSIiAinZV27dtUPP/xQ7L5yc3M1b948PfTQQ7LZbJKkPXv2KC0tzWk/drtdHTp0OO9+qoKK7vdC69atk7+/v5o0aaKhQ4fq0KFD5XsiV5BL7fNbb71Vq1ev1m+//SZJ2rFjhzZu3KgePXpI4lovTkX3eSGu8/+5lD4/ffq08vPz5e7u7lTj4eGhjRs3SuI6P5+K7vdCXOv/U1KfX0hubq62bdtW5HOJiIgwPxeu9aIqus8LXcnXefXKbgCuPnXq1NH777+vVq1aKScnR3PnzlXnzp21bt063X777ZKktLQ0BQQEOG0XEBCgtLS0Yve5dOlSHT16VNHR0eaywtri9rNv375yPKMrw+Xqd0nq3r27/vGPfyg4OFh79uzRSy+9pDvuuEPbtm2T3W6vkPOzovLq83/961/KzMxU06ZN5eLiovz8fL3++uu6//77zX0UbnfufqratX65+lziOi9UHn3u7e2t8PBwvfrqq2rWrJkCAgL0ySefaPPmzeYwKK5zZ5er3yWu9UIX0+cXkp6ervz8/BI/F671/7lcfS5d+dc5oQ3lLiQkRCEhIeb78PBwpaSkaMqUKU7/AM+9c2MYRpFlhWbOnKnu3bsrKCioyLrS7Odqdjn7vX///uZ/h4aGqnXr1goODtby5cvVt2/f8jidK0J59fnChQs1b948ffzxx7rhhhuUkJCgESNGKCgoSIMHD77o/VQFl7PPuc7PKK8+nzt3rh566CHVrVtXLi4uuvnmmzVgwAD99NNPTttxnZ9xOfuda/2Mi+3zi3Ex1zHX+uXt8yv9Omd4JC6Ltm3b6vfffzffBwYGFrm7c+jQoSJ/JZGkffv26dtvv9XDDz/stLzwYdSL3U9VVBH9Xpw6deooODjY6VhVVVn6/JlnntFzzz2n++67T2FhYYqKitLTTz+t8ePHm/uQuNbPpyL6vDhc5/9Tlj5v3Lix1q9fr6ysLKWkpOjHH39UXl6eGjVqZO5D4jovSUX0e3G41v/n3D6/ED8/P7m4uJT4uXCtl6wi+rw4V9p1TmjDZbF9+3bVqVPHfB8eHm7OSlho5cqVateuXZFtZ82aJX9/f/Xs2dNpeaNGjRQYGOi0n9zcXK1fv77Y/VRFFdHvxTly5IhSUlKcjlVVlaXPT5w4oWrVnH8cu7i4mNPPc62XrCL6vDhc5/9zKT9bvLy8VKdOHWVkZOibb77RXXfdJYnr/GJURL8Xh2v9f87t8wtxc3NTq1atinwuq1atMj8XrvWSVUSfF+eKu84rZ/4TXEmOHz9ubN++3di+fbshyYiLizO2b99u7Nu3zzAMw3juueeMqKgos/6NN94wlixZYvz2229GYmKi8dxzzxmSjM8//9ys+f777w0XFxdjwoQJRlJSkjFhwgSjevXqRnx8vNOx8/PzjQYNGhj/+te/im3bhAkTDIfDYSxevNjYuXOncf/99xt16tQxjh07VgE9cXlZtd+PHz9uxMTEGD/88IOxZ88eY+3atUZ4eLhRt27dK77fK6vPBw8ebNStW9dYtmyZsWfPHmPx4sWGn5+f8eyzz5o1V+u1btU+5zov/z5fsWKF8fXXXxt//vmnsXLlSuPGG280brnlFiM3N9esuVqvc8Owbr9zrZeuz3Nycsx91qlTxxg1apSxfft24/fffzdrFixYYLi6uhozZ840fv31V2PEiBGGl5eXsXfvXrPmar3WrdrnV8N1TmjDBRVOx3rua/DgwYZhnPnlp0OHDmb9xIkTjcaNGxvu7u6Gj4+PceuttxrLly8vst9FixYZISEhhqurq9G0aVOnf6CFvvnmG0OSsXv37mLbVlBQYIwZM8YIDAw07Ha7cfvttxs7d+4sl/OubFbt9xMnThgRERHGNddcY7i6uhoNGjQwBg8ebCQnJ5fbuVeWyurzY8eOGU899ZTRoEEDw93d3bj22muNF154wcjJyTFrrtZr3ap9znXewawvrz5fuHChce211xpubm5GYGCgMXz4cOPo0aNONVfrdW4Y1u13rvUOZv3F9PmePXuK3efZ+zEMw3jrrbeM4OBgw83Nzbj55puN9evXO62/Wq91q/b51XCd2wzDMC7tXh0AAAAAoKLwTBsAAAAAWBihDQAAAAAsjNAGAAAAABZGaAMAAAAACyO0AQAAAICFEdoAAAAAwMIIbQAAAABgYYQ2AAAAACjGhg0b1KtXLwUFBclms2np0qWl3senn36qm266SZ6engoODtbkyZNLvQ9CGwCgSouNjdVNN91U2c0AAFhQdna2brzxRs2YMaNM23/99dd64IEH9NhjjykxMVFvv/224uLiSr0/m2EYRplaAACAxdlsthLXDx48WDNmzFBOTo58fX0vU6uKio2N1dKlS5WQkFBpbQAAlMxms2nJkiXq06ePuSw3N1cvvvii5s+fr6NHjyo0NFQTJ05Ux44dJUkDBgxQXl6eFi1aZG4zbdo0TZ06VcnJyRf8/6lC1cvzRAAAsJLU1FTzvxcuXKiXX35Zu3fvNpd5eHioRo0aqlGjRmU0DwBwhXvwwQe1d+9eLViwQEFBQVqyZIm6deumnTt36vrrr1dOTo48PT2dtvHw8ND+/fu1b98+NWzY8KKOw/BIAMBVKzAw0Hw5HA7ZbLYiy84dHhkdHa0+ffpo3LhxCggIUK1atTR27FidPn1azzzzjGrXrq169erpww8/dDrWX3/9pf79+8vHx0e+vr666667tHfvXnP9unXrdMstt8jLy0u1atVS+/bttW/fPs2ePVtjx47Vjh07ZLPZZLPZNHv2bElSXFycwsLC5OXlpfr162vYsGHKysoy9zl79mzVqlVLy5YtU0hIiDw9PXXvvfcqOztbc+bMUcOGDeXj46MnnnhC+fn55nYNGzbUq6++qgEDBqhGjRoKCgrS9OnTK+QzAICr1R9//KFPPvlEixYt0m233abGjRtr1KhRuvXWWzVr1ixJUteuXbV48WKtXr1aBQUF+u233zRt2jRJzn9YvBBCGwAA51izZo0OHDigDRs2KC4uTrGxsYqMjJSPj482b96sxx57TI899phSUlIkSSdOnFCnTp1Uo0YNbdiwQRs3blSNGjXUrVs35ebm6vTp0+rTp486dOign3/+WZs2bdIjjzwim82m/v37KyYmRjfccINSU1OVmpqq/v37S5KqVaumN998U4mJiZozZ47WrFmjZ5991qmtJ06c0JtvvqkFCxZoxYoVWrdunfr27auvvvpKX331lebOnav3339fn332mdN2kydPVosWLfTTTz9p9OjRevrpp7Vq1arL08EAcBX46aefZBiGmjRpYo7aqFGjhtavX68//vhDkjR06FA9/vjjioyMlJubm9q2bav77rtPkuTi4nLRx2J4JAAA56hdu7befPNNVatWTSEhIZo0aZJOnDih559/XpI0evRoTZgwQd9//73uu+8+LViwQNWqVdN//vMf8/mEWbNmqVatWlq3bp1at26tzMxMRUZGqnHjxpKkZs2amcerUaOGqlevrsDAQKd2jBgxwvzvRo0a6dVXX9U///lPvf322+byvLw8vfPOO+Z+7733Xs2dO1cHDx5UjRo11Lx5c3Xq1Elr1641w6AktW/fXs8995wkqUmTJvr+++/1xhtvqEuXLuXYkwBw9SooKJCLi4u2bdtWJIAVDru32WyaOHGixo0bp7S0NF1zzTVavXq1JF300EiJ0AYAQBE33HCDqlX732CUgIAAhYaGmu9dXFzk6+urQ4cOSZK2bdum//73v/L29nbaz6lTp/THH38oIiJC0dHR6tq1q7p06aI777xT/fr1U506dUpsx9q1azVu3Dj9+uuvOnbsmE6fPq1Tp04pOztbXl5ekiRPT08zsBW2tWHDhk7P6QUEBJhtLRQeHl7kfeGQHQDAhbVs2VL5+fk6dOiQbrvtthJrXVxcVLduXUnSJ598ovDwcPn7+1/0sQhtAACcw9XV1em9zWYrdllBQYGkM39tbdWqlebPn19kX9dcc42kM3fennzySa1YsUILFy7Uiy++qFWrVqlt27bFtmHfvn3q0aOHHnvsMb366quqXbu2Nm7cqCFDhigvL6/MbS3Jxc5iBgBVRVZWlv773/+a7/fs2aOEhATVrl1bTZo00QMPPKBBgwZp6tSpatmypdLT07VmzRqFhYWpR48eSk9P12effaaOHTvq1KlTmjVrlhYtWqT169eXqh2ENgAALtHNN9+shQsXyt/fXzVr1jxvXcuWLdWyZUuNHj1a4eHh+vjjj9W2bVu5ubk5TRQiSVu3btXp06c1depU867fp59+Wm5tjo+PL/K+adOm5bZ/ALgabN26VZ06dTLfjxw5UtKZr4yZPXu2Zs2apddee00xMTH666+/5Ovrq/DwcPXo0cPcZs6cORo1apQMw1B4eLg5MVVpENoAALhEDzzwgCZPnqy77rpLr7zyiurVq6fk5GQtXrxYzzzzjPLy8vT++++rd+/eCgoK0u7du/Xbb79p0KBBks4811D419t69erJ29tbjRs31unTpzV9+nT16tVL33//vd59991ya/P333+vSZMmqU+fPlq1apUWLVqk5cuXl9v+AeBq0LFjR5X0tdaurq4aO3asxo4dW+x6Pz8/bdq06ZLbweyRAABcIk9PT23YsEENGjRQ37591axZMz300EM6efKkatasKU9PT+3atUv33HOPmjRpokceeUSPP/64Hn30UUnSPffco27duqlTp0665ppr9Mknn+imm25SXFycJk6cqNDQUM2fP1/jx48vtzbHxMRo27ZtatmypV599VVNnTpVXbt2Lbf9AwDKj80oKToCAICrTsOGDTVixAin2SkBANbFnTYAAAAAsDBCGwAAAABYGMMjAQAAAMDCuNMGAAAAABZGaAMAAAAACyO0AQAAAICFEdoAAAAAwMIIbQAAAABgYYQ2AAAAALAwQhsAAAAAWBihDQAAAAAs7P8HWRer7Ri/DE4AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# Plot histogram of the timestamp column\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(df['click_timestamp'], bins=50, edgecolor='k')\n",
    "plt.title('Histogram of Timestamps in the Globo Dataset')\n",
    "plt.xlabel('Timestamp')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "66ac1379-2266-4bec-b6d3-9cf22c1aaedf",
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp_counts = df['click_timestamp'].value_counts().sort_index(ascending=False)\n",
    "cumulative_counts = timestamp_counts.cumsum()\n",
    "total_counts = cumulative_counts.max()\n",
    "threshold_count = total_counts * 0.1\n",
    "threshold_timestamp = cumulative_counts[cumulative_counts >= threshold_count].index[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a8b54ee9-8024-4d18-89c8-7858f45d7906",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = df[df['click_timestamp'] >= threshold_timestamp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "877cfa8a-c9d3-4436-8a74-5009b026f266",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>click_article_id</th>\n",
       "      <th>click_timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>157541</td>\n",
       "      <td>1.506827e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>68866</td>\n",
       "      <td>1.506827e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>235840</td>\n",
       "      <td>1.506827e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>96663</td>\n",
       "      <td>1.506827e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>119592</td>\n",
       "      <td>1.506827e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2564</th>\n",
       "      <td>10051</td>\n",
       "      <td>84911</td>\n",
       "      <td>1.508212e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2565</th>\n",
       "      <td>322896</td>\n",
       "      <td>30760</td>\n",
       "      <td>1.508212e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2566</th>\n",
       "      <td>322896</td>\n",
       "      <td>157507</td>\n",
       "      <td>1.508212e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2567</th>\n",
       "      <td>123718</td>\n",
       "      <td>234481</td>\n",
       "      <td>1.508212e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2568</th>\n",
       "      <td>123718</td>\n",
       "      <td>233578</td>\n",
       "      <td>1.508212e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2988181 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      user_id  click_article_id  click_timestamp\n",
       "0           0            157541     1.506827e+09\n",
       "1           0             68866     1.506827e+09\n",
       "2           1            235840     1.506827e+09\n",
       "3           1             96663     1.506827e+09\n",
       "4           2            119592     1.506827e+09\n",
       "...       ...               ...              ...\n",
       "2564    10051             84911     1.508212e+09\n",
       "2565   322896             30760     1.508212e+09\n",
       "2566   322896            157507     1.508212e+09\n",
       "2567   123718            234481     1.508212e+09\n",
       "2568   123718            233578     1.508212e+09\n",
       "\n",
       "[2988181 rows x 3 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "75315c82-bb45-4090-8d92-87e16d42f204",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>click_article_id</th>\n",
       "      <th>click_timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4289</th>\n",
       "      <td>22712</td>\n",
       "      <td>158772</td>\n",
       "      <td>1.508196e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4290</th>\n",
       "      <td>22712</td>\n",
       "      <td>284638</td>\n",
       "      <td>1.508633e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4291</th>\n",
       "      <td>22712</td>\n",
       "      <td>95633</td>\n",
       "      <td>1.508678e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4292</th>\n",
       "      <td>22712</td>\n",
       "      <td>95524</td>\n",
       "      <td>1.508679e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4293</th>\n",
       "      <td>22712</td>\n",
       "      <td>184427</td>\n",
       "      <td>1.508679e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2564</th>\n",
       "      <td>10051</td>\n",
       "      <td>84911</td>\n",
       "      <td>1.508212e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2565</th>\n",
       "      <td>322896</td>\n",
       "      <td>30760</td>\n",
       "      <td>1.508212e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2566</th>\n",
       "      <td>322896</td>\n",
       "      <td>157507</td>\n",
       "      <td>1.508212e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2567</th>\n",
       "      <td>123718</td>\n",
       "      <td>234481</td>\n",
       "      <td>1.508212e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2568</th>\n",
       "      <td>123718</td>\n",
       "      <td>233578</td>\n",
       "      <td>1.508212e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>298819 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      user_id  click_article_id  click_timestamp\n",
       "4289    22712            158772     1.508196e+09\n",
       "4290    22712            284638     1.508633e+09\n",
       "4291    22712             95633     1.508678e+09\n",
       "4292    22712             95524     1.508679e+09\n",
       "4293    22712            184427     1.508679e+09\n",
       "...       ...               ...              ...\n",
       "2564    10051             84911     1.508212e+09\n",
       "2565   322896             30760     1.508212e+09\n",
       "2566   322896            157507     1.508212e+09\n",
       "2567   123718            234481     1.508212e+09\n",
       "2568   123718            233578     1.508212e+09\n",
       "\n",
       "[298819 rows x 3 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "095cfd61-c063-4637-8a29-810ee70adcc1",
   "metadata": {},
   "source": [
    "## Dataset Preprocessing to Interaction Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "28b3aa70-98ce-4bd8-9888-904495d7f8e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39171762087143528f40b950a2d2a97c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/298819 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9049b95094494f8b9ca350012dd14f13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/298819 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from recpack.matrix import InteractionMatrix\n",
    "from recpack.preprocessing.preprocessors import DataFramePreprocessor\n",
    "\n",
    "item_ix = 'click_article_id'\n",
    "user_ix = 'user_id'\n",
    "timestamp_ix = 'click_timestamp'\n",
    "\n",
    "preprocessor = DataFramePreprocessor(item_ix=item_ix, user_ix=user_ix, timestamp_ix=timestamp_ix)\n",
    "\n",
    "interaction_matrix = preprocessor.process(filtered_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3724a316-bddf-4d07-b37b-67d031f49866",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Compressed Sparse Row sparse matrix of dtype 'int32'\n",
       "\twith 296356 stored elements and shape (81233, 10303)>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interaction_matrix.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8f383d19-26b7-42b9-a47f-25581172d59f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "298819"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interaction_matrix.num_interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0977e4d5-f4e1-41eb-aab0-5911014c02ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "InteractionMatrix.InteractionMatrixProperties(num_users=81233, num_items=10303, has_timestamps=True)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interaction_matrix.properties"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d317b22-4048-4f5f-9bfe-4c8b77aebd7f",
   "metadata": {},
   "source": [
    "## TimedLastItemPrediction Scenario Splitting of Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "73d22b62-213c-4ac4-9346-70414e7c39db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([11940.,  7309., 16786., 29139., 36120.,  8249., 45830., 66290.,\n",
       "        47406., 27855.]),\n",
       " array([1.50802851e+09, 1.50804683e+09, 1.50806515e+09, 1.50808347e+09,\n",
       "        1.50810179e+09, 1.50812011e+09, 1.50813843e+09, 1.50815675e+09,\n",
       "        1.50817507e+09, 1.50819339e+09, 1.50821171e+09]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# Histogram of interactions over time\n",
    "tt = interaction_matrix.timestamps.values[int(0.999 * len(interaction_matrix.timestamps.values))]\n",
    "plt.hist(interaction_matrix.timestamps_lte(tt).timestamps.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "de37ad03-b7d4-4099-a4d8-d3c6636f9267",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1508184661.438 1508164951.091\n"
     ]
    }
   ],
   "source": [
    "interaction_matrix.timestamps.values\n",
    "t_80 = interaction_matrix.timestamps.values[int(0.8 * len(interaction_matrix.timestamps.values))]\n",
    "t_validate_80 = interaction_matrix.timestamps.values[int(0.8 * 0.8 * len(interaction_matrix.timestamps.values))]\n",
    "print(t_80, t_validate_80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa72bb09-e745-4c5f-b4b3-88785f8a96b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario = TimedLastItemPrediction(t = t_80, t_validation = t_validate_80, validation=True)\n",
    "scenario.split(interaction_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a62dd74-cd21-4d1d-8478-45376802c09a",
   "metadata": {},
   "source": [
    "## Experimental RecPack Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "40f6a5b5-4f21-49ee-a96e-f7e375031134",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/recpack/pipelines/pipeline_builder.py:145: UserWarning: Grid parameter for add_algorithm function will be deprecated in favour of optimisation_info.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe691ac3626343feba0a5b13dcb67089",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_58233/4206860820.py:81: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  user_indices = torch.tensor(user_indices).to(self.device)\n",
      "/tmp/ipykernel_58233/4206860820.py:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  pos_item_indices = torch.tensor(pos_item_indices).to(self.device)\n",
      "/tmp/ipykernel_58233/4206860820.py:83: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  neg_item_indices = torch.tensor(neg_item_indices).to(self.device).squeeze()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-05 14:36:41,034 - base - recpack - INFO - Processed epoch 0 in 3.24 s.Batch Training Loss = 0.1401\n",
      "2024-08-05 14:41:13,938 - stopping_criterion - recpack - INFO - StoppingCriterion has value 1.7272945263249904, which is better than previous iterations.\n",
      "2024-08-05 14:41:13,941 - base - recpack - INFO - Model improved. Storing better model.\n",
      "2024-08-05 14:41:14,027 - base - recpack - INFO - Evaluation at end of 0 took 272.99 s.\n",
      "2024-08-05 14:41:17,125 - base - recpack - INFO - Processed epoch 1 in 3.10 s.Batch Training Loss = 0.1267\n",
      "2024-08-05 14:45:49,886 - stopping_criterion - recpack - INFO - StoppingCriterion has value 2.4967495701607896, which is worse than previous iterations.\n",
      "2024-08-05 14:45:50,112 - base - recpack - INFO - Evaluation at end of 1 took 272.99 s.\n",
      "2024-08-05 14:45:53,084 - base - recpack - INFO - Processed epoch 2 in 2.97 s.Batch Training Loss = 0.1017\n",
      "2024-08-05 14:50:21,275 - stopping_criterion - recpack - INFO - StoppingCriterion has value 2.5114313251201748, which is worse than previous iterations.\n",
      "2024-08-05 14:50:21,297 - base - recpack - INFO - Evaluation at end of 2 took 268.21 s.\n",
      "2024-08-05 14:50:24,479 - base - recpack - INFO - Processed epoch 3 in 3.18 s.Batch Training Loss = 0.0879\n",
      "2024-08-05 14:54:58,504 - stopping_criterion - recpack - INFO - StoppingCriterion has value 2.304270953305917, which is worse than previous iterations.\n",
      "2024-08-05 14:54:58,527 - base - recpack - INFO - Evaluation at end of 3 took 274.05 s.\n",
      "2024-08-05 14:55:01,784 - base - recpack - INFO - Processed epoch 4 in 3.26 s.Batch Training Loss = 0.0806\n",
      "2024-08-05 14:59:33,222 - stopping_criterion - recpack - INFO - StoppingCriterion has value 2.1890315457362495, which is worse than previous iterations.\n",
      "2024-08-05 14:59:33,246 - base - recpack - INFO - Evaluation at end of 4 took 271.46 s.\n",
      "2024-08-05 14:59:33,275 - base - recpack - INFO - Fitting LightGCNAlgorithm complete - Took 1.38e+03s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/recpack/algorithms/base.py:509: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.model_ = torch.load(self.best_model)\n",
      "/tmp/ipykernel_58233/4206860820.py:81: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  user_indices = torch.tensor(user_indices).to(self.device)\n",
      "/tmp/ipykernel_58233/4206860820.py:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  pos_item_indices = torch.tensor(pos_item_indices).to(self.device)\n",
      "/tmp/ipykernel_58233/4206860820.py:83: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  neg_item_indices = torch.tensor(neg_item_indices).to(self.device).squeeze()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-05 15:04:50,239 - base - recpack - INFO - Processed epoch 0 in 3.08 s.Batch Training Loss = 0.1683\n",
      "2024-08-05 15:09:18,176 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.6616383723221656, which is better than previous iterations.\n",
      "2024-08-05 15:09:18,179 - base - recpack - INFO - Model improved. Storing better model.\n",
      "2024-08-05 15:09:18,265 - base - recpack - INFO - Evaluation at end of 0 took 268.03 s.\n",
      "2024-08-05 15:09:21,355 - base - recpack - INFO - Processed epoch 1 in 3.09 s.Batch Training Loss = 0.0759\n",
      "2024-08-05 15:13:46,717 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.6667560179803089, which is worse than previous iterations.\n",
      "2024-08-05 15:13:46,745 - base - recpack - INFO - Evaluation at end of 1 took 265.39 s.\n",
      "2024-08-05 15:13:50,353 - base - recpack - INFO - Processed epoch 2 in 3.61 s.Batch Training Loss = 0.0711\n",
      "2024-08-05 15:18:24,363 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.6746132216357631, which is worse than previous iterations.\n",
      "2024-08-05 15:18:24,614 - base - recpack - INFO - Evaluation at end of 2 took 274.26 s.\n",
      "2024-08-05 15:18:27,662 - base - recpack - INFO - Processed epoch 3 in 3.05 s.Batch Training Loss = 0.0688\n",
      "2024-08-05 15:22:56,381 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.6857385459421034, which is worse than previous iterations.\n",
      "2024-08-05 15:22:56,393 - base - recpack - INFO - Evaluation at end of 3 took 268.73 s.\n",
      "2024-08-05 15:22:59,530 - base - recpack - INFO - Processed epoch 4 in 3.14 s.Batch Training Loss = 0.0655\n",
      "2024-08-05 15:27:26,785 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.7012847267475569, which is worse than previous iterations.\n",
      "2024-08-05 15:27:26,807 - base - recpack - INFO - Evaluation at end of 4 took 267.27 s.\n",
      "2024-08-05 15:27:26,838 - base - recpack - INFO - Fitting LightGCNAlgorithm complete - Took 1.36e+03s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/recpack/algorithms/base.py:509: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.model_ = torch.load(self.best_model)\n",
      "/tmp/ipykernel_58233/4206860820.py:81: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  user_indices = torch.tensor(user_indices).to(self.device)\n",
      "/tmp/ipykernel_58233/4206860820.py:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  pos_item_indices = torch.tensor(pos_item_indices).to(self.device)\n",
      "/tmp/ipykernel_58233/4206860820.py:83: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  neg_item_indices = torch.tensor(neg_item_indices).to(self.device).squeeze()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-05 15:32:45,385 - base - recpack - INFO - Processed epoch 0 in 3.15 s.Batch Training Loss = 0.5526\n",
      "2024-08-05 15:37:09,868 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.688106838060674, which is better than previous iterations.\n",
      "2024-08-05 15:37:09,869 - base - recpack - INFO - Model improved. Storing better model.\n",
      "2024-08-05 15:37:09,956 - base - recpack - INFO - Evaluation at end of 0 took 264.57 s.\n",
      "2024-08-05 15:37:13,092 - base - recpack - INFO - Processed epoch 1 in 3.13 s.Batch Training Loss = 0.2122\n",
      "2024-08-05 15:41:42,296 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.6800185465543308, which is worse than previous iterations.\n",
      "2024-08-05 15:41:42,324 - base - recpack - INFO - Evaluation at end of 1 took 269.23 s.\n",
      "2024-08-05 15:41:45,661 - base - recpack - INFO - Processed epoch 2 in 3.34 s.Batch Training Loss = 0.1224\n",
      "2024-08-05 15:46:16,640 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.674338054320667, which is better than previous iterations.\n",
      "2024-08-05 15:46:16,642 - base - recpack - INFO - Model improved. Storing better model.\n",
      "2024-08-05 15:46:16,735 - base - recpack - INFO - Evaluation at end of 2 took 271.07 s.\n",
      "2024-08-05 15:46:20,169 - base - recpack - INFO - Processed epoch 3 in 3.43 s.Batch Training Loss = 0.0964\n",
      "2024-08-05 15:50:51,377 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.6706719096503508, which is worse than previous iterations.\n",
      "2024-08-05 15:50:51,390 - base - recpack - INFO - Evaluation at end of 3 took 271.22 s.\n",
      "2024-08-05 15:50:54,561 - base - recpack - INFO - Processed epoch 4 in 3.17 s.Batch Training Loss = 0.0853\n",
      "2024-08-05 15:55:31,013 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.6674627847231706, which is worse than previous iterations.\n",
      "2024-08-05 15:55:31,062 - base - recpack - INFO - Evaluation at end of 4 took 276.50 s.\n",
      "2024-08-05 15:55:31,095 - base - recpack - INFO - Fitting LightGCNAlgorithm complete - Took 1.37e+03s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/recpack/algorithms/base.py:509: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.model_ = torch.load(self.best_model)\n",
      "/tmp/ipykernel_58233/4206860820.py:81: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  user_indices = torch.tensor(user_indices).to(self.device)\n",
      "/tmp/ipykernel_58233/4206860820.py:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  pos_item_indices = torch.tensor(pos_item_indices).to(self.device)\n",
      "/tmp/ipykernel_58233/4206860820.py:83: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  neg_item_indices = torch.tensor(neg_item_indices).to(self.device).squeeze()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-05 16:00:46,505 - base - recpack - INFO - Processed epoch 0 in 4.10 s.Batch Training Loss = 0.1672\n",
      "2024-08-05 16:05:20,801 - stopping_criterion - recpack - INFO - StoppingCriterion has value 2.233627735014319, which is better than previous iterations.\n",
      "2024-08-05 16:05:20,802 - base - recpack - INFO - Model improved. Storing better model.\n",
      "2024-08-05 16:05:20,957 - base - recpack - INFO - Evaluation at end of 0 took 274.45 s.\n",
      "2024-08-05 16:05:24,766 - base - recpack - INFO - Processed epoch 1 in 3.81 s.Batch Training Loss = 0.1628\n",
      "2024-08-05 16:09:57,372 - stopping_criterion - recpack - INFO - StoppingCriterion has value 2.956243833264948, which is worse than previous iterations.\n",
      "2024-08-05 16:09:57,384 - base - recpack - INFO - Evaluation at end of 1 took 272.62 s.\n",
      "2024-08-05 16:10:01,369 - base - recpack - INFO - Processed epoch 2 in 3.98 s.Batch Training Loss = 0.1279\n",
      "2024-08-05 16:14:28,972 - stopping_criterion - recpack - INFO - StoppingCriterion has value 2.550109534507217, which is worse than previous iterations.\n",
      "2024-08-05 16:14:28,983 - base - recpack - INFO - Evaluation at end of 2 took 267.61 s.\n",
      "2024-08-05 16:14:33,492 - base - recpack - INFO - Processed epoch 3 in 4.51 s.Batch Training Loss = 0.1098\n",
      "2024-08-05 16:19:02,290 - stopping_criterion - recpack - INFO - StoppingCriterion has value 2.529935878525442, which is worse than previous iterations.\n",
      "2024-08-05 16:19:02,531 - base - recpack - INFO - Evaluation at end of 3 took 269.04 s.\n",
      "2024-08-05 16:19:06,877 - base - recpack - INFO - Processed epoch 4 in 4.34 s.Batch Training Loss = 0.1078\n",
      "2024-08-05 16:23:36,334 - stopping_criterion - recpack - INFO - StoppingCriterion has value 2.422207677528197, which is worse than previous iterations.\n",
      "2024-08-05 16:23:36,347 - base - recpack - INFO - Evaluation at end of 4 took 269.47 s.\n",
      "2024-08-05 16:23:36,402 - base - recpack - INFO - Fitting LightGCNAlgorithm complete - Took 1.37e+03s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/recpack/algorithms/base.py:509: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.model_ = torch.load(self.best_model)\n",
      "/tmp/ipykernel_58233/4206860820.py:81: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  user_indices = torch.tensor(user_indices).to(self.device)\n",
      "/tmp/ipykernel_58233/4206860820.py:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  pos_item_indices = torch.tensor(pos_item_indices).to(self.device)\n",
      "/tmp/ipykernel_58233/4206860820.py:83: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  neg_item_indices = torch.tensor(neg_item_indices).to(self.device).squeeze()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-05 16:28:54,810 - base - recpack - INFO - Processed epoch 0 in 4.22 s.Batch Training Loss = 0.1496\n",
      "2024-08-05 16:33:30,642 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.6693586883867589, which is better than previous iterations.\n",
      "2024-08-05 16:33:30,645 - base - recpack - INFO - Model improved. Storing better model.\n",
      "2024-08-05 16:33:30,761 - base - recpack - INFO - Evaluation at end of 0 took 275.95 s.\n",
      "2024-08-05 16:33:35,163 - base - recpack - INFO - Processed epoch 1 in 4.40 s.Batch Training Loss = 0.0778\n",
      "2024-08-05 16:38:01,922 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.6821232059525119, which is worse than previous iterations.\n",
      "2024-08-05 16:38:02,169 - base - recpack - INFO - Evaluation at end of 1 took 267.00 s.\n",
      "2024-08-05 16:38:06,242 - base - recpack - INFO - Processed epoch 2 in 4.07 s.Batch Training Loss = 0.0703\n",
      "2024-08-05 16:42:37,501 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.7025966763608681, which is worse than previous iterations.\n",
      "2024-08-05 16:42:37,513 - base - recpack - INFO - Evaluation at end of 2 took 271.27 s.\n",
      "2024-08-05 16:42:41,941 - base - recpack - INFO - Processed epoch 3 in 4.43 s.Batch Training Loss = 0.0665\n",
      "2024-08-05 16:47:07,826 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.7101696770986069, which is worse than previous iterations.\n",
      "2024-08-05 16:47:07,837 - base - recpack - INFO - Evaluation at end of 3 took 265.89 s.\n",
      "2024-08-05 16:47:11,898 - base - recpack - INFO - Processed epoch 4 in 4.06 s.Batch Training Loss = 0.0662\n",
      "2024-08-05 16:51:39,008 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.7233262588140094, which is worse than previous iterations.\n",
      "2024-08-05 16:51:39,020 - base - recpack - INFO - Evaluation at end of 4 took 267.12 s.\n",
      "2024-08-05 16:51:39,075 - base - recpack - INFO - Fitting LightGCNAlgorithm complete - Took 1.37e+03s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/recpack/algorithms/base.py:509: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.model_ = torch.load(self.best_model)\n",
      "/tmp/ipykernel_58233/4206860820.py:81: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  user_indices = torch.tensor(user_indices).to(self.device)\n",
      "/tmp/ipykernel_58233/4206860820.py:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  pos_item_indices = torch.tensor(pos_item_indices).to(self.device)\n",
      "/tmp/ipykernel_58233/4206860820.py:83: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  neg_item_indices = torch.tensor(neg_item_indices).to(self.device).squeeze()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-05 16:56:58,083 - base - recpack - INFO - Processed epoch 0 in 4.22 s.Batch Training Loss = 0.4774\n",
      "2024-08-05 17:01:25,427 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.6851879459209809, which is better than previous iterations.\n",
      "2024-08-05 17:01:25,429 - base - recpack - INFO - Model improved. Storing better model.\n",
      "2024-08-05 17:01:25,547 - base - recpack - INFO - Evaluation at end of 0 took 267.46 s.\n",
      "2024-08-05 17:01:29,756 - base - recpack - INFO - Processed epoch 1 in 4.21 s.Batch Training Loss = 0.1482\n",
      "2024-08-05 17:06:01,877 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.6758072182468998, which is worse than previous iterations.\n",
      "2024-08-05 17:06:01,888 - base - recpack - INFO - Evaluation at end of 1 took 272.13 s.\n",
      "2024-08-05 17:06:05,923 - base - recpack - INFO - Processed epoch 2 in 4.03 s.Batch Training Loss = 0.0979\n",
      "2024-08-05 17:10:32,560 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.6702660289970739, which is better than previous iterations.\n",
      "2024-08-05 17:10:32,562 - base - recpack - INFO - Model improved. Storing better model.\n",
      "2024-08-05 17:10:32,697 - base - recpack - INFO - Evaluation at end of 2 took 266.77 s.\n",
      "2024-08-05 17:10:37,036 - base - recpack - INFO - Processed epoch 3 in 4.34 s.Batch Training Loss = 0.0833\n",
      "2024-08-05 17:15:08,075 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.6669881525092127, which is worse than previous iterations.\n",
      "2024-08-05 17:15:08,105 - base - recpack - INFO - Evaluation at end of 3 took 271.07 s.\n",
      "2024-08-05 17:15:12,586 - base - recpack - INFO - Processed epoch 4 in 4.48 s.Batch Training Loss = 0.0762\n",
      "2024-08-05 17:19:36,927 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.6641123088506566, which is worse than previous iterations.\n",
      "2024-08-05 17:19:36,941 - base - recpack - INFO - Evaluation at end of 4 took 264.35 s.\n",
      "2024-08-05 17:19:36,994 - base - recpack - INFO - Fitting LightGCNAlgorithm complete - Took 1.36e+03s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/recpack/algorithms/base.py:509: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.model_ = torch.load(self.best_model)\n",
      "/tmp/ipykernel_58233/4206860820.py:81: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  user_indices = torch.tensor(user_indices).to(self.device)\n",
      "/tmp/ipykernel_58233/4206860820.py:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  pos_item_indices = torch.tensor(pos_item_indices).to(self.device)\n",
      "/tmp/ipykernel_58233/4206860820.py:83: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  neg_item_indices = torch.tensor(neg_item_indices).to(self.device).squeeze()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-05 17:24:55,600 - base - recpack - INFO - Processed epoch 0 in 5.37 s.Batch Training Loss = 0.2422\n",
      "2024-08-05 17:29:21,019 - stopping_criterion - recpack - INFO - StoppingCriterion has value 2.6094804650237604, which is better than previous iterations.\n",
      "2024-08-05 17:29:21,020 - base - recpack - INFO - Model improved. Storing better model.\n",
      "2024-08-05 17:29:21,244 - base - recpack - INFO - Evaluation at end of 0 took 265.64 s.\n",
      "2024-08-05 17:29:25,746 - base - recpack - INFO - Processed epoch 1 in 4.50 s.Batch Training Loss = 0.2328\n",
      "2024-08-05 17:33:54,954 - stopping_criterion - recpack - INFO - StoppingCriterion has value 3.3035740336363344, which is worse than previous iterations.\n",
      "2024-08-05 17:33:54,966 - base - recpack - INFO - Evaluation at end of 1 took 269.22 s.\n",
      "2024-08-05 17:33:59,523 - base - recpack - INFO - Processed epoch 2 in 4.56 s.Batch Training Loss = 0.1898\n",
      "2024-08-05 17:38:27,254 - stopping_criterion - recpack - INFO - StoppingCriterion has value 3.406227278451728, which is worse than previous iterations.\n",
      "2024-08-05 17:38:27,266 - base - recpack - INFO - Evaluation at end of 2 took 267.74 s.\n",
      "2024-08-05 17:38:32,327 - base - recpack - INFO - Processed epoch 3 in 5.06 s.Batch Training Loss = 0.1728\n",
      "2024-08-05 17:42:59,892 - stopping_criterion - recpack - INFO - StoppingCriterion has value 3.677922881352685, which is worse than previous iterations.\n",
      "2024-08-05 17:42:59,945 - base - recpack - INFO - Evaluation at end of 3 took 267.62 s.\n",
      "2024-08-05 17:43:05,403 - base - recpack - INFO - Processed epoch 4 in 5.46 s.Batch Training Loss = 0.1678\n",
      "2024-08-05 17:47:38,453 - stopping_criterion - recpack - INFO - StoppingCriterion has value 3.539219272121837, which is worse than previous iterations.\n",
      "2024-08-05 17:47:38,466 - base - recpack - INFO - Evaluation at end of 4 took 273.06 s.\n",
      "2024-08-05 17:47:38,569 - base - recpack - INFO - Fitting LightGCNAlgorithm complete - Took 1.37e+03s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/recpack/algorithms/base.py:509: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.model_ = torch.load(self.best_model)\n",
      "/tmp/ipykernel_58233/4206860820.py:81: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  user_indices = torch.tensor(user_indices).to(self.device)\n",
      "/tmp/ipykernel_58233/4206860820.py:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  pos_item_indices = torch.tensor(pos_item_indices).to(self.device)\n",
      "/tmp/ipykernel_58233/4206860820.py:83: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  neg_item_indices = torch.tensor(neg_item_indices).to(self.device).squeeze()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-05 17:52:59,882 - base - recpack - INFO - Processed epoch 0 in 6.22 s.Batch Training Loss = 0.1343\n",
      "2024-08-05 17:57:25,116 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.6798937271689557, which is better than previous iterations.\n",
      "2024-08-05 17:57:25,118 - base - recpack - INFO - Model improved. Storing better model.\n",
      "2024-08-05 17:57:25,344 - base - recpack - INFO - Evaluation at end of 0 took 265.46 s.\n",
      "2024-08-05 17:57:31,633 - base - recpack - INFO - Processed epoch 1 in 6.29 s.Batch Training Loss = 0.0759\n",
      "2024-08-05 18:02:02,408 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.7044561421880566, which is worse than previous iterations.\n",
      "2024-08-05 18:02:02,421 - base - recpack - INFO - Evaluation at end of 1 took 270.78 s.\n",
      "2024-08-05 18:02:08,755 - base - recpack - INFO - Processed epoch 2 in 6.33 s.Batch Training Loss = 0.0687\n",
      "2024-08-05 18:06:37,378 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.7208766920204239, which is worse than previous iterations.\n",
      "2024-08-05 18:06:37,392 - base - recpack - INFO - Evaluation at end of 2 took 268.63 s.\n",
      "2024-08-05 18:06:43,898 - base - recpack - INFO - Processed epoch 3 in 6.50 s.Batch Training Loss = 0.0676\n",
      "2024-08-05 18:11:15,991 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.7337560946853472, which is worse than previous iterations.\n",
      "2024-08-05 18:11:16,035 - base - recpack - INFO - Evaluation at end of 3 took 272.13 s.\n",
      "2024-08-05 18:11:22,261 - base - recpack - INFO - Processed epoch 4 in 6.22 s.Batch Training Loss = 0.0639\n",
      "2024-08-05 18:15:52,091 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.7381062886868347, which is worse than previous iterations.\n",
      "2024-08-05 18:15:52,137 - base - recpack - INFO - Evaluation at end of 4 took 269.87 s.\n",
      "2024-08-05 18:15:52,252 - base - recpack - INFO - Fitting LightGCNAlgorithm complete - Took 1.38e+03s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/recpack/algorithms/base.py:509: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.model_ = torch.load(self.best_model)\n",
      "/tmp/ipykernel_58233/4206860820.py:81: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  user_indices = torch.tensor(user_indices).to(self.device)\n",
      "/tmp/ipykernel_58233/4206860820.py:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  pos_item_indices = torch.tensor(pos_item_indices).to(self.device)\n",
      "/tmp/ipykernel_58233/4206860820.py:83: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  neg_item_indices = torch.tensor(neg_item_indices).to(self.device).squeeze()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-05 18:21:12,393 - base - recpack - INFO - Processed epoch 0 in 6.35 s.Batch Training Loss = 0.4009\n",
      "2024-08-05 18:25:39,011 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.6816916252716861, which is better than previous iterations.\n",
      "2024-08-05 18:25:39,014 - base - recpack - INFO - Model improved. Storing better model.\n",
      "2024-08-05 18:25:39,287 - base - recpack - INFO - Evaluation at end of 0 took 266.89 s.\n",
      "2024-08-05 18:25:45,615 - base - recpack - INFO - Processed epoch 1 in 6.33 s.Batch Training Loss = 0.1118\n",
      "2024-08-05 18:30:12,792 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.6718066178344262, which is worse than previous iterations.\n",
      "2024-08-05 18:30:12,843 - base - recpack - INFO - Evaluation at end of 1 took 267.23 s.\n",
      "2024-08-05 18:30:19,179 - base - recpack - INFO - Processed epoch 2 in 6.33 s.Batch Training Loss = 0.0842\n",
      "2024-08-05 18:34:51,835 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.6674325868124197, which is better than previous iterations.\n",
      "2024-08-05 18:34:51,836 - base - recpack - INFO - Model improved. Storing better model.\n",
      "2024-08-05 18:34:52,121 - base - recpack - INFO - Evaluation at end of 2 took 272.94 s.\n",
      "2024-08-05 18:34:58,471 - base - recpack - INFO - Processed epoch 3 in 6.35 s.Batch Training Loss = 0.0771\n",
      "2024-08-05 18:39:29,286 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.6625900583590286, which is worse than previous iterations.\n",
      "2024-08-05 18:39:29,337 - base - recpack - INFO - Evaluation at end of 3 took 270.86 s.\n",
      "2024-08-05 18:39:35,899 - base - recpack - INFO - Processed epoch 4 in 6.56 s.Batch Training Loss = 0.0735\n",
      "2024-08-05 18:44:05,749 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.6620030488465949, which is worse than previous iterations.\n",
      "2024-08-05 18:44:05,799 - base - recpack - INFO - Evaluation at end of 4 took 269.90 s.\n",
      "2024-08-05 18:44:05,902 - base - recpack - INFO - Fitting LightGCNAlgorithm complete - Took 1.38e+03s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/recpack/algorithms/base.py:509: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.model_ = torch.load(self.best_model)\n",
      "/tmp/ipykernel_58233/4206860820.py:81: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  user_indices = torch.tensor(user_indices).to(self.device)\n",
      "/tmp/ipykernel_58233/4206860820.py:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  pos_item_indices = torch.tensor(pos_item_indices).to(self.device)\n",
      "/tmp/ipykernel_58233/4206860820.py:83: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  neg_item_indices = torch.tensor(neg_item_indices).to(self.device).squeeze()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-05 18:49:19,392 - base - recpack - INFO - Processed epoch 0 in 3.16 s.Batch Training Loss = 0.1670\n",
      "2024-08-05 18:53:46,718 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.661989290180028, which is better than previous iterations.\n",
      "2024-08-05 18:53:46,722 - base - recpack - INFO - Model improved. Storing better model.\n",
      "2024-08-05 18:53:46,791 - base - recpack - INFO - Evaluation at end of 0 took 267.40 s.\n",
      "2024-08-05 18:53:49,783 - base - recpack - INFO - Processed epoch 1 in 2.99 s.Batch Training Loss = 0.0773\n",
      "2024-08-05 18:58:21,464 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.6634138281580129, which is worse than previous iterations.\n",
      "2024-08-05 18:58:21,478 - base - recpack - INFO - Evaluation at end of 1 took 271.69 s.\n",
      "2024-08-05 18:58:24,857 - base - recpack - INFO - Processed epoch 2 in 3.38 s.Batch Training Loss = 0.0735\n",
      "2024-08-05 19:02:54,561 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.673988098007243, which is worse than previous iterations.\n",
      "2024-08-05 19:02:54,572 - base - recpack - INFO - Evaluation at end of 2 took 269.71 s.\n",
      "2024-08-05 19:02:57,587 - base - recpack - INFO - Processed epoch 3 in 3.01 s.Batch Training Loss = 0.0684\n",
      "2024-08-05 19:07:26,935 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.6843133613183001, which is worse than previous iterations.\n",
      "2024-08-05 19:07:26,948 - base - recpack - INFO - Evaluation at end of 3 took 269.36 s.\n",
      "2024-08-05 19:07:30,030 - base - recpack - INFO - Processed epoch 4 in 3.08 s.Batch Training Loss = 0.0647\n",
      "2024-08-05 19:11:57,057 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.6980858616440725, which is worse than previous iterations.\n",
      "2024-08-05 19:11:57,070 - base - recpack - INFO - Evaluation at end of 4 took 267.04 s.\n",
      "2024-08-05 19:11:57,108 - base - recpack - INFO - Fitting LightGCNAlgorithm complete - Took 1.36e+03s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/recpack/algorithms/base.py:509: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.model_ = torch.load(self.best_model)\n"
     ]
    }
   ],
   "source": [
    "pipeline_builder = PipelineBuilder()\n",
    "ok = (scenario._validation_data_in, scenario._validation_data_out)\n",
    "pipeline_builder.set_data_from_scenario(scenario)\n",
    "\n",
    "\n",
    "# Add the baseline algorithms\n",
    "#pipeline_builder.add_algorithm('ItemKNN', grid={'K': [100, 200, 400, 800]})\n",
    "#pipeline_builder.add_algorithm('EASE', grid={'l2': [10, 100, 1000], 'alpha': [0, 0.1, 0.5]})\n",
    "\n",
    "# Add our LightGCN algorithm\n",
    "pipeline_builder.add_algorithm(\n",
    "    'LightGCNAlgorithm1',\n",
    "    grid={\n",
    "        'learning_rate': [0.1, 0.01, 0.001],\n",
    "        'embedding_dim': [100, 200, 400]\n",
    "    },\n",
    "    params={\n",
    "        'max_epochs': 5,\n",
    "        'batch_size': 1024,\n",
    "        'n_layers': 3\n",
    "    }\n",
    ")\n",
    "\n",
    "# Add NDCG, Recall, and HR metrics to be evaluated at 10, 20, and 50\n",
    "pipeline_builder.add_metric('NDCGK', [10, 20, 50])\n",
    "pipeline_builder.add_metric('RecallK', [10, 20, 50])\n",
    "pipeline_builder.add_metric('HitK', [10, 20, 50])\n",
    "\n",
    "# Set the optimisation metric\n",
    "pipeline_builder.set_optimisation_metric('RecallK', 20)\n",
    "\n",
    "# Construct pipeline\n",
    "pipeline = pipeline_builder.build()\n",
    "\n",
    "# Debugging: Output the shape of the training data\n",
    "#print(f\"Training data shape: {im.shape}\")\n",
    "\n",
    "# Run pipeline, will first do optimisation, and then evaluation\n",
    "pipeline.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18ace2c0-abce-419e-9b53-5caa21f83b6c",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e80f2784-1ed9-4d93-9883-4c34213d62ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NDCGK_10</th>\n",
       "      <th>NDCGK_20</th>\n",
       "      <th>NDCGK_50</th>\n",
       "      <th>RecallK_10</th>\n",
       "      <th>RecallK_20</th>\n",
       "      <th>RecallK_50</th>\n",
       "      <th>HitK_10</th>\n",
       "      <th>HitK_20</th>\n",
       "      <th>HitK_50</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LightGCNAlgorithm(batch_size=1024,embedding_dim=100,keep_last=False,learning_rate=0.01,max_epochs=5,max_iter_no_change=5,min_improvement=0.01,n_layers=3,predict_topK=None,reg_weight=1e-05,save_best_to_file=False,seed=2672830196,stop_early=True,stopping_criterion=&lt;recpack.algorithms.stopping_criterion.StoppingCriterion object at 0x7fadcc7baa10&gt;,validation_sample_size=None)</th>\n",
       "      <td>0.012028</td>\n",
       "      <td>0.013361</td>\n",
       "      <td>0.015955</td>\n",
       "      <td>0.020156</td>\n",
       "      <td>0.025428</td>\n",
       "      <td>0.038824</td>\n",
       "      <td>0.020156</td>\n",
       "      <td>0.025428</td>\n",
       "      <td>0.038824</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    NDCGK_10  NDCGK_20  \\\n",
       "LightGCNAlgorithm(batch_size=1024,embedding_dim...  0.012028  0.013361   \n",
       "\n",
       "                                                    NDCGK_50  RecallK_10  \\\n",
       "LightGCNAlgorithm(batch_size=1024,embedding_dim...  0.015955    0.020156   \n",
       "\n",
       "                                                    RecallK_20  RecallK_50  \\\n",
       "LightGCNAlgorithm(batch_size=1024,embedding_dim...    0.025428    0.038824   \n",
       "\n",
       "                                                     HitK_10   HitK_20  \\\n",
       "LightGCNAlgorithm(batch_size=1024,embedding_dim...  0.020156  0.025428   \n",
       "\n",
       "                                                     HitK_50  \n",
       "LightGCNAlgorithm(batch_size=1024,embedding_dim...  0.038824  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.get_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06eb89bb-82dc-4982-8025-327b4e25fddb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
