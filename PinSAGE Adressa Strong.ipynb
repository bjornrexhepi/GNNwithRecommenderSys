{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "986478e9-65a3-4298-8193-9817ec01fc4e",
   "metadata": {},
   "source": [
    "# PinSAGE with AddressaOneWeek Dataset and StrongGeneralization Scenario"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9ad2259-81f8-4d70-b569-a0d0a0fe58ec",
   "metadata": {},
   "source": [
    "In this notebook, the implementation of PinSAGE in RecPack and the experimental part to generate the results of the algorithm will be presented. \n",
    "The notebook contains:\n",
    "1. The implementation of PinSAGE in RecPack.\n",
    "2. The 10% of AddressaOneWeek Dataset from RecPack and the StrongGeneralization Scenario has been used to split the data.\n",
    "3. The StrongGeneralization Scenario to split the data.\n",
    "4. The RecPack Pipeline Builder to run the experiments, including the splitted dataset, the algorithms and metrics to run. Hyperparameter has been performed in the Pipeline.\n",
    "\n",
    "Please make sure you have installed all the latest libraries in your Python environment, in order to have a successful run of the code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b269cf-415c-4b5b-84cf-6a85192be87d",
   "metadata": {},
   "source": [
    "## PinSAGE implementation in RecPack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c7dc8a2-fbb5-4309-bb75-7274fd8fd280",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch_sparse import SparseTensor, matmul\n",
    "from recpack.algorithms.base import TorchMLAlgorithm\n",
    "from recpack.matrix.interaction_matrix import InteractionMatrix\n",
    "from recpack.algorithms.loss_functions import bpr_loss, bpr_max_loss\n",
    "from recpack.algorithms.samplers import PositiveNegativeSampler\n",
    "from recpack.matrix.util import to_csr_matrix \n",
    "from scipy.sparse import csr_matrix, lil_matrix\n",
    "from typing import List, Optional\n",
    "import logging\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# PinSAGEConv: A single convolutional layer for the PinSAGE model\n",
    "class PinSAGEConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, dropout=0.0):\n",
    "        \"\"\"\n",
    "        Initialize the PinSAGEConv layer.\n",
    "\n",
    "        Args:\n",
    "            in_channels (int): Number of input channels (dimensions of the input features).\n",
    "            out_channels (int): Number of output channels (dimensions of the output features).\n",
    "            dropout (float): Dropout rate for regularization.\n",
    "        \"\"\"\n",
    "        super(PinSAGEConv, self).__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.dropout = dropout\n",
    "\n",
    "        # Define a linear transformation and a dropout layer\n",
    "        self.linear = nn.Linear(in_channels, out_channels)\n",
    "        self.dropout_layer = nn.Dropout(dropout)\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        \"\"\"\n",
    "        Initialize the parameters of the layer using Xavier uniform initialization.\n",
    "        \"\"\"\n",
    "        nn.init.xavier_uniform_(self.linear.weight)\n",
    "        if self.linear.bias is not None:\n",
    "            nn.init.zeros_(self.linear.bias)\n",
    "\n",
    "    def forward(self, x, graph):\n",
    "        \"\"\"\n",
    "        Forward pass for the PinSAGEConv layer.\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): Input feature matrix.\n",
    "            graph (SparseTensor): Sparse adjacency matrix representing the graph.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Output features after convolution and activation.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            out = matmul(graph, x)  # Perform graph convolution\n",
    "        except RuntimeError as e:\n",
    "            # Log the error and return the input unchanged if the operation fails\n",
    "            # logger.error(f\"matmul failed with error: {e}\")\n",
    "            return x  \n",
    "        out = self.linear(out)\n",
    "        out = torch.relu(out)\n",
    "        out = self.dropout_layer(out)\n",
    "        \n",
    "        return out\n",
    "\n",
    "# PinSAGE: A model implementation based on the PinSAGE algorithm\n",
    "class PinSAGE(nn.Module):\n",
    "    def __init__(self, num_users, num_items, embedding_dim=64, n_layers=2, dropout=0.0):\n",
    "        \"\"\"\n",
    "        Initialize the PinSAGE model.\n",
    "\n",
    "        Args:\n",
    "            num_users (int): Number of users.\n",
    "            num_items (int): Number of items.\n",
    "            embedding_dim (int): Dimension of the embedding vectors.\n",
    "            n_layers (int): Number of PinSAGEConv layers.\n",
    "            dropout (float): Dropout rate for regularization.\n",
    "        \"\"\"\n",
    "        super(PinSAGE, self).__init__()\n",
    "        self.num_users = num_users\n",
    "        self.num_items = num_items\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.n_layers = n_layers\n",
    "        self.dropout = dropout\n",
    "\n",
    "        # Initialize user and item embeddings\n",
    "        self.user_embedding = nn.Embedding(num_users, embedding_dim)\n",
    "        self.item_embedding = nn.Embedding(num_items, embedding_dim)\n",
    "        \n",
    "        # Create a list of PinSAGEConv layers\n",
    "        self.convs = nn.ModuleList([\n",
    "            PinSAGEConv(embedding_dim, embedding_dim, dropout) for _ in range(n_layers)\n",
    "        ])\n",
    "        \n",
    "        # Final linear layers for users and items\n",
    "        self.user_final_linear = nn.Linear(embedding_dim, embedding_dim)\n",
    "        self.item_final_linear = nn.Linear(embedding_dim, embedding_dim)\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        \"\"\"\n",
    "        Initialize the parameters of the model using Xavier uniform initialization.\n",
    "        \"\"\"\n",
    "        nn.init.xavier_uniform_(self.user_embedding.weight)\n",
    "        nn.init.xavier_uniform_(self.item_embedding.weight)\n",
    "        nn.init.xavier_uniform_(self.user_final_linear.weight)\n",
    "        nn.init.xavier_uniform_(self.item_final_linear.weight)\n",
    "\n",
    "    def forward(self, graph):\n",
    "        \"\"\"\n",
    "        Forward pass for the PinSAGE model.\n",
    "\n",
    "        Args:\n",
    "            graph (SparseTensor): Sparse adjacency matrix representing the graph.\n",
    "\n",
    "        Returns:\n",
    "            Tuple[torch.Tensor, torch.Tensor]: Final user and item embeddings.\n",
    "        \"\"\"\n",
    "        user_emb = self.user_embedding.weight\n",
    "        item_emb = self.item_embedding.weight\n",
    "        \n",
    "        # Concatenate user and item embeddings\n",
    "        all_emb = torch.cat([user_emb, item_emb], dim=0)\n",
    "        embs = [all_emb]\n",
    "\n",
    "        # Pass through each PinSAGEConv layer\n",
    "        for conv in self.convs:\n",
    "            all_emb = conv(all_emb, graph)\n",
    "            embs.append(all_emb)\n",
    "\n",
    "        # Compute the final embeddings by averaging the embeddings across layers\n",
    "        final_embedding = torch.mean(torch.stack(embs, dim=1), dim=1)\n",
    "        user_emb_final, item_emb_final = torch.split(final_embedding, [self.num_users, self.num_items])\n",
    "        \n",
    "        # Separate final transformations for users and items\n",
    "        final_user_emb = torch.relu(self.user_final_linear(user_emb_final))\n",
    "        final_item_emb = torch.relu(self.item_final_linear(item_emb_final))\n",
    "\n",
    "        # Normalize final embeddings\n",
    "        final_user_emb = final_user_emb / torch.norm(final_user_emb, p=2, dim=1, keepdim=True)\n",
    "        final_item_emb = final_item_emb / torch.norm(final_item_emb, p=2, dim=1, keepdim=True)\n",
    "\n",
    "        return final_user_emb, final_item_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "383f2777-5652-4d39-a111-9f8f71865f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from recpack.algorithms.base import TorchMLAlgorithm\n",
    "from recpack.matrix import Matrix\n",
    "from recpack.matrix.interaction_matrix import InteractionMatrix\n",
    "from recpack.algorithms.loss_functions import bpr_loss\n",
    "from recpack.algorithms.samplers import PositiveNegativeSampler\n",
    "from recpack.algorithms.stopping_criterion import (\n",
    "    EarlyStoppingException,\n",
    "    StoppingCriterion,\n",
    ")\n",
    "from typing import List, Tuple, Optional\n",
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix, lil_matrix, coo_matrix\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import tempfile\n",
    "import time\n",
    "import logging\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# PinSAGEAlgorithm: An implementation of the PinSAGE algorithm using TorchMLAlgorithm as a base class\n",
    "class PinSAGEAlgorithm(TorchMLAlgorithm):\n",
    "    def __init__(\n",
    "        self,\n",
    "        batch_size: int = 256,\n",
    "        max_epochs: int = 100,\n",
    "        learning_rate: float = 0.001,\n",
    "        embedding_dim: int = 64,\n",
    "        n_layers: int = 3,\n",
    "        dropout: float = 0.1,\n",
    "        stopping_criterion: str = \"bpr\",\n",
    "        stop_early: bool = True,\n",
    "        max_iter_no_change: int = 5,\n",
    "        min_improvement: float = 0.01,\n",
    "        seed: Optional[int] = None,\n",
    "        save_best_to_file: bool = False,\n",
    "        keep_last: bool = False,\n",
    "        predict_topK: Optional[int] = None,\n",
    "        validation_sample_size: Optional[int] = None,\n",
    "        grad_clip: float = 1.0,  # Gradient clipping value\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Initialize the PinSAGEAlgorithm with various hyperparameters.\n",
    "\n",
    "        Args:\n",
    "            batch_size (int): Number of samples per batch.\n",
    "            max_epochs (int): Maximum number of training epochs.\n",
    "            learning_rate (float): Learning rate for the optimizer.\n",
    "            embedding_dim (int): Dimension of the embedding vectors.\n",
    "            n_layers (int): Number of PinSAGEConv layers.\n",
    "            dropout (float): Dropout rate for regularization.\n",
    "            stopping_criterion (str): Criterion to stop training early.\n",
    "            stop_early (bool): Whether to enable early stopping.\n",
    "            max_iter_no_change (int): Maximum iterations with no improvement for early stopping.\n",
    "            min_improvement (float): Minimum improvement required for early stopping.\n",
    "            seed (Optional[int]): Random seed for reproducibility.\n",
    "            save_best_to_file (bool): Whether to save the best model to a file.\n",
    "            keep_last (bool): Whether to keep the last model.\n",
    "            predict_topK (Optional[int]): Number of top-K predictions to consider.\n",
    "            validation_sample_size (Optional[int]): Size of the validation sample.\n",
    "            grad_clip (float): Maximum gradient norm for clipping.\n",
    "        \"\"\"\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.n_layers = n_layers\n",
    "        self.dropout = dropout\n",
    "        self.grad_clip = grad_clip\n",
    "        super().__init__(\n",
    "            batch_size=batch_size,\n",
    "            max_epochs=max_epochs,\n",
    "            learning_rate=learning_rate,\n",
    "            stopping_criterion=stopping_criterion,\n",
    "            stop_early=stop_early,\n",
    "            max_iter_no_change=max_iter_no_change,\n",
    "            min_improvement=min_improvement,\n",
    "            seed=seed,\n",
    "            save_best_to_file=save_best_to_file,\n",
    "            keep_last=keep_last,\n",
    "            predict_topK=predict_topK,\n",
    "            validation_sample_size=validation_sample_size,\n",
    "        )\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    def _init_model(self, train: InteractionMatrix) -> None:\n",
    "        \"\"\"\n",
    "        Initialize the PinSAGE model and optimizer.\n",
    "\n",
    "        Args:\n",
    "            train (InteractionMatrix): The training interaction matrix.\n",
    "        \"\"\"\n",
    "        num_users, num_items = train.shape\n",
    "        self.model_ = PinSAGE(num_users, num_items, self.embedding_dim, self.n_layers, self.dropout).to(self.device)\n",
    "        self.optimizer = optim.Adam(self.model_.parameters(), lr=self.learning_rate)\n",
    "\n",
    "    def _create_sparse_graph(self, interaction_matrix: csr_matrix, num_users: int, num_items: int) -> SparseTensor:\n",
    "        \"\"\"\n",
    "        Create a sparse graph from the interaction matrix.\n",
    "\n",
    "        Args:\n",
    "            interaction_matrix (csr_matrix): The interaction matrix in CSR format.\n",
    "            num_users (int): Number of users.\n",
    "            num_items (int): Number of items.\n",
    "\n",
    "        Returns:\n",
    "            SparseTensor: A sparse tensor representing the graph.\n",
    "        \"\"\"\n",
    "        coo = interaction_matrix.tocoo()\n",
    "        row = torch.tensor(coo.row, dtype=torch.long)\n",
    "        col = torch.tensor(coo.col, dtype=torch.long)\n",
    "        value = torch.tensor(coo.data, dtype=torch.float32)\n",
    "        shape = (num_users + num_items, num_users + num_items)\n",
    "        graph = SparseTensor(row=row, col=col, value=value, sparse_sizes=shape).to(self.device)\n",
    "        return graph\n",
    "\n",
    "    def _train_epoch(self, train: InteractionMatrix) -> List[float]:\n",
    "        \"\"\"\n",
    "        Train the model for one epoch.\n",
    "\n",
    "        Args:\n",
    "            train (InteractionMatrix): The training interaction matrix.\n",
    "\n",
    "        Returns:\n",
    "            List[float]: A list of losses for each batch.\n",
    "        \"\"\"\n",
    "        self.model_.train()\n",
    "        interaction_matrix = train  # Get the sparse matrix directly\n",
    "        graph = self._create_sparse_graph(interaction_matrix, train.shape[0], train.shape[1])\n",
    "        total_loss = 0\n",
    "        losses = []\n",
    "\n",
    "        sampler = PositiveNegativeSampler(num_negatives=1, batch_size=self.batch_size)\n",
    "\n",
    "        # Iterate over samples generated by the PositiveNegativeSampler\n",
    "        for user_indices, pos_item_indices, neg_item_indices in sampler.sample(interaction_matrix):\n",
    "            user_indices = torch.tensor(user_indices).to(self.device)\n",
    "            pos_item_indices = torch.tensor(pos_item_indices).to(self.device)\n",
    "            neg_item_indices = torch.tensor(neg_item_indices).to(self.device).squeeze()\n",
    "\n",
    "            self.optimizer.zero_grad()\n",
    "            user_emb_final, item_emb_final = self.model_(graph)  # Call model only once\n",
    "            pos_scores = user_emb_final[user_indices] @ item_emb_final[pos_item_indices].t()\n",
    "            neg_scores = user_emb_final[user_indices] @ item_emb_final[neg_item_indices].t()\n",
    "\n",
    "            loss = bpr_loss(pos_scores, neg_scores)\n",
    "\n",
    "            if torch.isnan(loss).any() or torch.isinf(loss).any():\n",
    "                continue\n",
    "\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(self.model_.parameters(), max_norm=self.grad_clip)  # Gradient clipping\n",
    "            self.optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            losses.append(loss.item())\n",
    "\n",
    "        if len(losses) == 0:\n",
    "            return [float('nan')]\n",
    "\n",
    "        return losses\n",
    "\n",
    "    def _batch_predict(self, X: InteractionMatrix, users: List[int]) -> csr_matrix:\n",
    "        \"\"\"\n",
    "        Make batch predictions for a list of users.\n",
    "\n",
    "        Args:\n",
    "            X (InteractionMatrix): The interaction matrix.\n",
    "            users (List[int]): List of user indices to make predictions for.\n",
    "\n",
    "        Returns:\n",
    "            csr_matrix: A sparse matrix with the prediction scores.\n",
    "        \"\"\"\n",
    "        self.model_.eval()\n",
    "        graph = self._create_sparse_graph(X, X.shape[0], X.shape[1])\n",
    "        user_indices = torch.tensor(users).to(self.device)\n",
    "        item_indices = torch.arange(X.shape[1]).to(self.device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            user_emb_final, item_emb_final = self.model_(graph)\n",
    "            scores = user_emb_final[user_indices] @ item_emb_final.t()\n",
    "            scores = scores.cpu().numpy()\n",
    "        \n",
    "        result = lil_matrix((X.shape[0], X.shape[1]))\n",
    "        for i, user in enumerate(users):\n",
    "            result[user] = scores[i]\n",
    "        \n",
    "        return result.tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e87fd90c-f8ae-4fcc-a455-90fb8f2335c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from recpack.datasets import Netflix, DummyDataset\n",
    "from recpack.pipelines import PipelineBuilder\n",
    "from recpack.scenarios import StrongGeneralization\n",
    "from recpack.pipelines import ALGORITHM_REGISTRY\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "03a047ff-a58e-4ffb-bb09-247622834b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "ALGORITHM_REGISTRY.register(\"PinSAGEAlgorithm2\", PinSAGEAlgorithm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "457f44b0-5fee-4ab6-ab5e-fed34f3f8082",
   "metadata": {},
   "source": [
    "## RecPack Dataset Importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "288305e2-e570-4286-8468-c902e9d7ca25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from recpack.datasets import AdressaOneWeek\n",
    "dataset = AdressaOneWeek()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9c73499f-1c14-4241-a0bd-e3412b4efd34",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.fetch_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "25bb2d15-0f4f-4142-8d5d-e06a6ea3c024",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<recpack.datasets.adressa.AdressaOneWeek at 0x7fea4dd5bd10>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a290f199-0a3d-4c2b-bc30-c82b5254ab34",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dataset._load_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e4eef56-e9ff-4dfe-8c6b-27ab088b5ef4",
   "metadata": {},
   "source": [
    "## Datasets with Timestamps sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "66ac1379-2266-4bec-b6d3-9cf22c1aaedf",
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp_counts = df['time'].value_counts().sort_index(ascending=False)\n",
    "cumulative_counts = timestamp_counts.cumsum()\n",
    "total_counts = cumulative_counts.max()\n",
    "threshold_count = total_counts * 0.1\n",
    "threshold_timestamp = cumulative_counts[cumulative_counts >= threshold_count].index[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a8b54ee9-8024-4d18-89c8-7858f45d7906",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = df[df['time'] >= threshold_timestamp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "877cfa8a-c9d3-4436-8a74-5009b026f266",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>id</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cx:2fs9x8i7jvcjyckoxqfa6l4lw:3rr1gvpcbzx8w</td>\n",
       "      <td>9f3999bd1a1a8d67bcb073ad54840f15cb30f014</td>\n",
       "      <td>1483225202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cx:2u0wp23pfgjcc12gorbv6mp6tp:1l4jele4s191</td>\n",
       "      <td>f21680b77830223807e4847b3307e6ffa1e175ed</td>\n",
       "      <td>1483225203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cx:kfubh0ub7g8z3g5mgndoaljqd:1w4rvohza6x7d</td>\n",
       "      <td>2607fc7d7b4c0ede839a5ff6d499fa428237443e</td>\n",
       "      <td>1483225203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cx:hua808o791zl6cx9:3s9kdckn8su34</td>\n",
       "      <td>68d1503c73ad169dcfff48214fd0274c4d612e63</td>\n",
       "      <td>1483225204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cx:1s8dobcz77bgl3jozo9wdodu0t:2h45sh9wqlrpp</td>\n",
       "      <td>68d1503c73ad169dcfff48214fd0274c4d612e63</td>\n",
       "      <td>1483225207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3101986</th>\n",
       "      <td>cx:9k87jvj35ts82aloy49wfxosg:952wl4r7sedv</td>\n",
       "      <td>d26dae18a47ee499c4aaca4a9b6017f1b5b1da13</td>\n",
       "      <td>1483830000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3101987</th>\n",
       "      <td>cx:ikird5ho7t08hlc6:2n6k9bd2ntk6v</td>\n",
       "      <td>8a3d76e1d7452ce38ae70fe900a9952be4305c63</td>\n",
       "      <td>1483830000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3101988</th>\n",
       "      <td>cx:2ry3bd6yl2fbb3mq9zs5cl4zvc:9oicxykjoyvo</td>\n",
       "      <td>faa8cc5200499acbf0f23f6b8e8f78b2b55d2c60</td>\n",
       "      <td>1483830001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3101989</th>\n",
       "      <td>cx:3c83unb96kkua3kw8jnflgge0n:1au0d7qhme3j5</td>\n",
       "      <td>4d44e61d966ed5a2c8b70a95eb9948aa2a10696f</td>\n",
       "      <td>1483830001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3101990</th>\n",
       "      <td>cx:iolu0een5wf8whla:1gtj0r7yyqtm8</td>\n",
       "      <td>64ae4a1db60e066701aa444bc0af2f8f3dbcda3f</td>\n",
       "      <td>1483830001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3101991 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              userId  \\\n",
       "0         cx:2fs9x8i7jvcjyckoxqfa6l4lw:3rr1gvpcbzx8w   \n",
       "1         cx:2u0wp23pfgjcc12gorbv6mp6tp:1l4jele4s191   \n",
       "2         cx:kfubh0ub7g8z3g5mgndoaljqd:1w4rvohza6x7d   \n",
       "3                  cx:hua808o791zl6cx9:3s9kdckn8su34   \n",
       "4        cx:1s8dobcz77bgl3jozo9wdodu0t:2h45sh9wqlrpp   \n",
       "...                                              ...   \n",
       "3101986    cx:9k87jvj35ts82aloy49wfxosg:952wl4r7sedv   \n",
       "3101987            cx:ikird5ho7t08hlc6:2n6k9bd2ntk6v   \n",
       "3101988   cx:2ry3bd6yl2fbb3mq9zs5cl4zvc:9oicxykjoyvo   \n",
       "3101989  cx:3c83unb96kkua3kw8jnflgge0n:1au0d7qhme3j5   \n",
       "3101990            cx:iolu0een5wf8whla:1gtj0r7yyqtm8   \n",
       "\n",
       "                                               id        time  \n",
       "0        9f3999bd1a1a8d67bcb073ad54840f15cb30f014  1483225202  \n",
       "1        f21680b77830223807e4847b3307e6ffa1e175ed  1483225203  \n",
       "2        2607fc7d7b4c0ede839a5ff6d499fa428237443e  1483225203  \n",
       "3        68d1503c73ad169dcfff48214fd0274c4d612e63  1483225204  \n",
       "4        68d1503c73ad169dcfff48214fd0274c4d612e63  1483225207  \n",
       "...                                           ...         ...  \n",
       "3101986  d26dae18a47ee499c4aaca4a9b6017f1b5b1da13  1483830000  \n",
       "3101987  8a3d76e1d7452ce38ae70fe900a9952be4305c63  1483830000  \n",
       "3101988  faa8cc5200499acbf0f23f6b8e8f78b2b55d2c60  1483830001  \n",
       "3101989  4d44e61d966ed5a2c8b70a95eb9948aa2a10696f  1483830001  \n",
       "3101990  64ae4a1db60e066701aa444bc0af2f8f3dbcda3f  1483830001  \n",
       "\n",
       "[3101991 rows x 3 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "75315c82-bb45-4090-8d92-87e16d42f204",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>id</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2791789</th>\n",
       "      <td>cx:2ren7oax3ikx1126uc6379p1m1:1ilgu73jr9354</td>\n",
       "      <td>9da08a8be1d6cf85b0c7cd3f40b774cba66960b8</td>\n",
       "      <td>1483745358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2791790</th>\n",
       "      <td>cx:13573746954421111340278:21n4bwo3o22w3</td>\n",
       "      <td>f28b18132dfe141356c778b1909f13fcded3c613</td>\n",
       "      <td>1483745358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2791791</th>\n",
       "      <td>cx:ehi4yx5vak421bv2uzvm0hz9m:2tfkglwogbje9</td>\n",
       "      <td>bb8ff8365233ea91dfcdb36fdd84f87fcc33e1a8</td>\n",
       "      <td>1483745358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2791792</th>\n",
       "      <td>cx:imiu917sfw8scsba:2b3kfu5odsixi</td>\n",
       "      <td>9de2fd10200602037cc938b038a0f7d3d5f8fb76</td>\n",
       "      <td>1483745359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2791793</th>\n",
       "      <td>cx:hu9xqbxb2q1op1a2:2bvkrtdex7gri</td>\n",
       "      <td>17a7ea777cb261130668d4314b1591f3767cd090</td>\n",
       "      <td>1483745359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3101986</th>\n",
       "      <td>cx:9k87jvj35ts82aloy49wfxosg:952wl4r7sedv</td>\n",
       "      <td>d26dae18a47ee499c4aaca4a9b6017f1b5b1da13</td>\n",
       "      <td>1483830000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3101987</th>\n",
       "      <td>cx:ikird5ho7t08hlc6:2n6k9bd2ntk6v</td>\n",
       "      <td>8a3d76e1d7452ce38ae70fe900a9952be4305c63</td>\n",
       "      <td>1483830000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3101988</th>\n",
       "      <td>cx:2ry3bd6yl2fbb3mq9zs5cl4zvc:9oicxykjoyvo</td>\n",
       "      <td>faa8cc5200499acbf0f23f6b8e8f78b2b55d2c60</td>\n",
       "      <td>1483830001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3101989</th>\n",
       "      <td>cx:3c83unb96kkua3kw8jnflgge0n:1au0d7qhme3j5</td>\n",
       "      <td>4d44e61d966ed5a2c8b70a95eb9948aa2a10696f</td>\n",
       "      <td>1483830001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3101990</th>\n",
       "      <td>cx:iolu0een5wf8whla:1gtj0r7yyqtm8</td>\n",
       "      <td>64ae4a1db60e066701aa444bc0af2f8f3dbcda3f</td>\n",
       "      <td>1483830001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>310202 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              userId  \\\n",
       "2791789  cx:2ren7oax3ikx1126uc6379p1m1:1ilgu73jr9354   \n",
       "2791790     cx:13573746954421111340278:21n4bwo3o22w3   \n",
       "2791791   cx:ehi4yx5vak421bv2uzvm0hz9m:2tfkglwogbje9   \n",
       "2791792            cx:imiu917sfw8scsba:2b3kfu5odsixi   \n",
       "2791793            cx:hu9xqbxb2q1op1a2:2bvkrtdex7gri   \n",
       "...                                              ...   \n",
       "3101986    cx:9k87jvj35ts82aloy49wfxosg:952wl4r7sedv   \n",
       "3101987            cx:ikird5ho7t08hlc6:2n6k9bd2ntk6v   \n",
       "3101988   cx:2ry3bd6yl2fbb3mq9zs5cl4zvc:9oicxykjoyvo   \n",
       "3101989  cx:3c83unb96kkua3kw8jnflgge0n:1au0d7qhme3j5   \n",
       "3101990            cx:iolu0een5wf8whla:1gtj0r7yyqtm8   \n",
       "\n",
       "                                               id        time  \n",
       "2791789  9da08a8be1d6cf85b0c7cd3f40b774cba66960b8  1483745358  \n",
       "2791790  f28b18132dfe141356c778b1909f13fcded3c613  1483745358  \n",
       "2791791  bb8ff8365233ea91dfcdb36fdd84f87fcc33e1a8  1483745358  \n",
       "2791792  9de2fd10200602037cc938b038a0f7d3d5f8fb76  1483745359  \n",
       "2791793  17a7ea777cb261130668d4314b1591f3767cd090  1483745359  \n",
       "...                                           ...         ...  \n",
       "3101986  d26dae18a47ee499c4aaca4a9b6017f1b5b1da13  1483830000  \n",
       "3101987  8a3d76e1d7452ce38ae70fe900a9952be4305c63  1483830000  \n",
       "3101988  faa8cc5200499acbf0f23f6b8e8f78b2b55d2c60  1483830001  \n",
       "3101989  4d44e61d966ed5a2c8b70a95eb9948aa2a10696f  1483830001  \n",
       "3101990  64ae4a1db60e066701aa444bc0af2f8f3dbcda3f  1483830001  \n",
       "\n",
       "[310202 rows x 3 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6364e33d-9a6f-44b5-85bb-334c23a1ae62",
   "metadata": {},
   "source": [
    "## Dataset Preprocessing to Interaction Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b1803c48-66d4-4256-8fbe-89bc65fa85ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f186af5ded2c47e59bf13c9129c6269f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/310202 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a04f729df1a4cbdb35fd71ad4c7ab5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/310202 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from recpack.matrix import InteractionMatrix\n",
    "from recpack.preprocessing.preprocessors import DataFramePreprocessor\n",
    "\n",
    "item_ix = 'id'\n",
    "user_ix = 'userId'\n",
    "timestamp_ix = 'time'\n",
    "\n",
    "preprocessor = DataFramePreprocessor(item_ix=item_ix, user_ix=user_ix, timestamp_ix=timestamp_ix)\n",
    "\n",
    "interaction_matrix = preprocessor.process(filtered_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83c6dd74-5059-48c5-8ec4-078fd3d864f2",
   "metadata": {},
   "source": [
    "## StrongGeneralization Scenario Splitting of Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "73d22b62-213c-4ac4-9346-70414e7c39db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([13123.,  3503.,  5846., 29171., 35780., 42317., 45759., 47552.,\n",
       "        38200., 48951.]),\n",
       " array([1.48374536e+09, 1.48375382e+09, 1.48376229e+09, 1.48377075e+09,\n",
       "        1.48377922e+09, 1.48378768e+09, 1.48379614e+09, 1.48380461e+09,\n",
       "        1.48381307e+09, 1.48382154e+09, 1.48383000e+09]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjoAAAGvCAYAAABSC3+tAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/TGe4hAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAvZUlEQVR4nO3dfVDU9cL//xeCrEiwgQTbKpUVl2moV1GDmCfsqKCBdOWZ0cRrrzyZ5TFvKM2baiZPc4540qzTcSy7Ge2kRXONWk4Wgecyk/E2jHO87ZbyDsRyWdRwIXz//ujn53tWTEMz4t3zMbMz7efz2s++9/PO4cWb3c+GGWOMAAAALNSutQcAAABwsVB0AACAtSg6AADAWhQdAABgLYoOAACwFkUHAABYi6IDAACsRdEBAADWimjtAbSmkydP6uDBg4qJiVFYWFhrDwcAAPwIxhgdPXpUXq9X7dqdfc3mV110Dh48qOTk5NYeBgAAOA/79u1Tly5dzpr5VRedmJgYSd+fqNjY2FYeDQAA+DHq6uqUnJzs/Bw/m1910Tn156rY2FiKDgAAbcyPedsJb0YGAADWougAAABrUXQAAIC1WlR0Zs2apbCwsJCbx+Nx9htjNGvWLHm9XkVFRal///7auXNnyDGCwaAmTpyohIQERUdHKy8vT/v37w/J+P1++Xw+ud1uud1u+Xw+1dbWhmT27t2roUOHKjo6WgkJCZo0aZIaGhpa+PIBAIDNWryic/3116uqqsq5bd++3dn35JNPav78+VqwYIG2bt0qj8ejQYMG6ejRo06moKBAK1euVFFRkcrKynTs2DHl5uaqqanJyeTn56uiokLFxcUqLi5WRUWFfD6fs7+pqUk5OTk6fvy4ysrKVFRUpOXLl2vKlCnnex4AAICNTAs8/vjjpnfv3mfcd/LkSePxeMycOXOcbSdOnDBut9s8//zzxhhjamtrTfv27U1RUZGTOXDggGnXrp0pLi42xhiza9cuI8ls2rTJyWzcuNFIMnv27DHGGPPOO++Ydu3amQMHDjiZ119/3bhcLhMIBH706wkEAkZSix4DAABaV0t+frd4RefTTz+V1+tV165dddddd+mLL76QJFVWVqq6ulpZWVlO1uVyKTMzUxs2bJAklZeXq7GxMSTj9XqVmprqZDZu3Ci326309HQn06dPH7nd7pBMamqqvF6vk8nOzlYwGFR5efkPjj0YDKquri7kBgAA7NWiopOenq6///3veu+99/Tiiy+qurpaffv21TfffKPq6mpJUlJSUshjkpKSnH3V1dWKjIxUXFzcWTOJiYnNnjsxMTEkc/rzxMXFKTIy0smcSWFhofO+H7fbzVWRAQCwXIuKzpAhQ/S73/1OPXv21MCBA7V69WpJ0iuvvOJkTr94jzHmnBf0OT1zpvz5ZE43c+ZMBQIB57Zv376zjgsAALRtF/Tx8ujoaPXs2VOffvqp8+mr01dUampqnNUXj8ejhoYG+f3+s2YOHTrU7LkOHz4ckjn9efx+vxobG5ut9Pw7l8vlXAWZqyEDAGC/Cyo6wWBQu3fv1uWXX66uXbvK4/GotLTU2d/Q0KB169apb9++kqS0tDS1b98+JFNVVaUdO3Y4mYyMDAUCAW3ZssXJbN68WYFAICSzY8cOVVVVOZmSkhK5XC6lpaVdyEsCAAAWadF3XU2dOlVDhw7VFVdcoZqaGv3pT39SXV2d7r77boWFhamgoECzZ89WSkqKUlJSNHv2bHXs2FH5+fmSJLfbrTFjxmjKlCnq1KmT4uPjNXXqVOdPYZLUvXt3DR48WGPHjtWiRYskSffdd59yc3PVrVs3SVJWVpZ69Oghn8+nuXPn6siRI5o6darGjh3LKg0AAHC0qOjs379fI0eO1Ndff63LLrtMffr00aZNm3TllVdKkqZNm6b6+nqNHz9efr9f6enpKikpCfl20aeffloREREaPny46uvrNWDAAC1ZskTh4eFOZtmyZZo0aZLz6ay8vDwtWLDA2R8eHq7Vq1dr/PjxuuWWWxQVFaX8/HzNmzfvgk4GAACwS5gxxrT2IFpLXV2d3G63AoEAK0EAALQRLfn53aIVHQAA0DqumrG6tYdwXr6ck9Oqz8+XegIAAGtRdAAAgLUoOgAAwFoUHQAAYC2KDgAAsBZFBwAAWIuiAwAArEXRAQAA1qLoAAAAa3FlZADABWmLV+xt7av14ufDig4AALAWRQcAAFiLogMAAKxF0QEAANai6AAAAGtRdAAAgLUoOgAAwFoUHQAAYC2KDgAAsBZFBwAAWIuiAwAArEXRAQAA1uJLPQHgF6QtfkEm8EvGig4AALAWRQcAAFiLogMAAKxF0QEAANai6AAAAGtRdAAAgLUoOgAAwFoUHQAAYC2KDgAAsBZFBwAAWIuiAwAArEXRAQAA1qLoAAAAa1F0AACAtSg6AADAWhQdAABgLYoOAACwFkUHAABYi6IDAACsRdEBAADWougAAABrUXQAAIC1KDoAAMBaFB0AAGCtiNYeAABcLFfNWN3aQwDQyljRAQAA1qLoAAAAa1F0AACAtSg6AADAWhQdAABgLYoOAACwFkUHAABYi6IDAACsRdEBAADWougAAABrUXQAAIC1LqjoFBYWKiwsTAUFBc42Y4xmzZolr9erqKgo9e/fXzt37gx5XDAY1MSJE5WQkKDo6Gjl5eVp//79IRm/3y+fzye32y232y2fz6fa2tqQzN69ezV06FBFR0crISFBkyZNUkNDw4W8JAAAYJHzLjpbt27VCy+8oF69eoVsf/LJJzV//nwtWLBAW7dulcfj0aBBg3T06FEnU1BQoJUrV6qoqEhlZWU6duyYcnNz1dTU5GTy8/NVUVGh4uJiFRcXq6KiQj6fz9nf1NSknJwcHT9+XGVlZSoqKtLy5cs1ZcqU831JAADAMudVdI4dO6ZRo0bpxRdfVFxcnLPdGKNnnnlGjz76qIYNG6bU1FS98sor+vbbb/Xaa69JkgKBgF5++WU99dRTGjhwoG644QYtXbpU27dv15o1ayRJu3fvVnFxsV566SVlZGQoIyNDL774ot5++219/PHHkqSSkhLt2rVLS5cu1Q033KCBAwfqqaee0osvvqi6uroLPS8AAMAC51V0HnjgAeXk5GjgwIEh2ysrK1VdXa2srCxnm8vlUmZmpjZs2CBJKi8vV2NjY0jG6/UqNTXVyWzcuFFut1vp6elOpk+fPnK73SGZ1NRUeb1eJ5Odna1gMKjy8vIzjjsYDKquri7kBgAA7BXR0gcUFRVp27Zt2rp1a7N91dXVkqSkpKSQ7UlJSfrqq6+cTGRkZMhK0KnMqcdXV1crMTGx2fETExNDMqc/T1xcnCIjI53M6QoLC/XHP/7xx7xMAABggRat6Ozbt0+TJ0/W0qVL1aFDhx/MhYWFhdw3xjTbdrrTM2fKn0/m382cOVOBQMC57du376xjAgAAbVuLik55eblqamqUlpamiIgIRUREaN26dXr22WcVERHhrLCcvqJSU1Pj7PN4PGpoaJDf7z9r5tChQ82e//DhwyGZ05/H7/ersbGx2UrPKS6XS7GxsSE3AABgrxYVnQEDBmj79u2qqKhwbjfddJNGjRqliooKXX311fJ4PCotLXUe09DQoHXr1qlv376SpLS0NLVv3z4kU1VVpR07djiZjIwMBQIBbdmyxcls3rxZgUAgJLNjxw5VVVU5mZKSErlcLqWlpZ3HqQAAALZp0Xt0YmJilJqaGrItOjpanTp1crYXFBRo9uzZSklJUUpKimbPnq2OHTsqPz9fkuR2uzVmzBhNmTJFnTp1Unx8vKZOnaqePXs6b27u3r27Bg8erLFjx2rRokWSpPvuu0+5ubnq1q2bJCkrK0s9evSQz+fT3LlzdeTIEU2dOlVjx45lpQYAAEg6jzcjn8u0adNUX1+v8ePHy+/3Kz09XSUlJYqJiXEyTz/9tCIiIjR8+HDV19drwIABWrJkicLDw53MsmXLNGnSJOfTWXl5eVqwYIGzPzw8XKtXr9b48eN1yy23KCoqSvn5+Zo3b95P/ZIAAEAbFWaMMa09iNZSV1cnt9utQCDAKhBgoatmrG7tIeAX6ss5Oa09hBZrq/8/X4xz3ZKf33zXFQAAsBZFBwAAWIuiAwAArEXRAQAA1qLoAAAAa1F0AACAtX7y6+gAAPBL11Y/qo2WY0UHAABYi6IDAACsRdEBAADWougAAABrUXQAAIC1KDoAAMBaFB0AAGAtig4AALAWRQcAAFiLogMAAKxF0QEAANai6AAAAGtRdAAAgLUoOgAAwFoUHQAAYC2KDgAAsBZFBwAAWCuitQcAoG24asbq1h4CALQYKzoAAMBaFB0AAGAtig4AALAWRQcAAFiLogMAAKxF0QEAANai6AAAAGtRdAAAgLUoOgAAwFoUHQAAYC2KDgAAsBZFBwAAWIuiAwAArEXRAQAA1qLoAAAAa1F0AACAtSg6AADAWhQdAABgLYoOAACwFkUHAABYi6IDAACsRdEBAADWougAAABrUXQAAIC1KDoAAMBaFB0AAGAtig4AALAWRQcAAFiLogMAAKxF0QEAANai6AAAAGtRdAAAgLUoOgAAwFoUHQAAYC2KDgAAsBZFBwAAWKtFRee5555Tr169FBsbq9jYWGVkZOjdd9919htjNGvWLHm9XkVFRal///7auXNnyDGCwaAmTpyohIQERUdHKy8vT/v37w/J+P1++Xw+ud1uud1u+Xw+1dbWhmT27t2roUOHKjo6WgkJCZo0aZIaGhpa+PIBAIDNWlR0unTpojlz5ujDDz/Uhx9+qN/+9re64447nDLz5JNPav78+VqwYIG2bt0qj8ejQYMG6ejRo84xCgoKtHLlShUVFamsrEzHjh1Tbm6umpqanEx+fr4qKipUXFys4uJiVVRUyOfzOfubmpqUk5Oj48ePq6ysTEVFRVq+fLmmTJlyoecDAABYJMwYYy7kAPHx8Zo7d67uueceeb1eFRQUaPr06ZK+X71JSkrSX/7yF91///0KBAK67LLL9Oqrr2rEiBGSpIMHDyo5OVnvvPOOsrOztXv3bvXo0UObNm1Senq6JGnTpk3KyMjQnj171K1bN7377rvKzc3Vvn375PV6JUlFRUUaPXq0ampqFBsb+6PGXldXJ7fbrUAg8KMfA/xaXTVjdWsPAUAb9OWcnJ/8mC35+X3e79FpampSUVGRjh8/royMDFVWVqq6ulpZWVlOxuVyKTMzUxs2bJAklZeXq7GxMSTj9XqVmprqZDZu3Ci32+2UHEnq06eP3G53SCY1NdUpOZKUnZ2tYDCo8vLyHxxzMBhUXV1dyA0AANirxUVn+/btuuSSS+RyuTRu3DitXLlSPXr0UHV1tSQpKSkpJJ+UlOTsq66uVmRkpOLi4s6aSUxMbPa8iYmJIZnTnycuLk6RkZFO5kwKCwud9/243W4lJye38NUDAIC2pMVFp1u3bqqoqNCmTZv0hz/8QXfffbd27drl7A8LCwvJG2OabTvd6Zkz5c8nc7qZM2cqEAg4t3379p11XAAAoG1rcdGJjIzUtddeq5tuukmFhYXq3bu3/vrXv8rj8UhSsxWVmpoaZ/XF4/GooaFBfr//rJlDhw41e97Dhw+HZE5/Hr/fr8bGxmYrPf/O5XI5nxg7dQMAAPa64OvoGGMUDAbVtWtXeTwelZaWOvsaGhq0bt069e3bV5KUlpam9u3bh2Sqqqq0Y8cOJ5ORkaFAIKAtW7Y4mc2bNysQCIRkduzYoaqqKidTUlIil8ultLS0C31JAADAEhEtCT/yyCMaMmSIkpOTdfToURUVFen9999XcXGxwsLCVFBQoNmzZyslJUUpKSmaPXu2OnbsqPz8fEmS2+3WmDFjNGXKFHXq1Enx8fGaOnWqevbsqYEDB0qSunfvrsGDB2vs2LFatGiRJOm+++5Tbm6uunXrJknKyspSjx495PP5NHfuXB05ckRTp07V2LFjWaUBAACOFhWdQ4cOyefzqaqqSm63W7169VJxcbEGDRokSZo2bZrq6+s1fvx4+f1+paenq6SkRDExMc4xnn76aUVERGj48OGqr6/XgAEDtGTJEoWHhzuZZcuWadKkSc6ns/Ly8rRgwQJnf3h4uFavXq3x48frlltuUVRUlPLz8zVv3rwLOhkAAMAuF3wdnbaM6+igtXBNGgC/Fm32OjoAAAC/dBQdAABgLYoOAACwFkUHAABYi6IDAACsRdEBAADWougAAABrUXQAAIC1KDoAAMBaFB0AAGAtig4AALAWRQcAAFiLogMAAKxF0QEAANai6AAAAGtRdAAAgLUoOgAAwFoUHQAAYC2KDgAAsBZFBwAAWIuiAwAArEXRAQAA1qLoAAAAa1F0AACAtSg6AADAWhQdAABgLYoOAACwFkUHAABYi6IDAACsRdEBAADWougAAABrUXQAAIC1KDoAAMBaFB0AAGAtig4AALAWRQcAAFiLogMAAKxF0QEAANai6AAAAGtRdAAAgLUoOgAAwFoUHQAAYC2KDgAAsBZFBwAAWIuiAwAArEXRAQAA1qLoAAAAa1F0AACAtSg6AADAWhQdAABgLYoOAACwFkUHAABYi6IDAACsRdEBAADWougAAABrUXQAAIC1KDoAAMBaFB0AAGAtig4AALAWRQcAAFiLogMAAKzVoqJTWFiom2++WTExMUpMTNR//dd/6eOPPw7JGGM0a9Yseb1eRUVFqX///tq5c2dIJhgMauLEiUpISFB0dLTy8vK0f//+kIzf75fP55Pb7Zbb7ZbP51NtbW1IZu/evRo6dKiio6OVkJCgSZMmqaGhoSUvCQAAWKxFRWfdunV64IEHtGnTJpWWluq7775TVlaWjh8/7mSefPJJzZ8/XwsWLNDWrVvl8Xg0aNAgHT161MkUFBRo5cqVKioqUllZmY4dO6bc3Fw1NTU5mfz8fFVUVKi4uFjFxcWqqKiQz+dz9jc1NSknJ0fHjx9XWVmZioqKtHz5ck2ZMuVCzgcAALBImDHGnO+DDx8+rMTERK1bt0633nqrjDHyer0qKCjQ9OnTJX2/epOUlKS//OUvuv/++xUIBHTZZZfp1Vdf1YgRIyRJBw8eVHJyst555x1lZ2dr9+7d6tGjhzZt2qT09HRJ0qZNm5SRkaE9e/aoW7duevfdd5Wbm6t9+/bJ6/VKkoqKijR69GjV1NQoNjb2nOOvq6uT2+1WIBD4UXngp3LVjNWtPQQA+Fl8OSfnJz9mS35+X9B7dAKBgCQpPj5eklRZWanq6mplZWU5GZfLpczMTG3YsEGSVF5ersbGxpCM1+tVamqqk9m4caPcbrdTciSpT58+crvdIZnU1FSn5EhSdna2gsGgysvLzzjeYDCourq6kBsAALDXeRcdY4weeugh9evXT6mpqZKk6upqSVJSUlJINikpydlXXV2tyMhIxcXFnTWTmJjY7DkTExNDMqc/T1xcnCIjI53M6QoLC533/LjdbiUnJ7f0ZQMAgDbkvIvOhAkT9K9//Uuvv/56s31hYWEh940xzbad7vTMmfLnk/l3M2fOVCAQcG779u0765gAAEDbdl5FZ+LEiVq1apXWrl2rLl26ONs9Ho8kNVtRqampcVZfPB6PGhoa5Pf7z5o5dOhQs+c9fPhwSOb05/H7/WpsbGy20nOKy+VSbGxsyA0AANirRUXHGKMJEyZoxYoV+r//+z917do1ZH/Xrl3l8XhUWlrqbGtoaNC6devUt29fSVJaWprat28fkqmqqtKOHTucTEZGhgKBgLZs2eJkNm/erEAgEJLZsWOHqqqqnExJSYlcLpfS0tJa8rIAAIClIloSfuCBB/Taa6/prbfeUkxMjLOi4na7FRUVpbCwMBUUFGj27NlKSUlRSkqKZs+erY4dOyo/P9/JjhkzRlOmTFGnTp0UHx+vqVOnqmfPnho4cKAkqXv37ho8eLDGjh2rRYsWSZLuu+8+5ebmqlu3bpKkrKws9ejRQz6fT3PnztWRI0c0depUjR07lpUaAAAgqYVF57nnnpMk9e/fP2T74sWLNXr0aEnStGnTVF9fr/Hjx8vv9ys9PV0lJSWKiYlx8k8//bQiIiI0fPhw1dfXa8CAAVqyZInCw8OdzLJlyzRp0iTn01l5eXlasGCBsz88PFyrV6/W+PHjdcsttygqKkr5+fmaN29ei04AAACw1wVdR6et4zo6aC1cRwfAr0Wbvo4OAADALxlFBwAAWIuiAwAArEXRAQAA1qLoAAAAa1F0AACAtSg6AADAWhQdAABgLYoOAACwFkUHAABYi6IDAACsRdEBAADWougAAABrUXQAAIC1KDoAAMBaFB0AAGAtig4AALAWRQcAAFiLogMAAKxF0QEAANai6AAAAGtRdAAAgLUoOgAAwFoUHQAAYC2KDgAAsBZFBwAAWIuiAwAArEXRAQAA1qLoAAAAa1F0AACAtSg6AADAWhQdAABgLYoOAACwFkUHAABYi6IDAACsRdEBAADWougAAABrUXQAAIC1KDoAAMBaFB0AAGAtig4AALAWRQcAAFiLogMAAKwV0doDsNlVM1a39hBa7Ms5Oa09BAAAfjKs6AAAAGtRdAAAgLUoOgAAwFoUHQAAYC2KDgAAsBZFBwAAWIuiAwAArEXRAQAA1qLoAAAAa1F0AACAtSg6AADAWhQdAABgLYoOAACwFkUHAABYi6IDAACsRdEBAADWougAAABrtbjofPDBBxo6dKi8Xq/CwsL05ptvhuw3xmjWrFnyer2KiopS//79tXPnzpBMMBjUxIkTlZCQoOjoaOXl5Wn//v0hGb/fL5/PJ7fbLbfbLZ/Pp9ra2pDM3r17NXToUEVHRyshIUGTJk1SQ0NDS18SAACwVIuLzvHjx9W7d28tWLDgjPuffPJJzZ8/XwsWLNDWrVvl8Xg0aNAgHT161MkUFBRo5cqVKioqUllZmY4dO6bc3Fw1NTU5mfz8fFVUVKi4uFjFxcWqqKiQz+dz9jc1NSknJ0fHjx9XWVmZioqKtHz5ck2ZMqWlLwkAAFgqoqUPGDJkiIYMGXLGfcYYPfPMM3r00Uc1bNgwSdIrr7yipKQkvfbaa7r//vsVCAT08ssv69VXX9XAgQMlSUuXLlVycrLWrFmj7Oxs7d69W8XFxdq0aZPS09MlSS+++KIyMjL08ccfq1u3biopKdGuXbu0b98+eb1eSdJTTz2l0aNH689//rNiY2PP64QAAAB7/KTv0amsrFR1dbWysrKcbS6XS5mZmdqwYYMkqby8XI2NjSEZr9er1NRUJ7Nx40a53W6n5EhSnz595Ha7QzKpqalOyZGk7OxsBYNBlZeXn3F8wWBQdXV1ITcAAGCvn7ToVFdXS5KSkpJCticlJTn7qqurFRkZqbi4uLNmEhMTmx0/MTExJHP688TFxSkyMtLJnK6wsNB5z4/b7VZycvJ5vEoAANBWXJRPXYWFhYXcN8Y023a60zNnyp9P5t/NnDlTgUDAue3bt++sYwIAAG3bT1p0PB6PJDVbUampqXFWXzwejxoaGuT3+8+aOXToULPjHz58OCRz+vP4/X41NjY2W+k5xeVyKTY2NuQGAADs9ZMWna5du8rj8ai0tNTZ1tDQoHXr1qlv376SpLS0NLVv3z4kU1VVpR07djiZjIwMBQIBbdmyxcls3rxZgUAgJLNjxw5VVVU5mZKSErlcLqWlpf2ULwsAALRRLf7U1bFjx/TZZ5859ysrK1VRUaH4+HhdccUVKigo0OzZs5WSkqKUlBTNnj1bHTt2VH5+viTJ7XZrzJgxmjJlijp16qT4+HhNnTpVPXv2dD6F1b17dw0ePFhjx47VokWLJEn33XefcnNz1a1bN0lSVlaWevToIZ/Pp7lz5+rIkSOaOnWqxo4dy0oNAACQdB5F58MPP9Rtt93m3H/ooYckSXfffbeWLFmiadOmqb6+XuPHj5ff71d6erpKSkoUExPjPObpp59WRESEhg8frvr6eg0YMEBLlixReHi4k1m2bJkmTZrkfDorLy8v5No94eHhWr16tcaPH69bbrlFUVFRys/P17x581p+FgAAgJXCjDGmtQfRWurq6uR2uxUIBC7KKtBVM1b/5Me82L6ck9PaQ/hVaIv/bwDA+bgYP1da8vOb77oCAADWougAAABrUXQAAIC1KDoAAMBaFB0AAGAtig4AALAWRQcAAFiLogMAAKxF0QEAANai6AAAAGtRdAAAgLUoOgAAwFoUHQAAYC2KDgAAsBZFBwAAWIuiAwAArEXRAQAA1qLoAAAAa1F0AACAtSg6AADAWhQdAABgLYoOAACwFkUHAABYK6K1BwBcqKtmrG7tIQAAfqFY0QEAANai6AAAAGtRdAAAgLUoOgAAwFoUHQAAYC2KDgAAsBZFBwAAWIuiAwAArEXRAQAA1qLoAAAAa1F0AACAtSg6AADAWhQdAABgLYoOAACwFkUHAABYi6IDAACsFdHaA8Avy1UzVrf2EAAA+MmwogMAAKxF0QEAANai6AAAAGtRdAAAgLUoOgAAwFoUHQAAYC2KDgAAsBZFBwAAWIuiAwAArEXRAQAA1qLoAAAAa1F0AACAtSg6AADAWhQdAABgLYoOAACwFkUHAABYi6IDAACsRdEBAADWougAAABrUXQAAIC12nzRWbhwobp27aoOHTooLS1N69evb+0hAQCAX4g2XXTeeOMNFRQU6NFHH9VHH32k3/zmNxoyZIj27t3b2kMDAAC/AG266MyfP19jxozRvffeq+7du+uZZ55RcnKynnvuudYeGgAA+AWIaO0BnK+GhgaVl5drxowZIduzsrK0YcOGMz4mGAwqGAw69wOBgCSprq7uoozxZPDbi3JcAADaiovxM/bUMY0x58y22aLz9ddfq6mpSUlJSSHbk5KSVF1dfcbHFBYW6o9//GOz7cnJyRdljAAA/Nq5n7l4xz569KjcbvdZM2226JwSFhYWct8Y02zbKTNnztRDDz3k3D958qSOHDmiTp06/eBj8POqq6tTcnKy9u3bp9jY2NYeDn4A89R2MFdtA/PUMsYYHT16VF6v95zZNlt0EhISFB4e3mz1pqamptkqzykul0sulytk26WXXnqxhogLEBsbyz/2NoB5ajuYq7aBefrxzrWSc0qbfTNyZGSk0tLSVFpaGrK9tLRUffv2baVRAQCAX5I2u6IjSQ899JB8Pp9uuukmZWRk6IUXXtDevXs1bty41h4aAAD4BWjTRWfEiBH65ptv9MQTT6iqqkqpqal65513dOWVV7b20HCeXC6XHn/88WZ/YsQvC/PUdjBXbQPzdPGEmR/z2SwAAIA2qM2+RwcAAOBcKDoAAMBaFB0AAGAtig4AALAWRQc/2lVXXaWwsLBmtwceeMDJ7N69W3l5eXK73YqJiVGfPn1Cvk0+GAxq4sSJSkhIUHR0tPLy8rR///6Q5/H7/fL5fHK73XK73fL5fKqtrQ3J7N27V0OHDlV0dLQSEhI0adIkNTQ0hGS2b9+uzMxMRUVFqXPnznriiSd+1Pei2OBcc3Xs2DFNmDBBXbp0UVRUlLp3797sy3CZq4vvu+++02OPPaauXbsqKipKV199tZ544gmdPHnSyRhjNGvWLHm9XkVFRal///7auXNnyHGYq4vvXHPV2Nio6dOnq2fPnoqOjpbX69X//M//6ODBgyHHYa5agQF+pJqaGlNVVeXcSktLjSSzdu1aY4wxn332mYmPjzcPP/yw2bZtm/n888/N22+/bQ4dOuQcY9y4caZz586mtLTUbNu2zdx2222md+/e5rvvvnMygwcPNqmpqWbDhg1mw4YNJjU11eTm5jr7v/vuO5Oammpuu+02s23bNlNaWmq8Xq+ZMGGCkwkEAiYpKcncddddZvv27Wb58uUmJibGzJs37+KfqF+Ac83Vvffea6655hqzdu1aU1lZaRYtWmTCw8PNm2++6RyDubr4/vSnP5lOnTqZt99+21RWVpr//d//NZdccol55plnnMycOXNMTEyMWb58udm+fbsZMWKEufzyy01dXZ2TYa4uvnPNVW1trRk4cKB54403zJ49e8zGjRtNenq6SUtLCzkOc/Xzo+jgvE2ePNlcc8015uTJk8YYY0aMGGH++7//+wfztbW1pn379qaoqMjZduDAAdOuXTtTXFxsjDFm165dRpLZtGmTk9m4caORZPbs2WOMMeadd94x7dq1MwcOHHAyr7/+unG5XCYQCBhjjFm4cKFxu93mxIkTTqawsNB4vV5nvL8mp8/V9ddfb5544omQzI033mgee+wxYwxz9XPJyckx99xzT8i2YcOGOf+OTp48aTwej5kzZ46z/8SJE8btdpvnn3/eGMNc/VzONVdnsmXLFiPJfPXVV8YY5qq18KcrnJeGhgYtXbpU99xzj8LCwnTy5EmtXr1a//Ef/6Hs7GwlJiYqPT1db775pvOY8vJyNTY2Kisry9nm9XqVmpqqDRs2SJI2btwot9ut9PR0J9OnTx+53e6QTGpqasiXuWVnZysYDKq8vNzJZGZmhlx8Kzs7WwcPHtSXX355MU7JL9bpcyVJ/fr106pVq3TgwAEZY7R27Vp98sknys7OlsRc/Vz69eunf/zjH/rkk08kSf/85z9VVlam22+/XZJUWVmp6urqkHlwuVzKzMx0zjFz9fM411ydSSAQUFhYmPOdisxV66Do4Ly8+eabqq2t1ejRoyV9/2Wqx44d05w5czR48GCVlJTozjvv1LBhw7Ru3TpJUnV1tSIjIxUXFxdyrKSkJOfLWaurq5WYmNjs+RITE0Myp39xa1xcnCIjI8+aOXX/9C+Ctd3pcyVJzz77rHr06KEuXbooMjJSgwcP1sKFC9WvXz9JzNXPZfr06Ro5cqSuu+46tW/fXjfccIMKCgo0cuRISf/v9Z/p/Pz7+WOuLr5zzdXpTpw4oRkzZig/P9/5kk7mqnW06a+AQOt5+eWXNWTIEOc3ilNvyLvjjjv04IMPSpL+8z//Uxs2bNDzzz+vzMzMHzyWMcZZaZAU8t8/Zcb8/2/CO9NjbXb6XEnfF51NmzZp1apVuvLKK/XBBx9o/PjxuvzyyzVw4MAfPBZz9dN64403tHTpUr322mu6/vrrVVFRoYKCAnm9Xt19991O7kzn51znhrn6af3YuZK+f2PyXXfdpZMnT2rhwoXnPDZzdXGxooMW++qrr7RmzRrde++9zraEhARFRESoR48eIdnu3bs7n7ryeDxqaGiQ3+8PydTU1Di/aXg8Hh06dKjZcx4+fDgkc/pvJH6/X42NjWfN1NTUSGr+27HNzjRX9fX1euSRRzR//nwNHTpUvXr10oQJEzRixAjNmzdPEnP1c3n44Yc1Y8YM3XXXXerZs6d8Pp8efPBBFRYWSvr+3EjNfwM/fR6Yq4vvXHN1SmNjo4YPH67KykqVlpY6qzkSc9VaKDposcWLFysxMVE5OTnOtsjISN188836+OOPQ7KffPKJ8yWraWlpat++vUpLS539VVVV2rFjh/r27StJysjIUCAQ0JYtW5zM5s2bFQgEQjI7duxQVVWVkykpKZHL5VJaWpqT+eCDD0I+bllSUiKv16urrrrqJzoTv3xnmqvGxkY1NjaqXbvQf/7h4eHOyhxz9fP49ttvzzoPXbt2lcfjCZmHhoYGrVu3zjnHzNXP41xzJf2/kvPpp59qzZo16tSpU0ieuWolP/e7n9G2NTU1mSuuuMJMnz692b4VK1aY9u3bmxdeeMF8+umn5m9/+5sJDw8369evdzLjxo0zXbp0MWvWrDHbtm0zv/3tb8/40cpevXqZjRs3mo0bN5qePXue8aOVAwYMMNu2bTNr1qwxXbp0CfloZW1trUlKSjIjR44027dvNytWrDCxsbG/qo9Wnm2uMjMzzfXXX2/Wrl1rvvjiC7N48WLToUMHs3DhQifDXF18d999t+ncubPzkeUVK1aYhIQEM23aNCczZ84c43a7zYoVK8z27dvNyJEjz/jxcubq4jrXXDU2Npq8vDzTpUsXU1FREXJ5h2Aw6ByHufr5UXTQIu+9956RZD7++OMz7n/55ZfNtddeazp06GB69+4dcl0WY4ypr683EyZMMPHx8SYqKsrk5uaavXv3hmS++eYbM2rUKBMTE2NiYmLMqFGjjN/vD8l89dVXJicnx0RFRZn4+HgzYcKEkI9RGmPMv/71L/Ob3/zGuFwu4/F4zKxZs35VH6s821xVVVWZ0aNHG6/Xazp06GC6detmnnrqqZDzw1xdfHV1dWby5MnmiiuuMB06dDBXX321efTRR0N+MJ48edI8/vjjxuPxGJfLZW699Vazffv2kOMwVxffueaqsrLSSDrj7dT1q4xhrlpDmDG/xsskAgCAXwPeowMAAKxF0QEAANai6AAAAGtRdAAAgLUoOgAAwFoUHQAAYC2KDgAAsBZFBwAAC73wwgvq37+/YmNjFRYWptra2hY9vrCwUGFhYSooKAjZfuzYMU2YMEFdunRRVFSUunfvrueeey4kc//99+uaa65RVFSULrvsMt1xxx3as2dPi56/sbFRTzzxhK655hp16NBBvXv3VnFxcYuOIVF0AABos/r3768lS5accd+3336rwYMH65FHHmnxcbdu3aoXXnhBvXr1arbvwQcfVHFxsZYuXardu3frwQcf1MSJE/XWW285mbS0NC1evFi7d+/We++9J2OMsrKy1NTU9KPH8Nhjj2nRokX629/+pl27dmncuHG688479dFHH7XsxbTylZkBAMB5yszMNIsXLz5rZu3atUZSs6+R+CFHjx41KSkpprS01GRmZprJkyeH7L/++uvNE088EbLtxhtvNI899tgPHvOf//ynkWQ+++wzZ9v+/fvN8OHDzaWXXmri4+NNXl6eqaysdPZffvnlZsGCBSHHueOOO8yoUaN+1Os4hRUdAADgeOCBB5STk6OBAweecX+/fv20atUqHThwQMYYrV27Vp988omys7PPmD9+/LgWL16srl27Kjk5WdL3q0233XabLrnkEn3wwQcqKyvTJZdcosGDBzvfuB4MBtWhQ4eQY0VFRamsrKxFryeiRWkAAGCtoqIibdu2TVu3bv3BzLPPPquxY8eqS5cuioiIULt27fTSSy+pX79+IbmFCxdq2rRpOn78uK677jqVlpYqMjLSeZ5TjwsLC5MkLV68WJdeeqnef/99ZWVlKTs7W/Pnz9ett96qa665Rv/4xz/01ltvtejPXxLv0QEAoM2YPXu2LrnkEue2fv16jRs3rtm287Fv3z5NnjxZS5cubbaS8u+effZZbdq0SatWrVJ5ebmeeuopjR8/XmvWrAnJjRo1Sh999JHWrVunlJQUDR8+XCdOnJAklZeX67PPPlNMTIwz7vj4eJ04cUKff/65JOmvf/2rUlJSdN111ykyMlITJkzQ73//e4WHh7fodfHt5QAAtBFHjhzRkSNHnPujRo3S7373Ow0bNszZ1rlzZ0VFRTn333//fd12223y+/269NJLf/DYb775pu68886QItHU1KSwsDC1a9dOwWBQDQ0NcrvdWrlypXJycpzcvffeq/379//gp6IaGhoUFxenl156SSNHjtQf/vAHbdu2TcuWLWuWveyyy+R2u537J06c0DfffCOv16sZM2bo7bff1s6dO89+ov4Nf7oCAKCNiI+PV3x8vHM/KipKiYmJuvbaay/42AMGDND27dtDtv3+97/Xddddp+nTpys8PFyNjY1qbGxUu3ahfxAKDw/XyZMnz3p8Y4yCwaAk6cYbb9Qbb7yhxMRExcbGnvVxHTp0UOfOndXY2Kjly5dr+PDhLXpd/OkKAAALVVdXq6KiQp999pkkafv27aqoqAhZERowYIAWLFggSYqJiVFqamrILTo6Wp06dVJqaqokKTY2VpmZmXr44Yf1/vvvq7KyUkuWLNHf//533XnnnZKkL774QoWFhSovL9fevXu1ceNGDR8+XFFRUbr99tslfb8SlZCQoDvuuEPr169XZWWl1q1bp8mTJ2v//v2SpM2bN2vFihX64osvtH79eg0ePFgnT57UtGnTWnQeKDoAAFjo+eef1w033KCxY8dKkm699VbdcMMNWrVqlZP5/PPP9fXXX7fouEVFRbr55ps1atQo9ejRQ3PmzNGf//xnjRs3TtL3KzDr16/X7bffrmuvvVbDhw9XdHS0NmzYoMTERElSx44d9cEHH+iKK67QsGHD1L17d91zzz2qr693VnhOnDihxx57TD169NCdd96pzp07q6ys7Kx/fjsT3qMDAACsxYoOAACwFkUHAABYi6IDAACsRdEBAADWougAAABrUXQAAIC1KDoAAMBaFB0AAGAtig4AALAWRQcAAFiLogMAAKxF0QEAANb6/wAF75n7fojZfgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.hist(interaction_matrix.timestamps.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aa72bb09-e745-4c5f-b4b3-88785f8a96b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfca21b4191e492383085792d76e94f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49976a5ffef2422a828f18a928f20e62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "scenario = StrongGeneralization(frac_users_train=0.8, frac_interactions_in=0.8, validation=True)\n",
    "scenario.split(interaction_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65e0c5cd-5574-417f-b7c8-090d9b0d46de",
   "metadata": {},
   "source": [
    "## Experimental RecPack Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "40f6a5b5-4f21-49ee-a96e-f7e375031134",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/recpack/pipelines/pipeline_builder.py:145: UserWarning: Grid parameter for add_algorithm function will be deprecated in favour of optimisation_info.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e33ef17b95641c2b9a1a0d5c3ec1baa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_48313/2405251189.py:85: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  user_indices = torch.tensor(user_indices).to(self.device)\n",
      "/tmp/ipykernel_48313/2405251189.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  pos_item_indices = torch.tensor(pos_item_indices).to(self.device)\n",
      "/tmp/ipykernel_48313/2405251189.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  neg_item_indices = torch.tensor(neg_item_indices).to(self.device).squeeze()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-05 12:45:59,039 - base - recpack - INFO - Processed epoch 0 in 5.82 s.Batch Training Loss = 0.3551\n",
      "2024-08-05 12:46:04,800 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.35044568022983935, which is better than previous iterations.\n",
      "2024-08-05 12:46:04,801 - base - recpack - INFO - Model improved. Storing better model.\n",
      "2024-08-05 12:46:04,920 - base - recpack - INFO - Evaluation at end of 0 took 5.88 s.\n",
      "2024-08-05 12:46:09,541 - base - recpack - INFO - Processed epoch 1 in 4.62 s.Batch Training Loss = 0.3498\n",
      "2024-08-05 12:46:14,866 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.35042951742744993, which is worse than previous iterations.\n",
      "2024-08-05 12:46:14,867 - base - recpack - INFO - Evaluation at end of 1 took 5.32 s.\n",
      "2024-08-05 12:46:19,642 - base - recpack - INFO - Processed epoch 2 in 4.77 s.Batch Training Loss = 0.3497\n",
      "2024-08-05 12:46:25,318 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.34707349000626003, which is worse than previous iterations.\n",
      "2024-08-05 12:46:25,319 - base - recpack - INFO - Evaluation at end of 2 took 5.68 s.\n",
      "2024-08-05 12:46:30,278 - base - recpack - INFO - Processed epoch 3 in 4.96 s.Batch Training Loss = 0.3496\n",
      "2024-08-05 12:46:35,831 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.35301186450628563, which is worse than previous iterations.\n",
      "2024-08-05 12:46:35,832 - base - recpack - INFO - Evaluation at end of 3 took 5.55 s.\n",
      "2024-08-05 12:46:40,580 - base - recpack - INFO - Processed epoch 4 in 4.75 s.Batch Training Loss = 0.3492\n",
      "2024-08-05 12:46:45,874 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.3441552266214142, which is worse than previous iterations.\n",
      "2024-08-05 12:46:45,875 - base - recpack - INFO - Evaluation at end of 4 took 5.29 s.\n",
      "2024-08-05 12:46:45,946 - base - recpack - INFO - Fitting PinSAGEAlgorithm complete - Took 55.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/recpack/algorithms/base.py:509: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.model_ = torch.load(self.best_model)\n",
      "/tmp/ipykernel_48313/2405251189.py:85: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  user_indices = torch.tensor(user_indices).to(self.device)\n",
      "/tmp/ipykernel_48313/2405251189.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  pos_item_indices = torch.tensor(pos_item_indices).to(self.device)\n",
      "/tmp/ipykernel_48313/2405251189.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  neg_item_indices = torch.tensor(neg_item_indices).to(self.device).squeeze()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-05 12:46:57,008 - base - recpack - INFO - Processed epoch 0 in 4.81 s.Batch Training Loss = 0.3556\n",
      "2024-08-05 12:47:02,501 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.3477732590545753, which is better than previous iterations.\n",
      "2024-08-05 12:47:02,503 - base - recpack - INFO - Model improved. Storing better model.\n",
      "2024-08-05 12:47:02,620 - base - recpack - INFO - Evaluation at end of 0 took 5.61 s.\n",
      "2024-08-05 12:47:07,466 - base - recpack - INFO - Processed epoch 1 in 4.84 s.Batch Training Loss = 0.3478\n",
      "2024-08-05 12:47:12,957 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.34754051822461585, which is worse than previous iterations.\n",
      "2024-08-05 12:47:12,959 - base - recpack - INFO - Evaluation at end of 1 took 5.49 s.\n",
      "2024-08-05 12:47:17,736 - base - recpack - INFO - Processed epoch 2 in 4.78 s.Batch Training Loss = 0.3474\n",
      "2024-08-05 12:47:22,794 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.34794950735420327, which is worse than previous iterations.\n",
      "2024-08-05 12:47:22,795 - base - recpack - INFO - Evaluation at end of 2 took 5.06 s.\n",
      "2024-08-05 12:47:27,507 - base - recpack - INFO - Processed epoch 3 in 4.71 s.Batch Training Loss = 0.3477\n",
      "2024-08-05 12:47:32,956 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.3449336146938997, which is worse than previous iterations.\n",
      "2024-08-05 12:47:32,957 - base - recpack - INFO - Evaluation at end of 3 took 5.45 s.\n",
      "2024-08-05 12:47:37,583 - base - recpack - INFO - Processed epoch 4 in 4.62 s.Batch Training Loss = 0.3479\n",
      "2024-08-05 12:47:43,012 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.3482446792294476, which is worse than previous iterations.\n",
      "2024-08-05 12:47:43,013 - base - recpack - INFO - Evaluation at end of 4 took 5.43 s.\n",
      "2024-08-05 12:47:43,081 - base - recpack - INFO - Fitting PinSAGEAlgorithm complete - Took 51.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/recpack/algorithms/base.py:509: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.model_ = torch.load(self.best_model)\n",
      "/tmp/ipykernel_48313/2405251189.py:85: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  user_indices = torch.tensor(user_indices).to(self.device)\n",
      "/tmp/ipykernel_48313/2405251189.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  pos_item_indices = torch.tensor(pos_item_indices).to(self.device)\n",
      "/tmp/ipykernel_48313/2405251189.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  neg_item_indices = torch.tensor(neg_item_indices).to(self.device).squeeze()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-05 12:47:53,217 - base - recpack - INFO - Processed epoch 0 in 4.63 s.Batch Training Loss = 0.3905\n",
      "2024-08-05 12:47:59,124 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.3469997910797825, which is better than previous iterations.\n",
      "2024-08-05 12:47:59,125 - base - recpack - INFO - Model improved. Storing better model.\n",
      "2024-08-05 12:47:59,205 - base - recpack - INFO - Evaluation at end of 0 took 5.99 s.\n",
      "2024-08-05 12:48:04,047 - base - recpack - INFO - Processed epoch 1 in 4.84 s.Batch Training Loss = 0.3462\n",
      "2024-08-05 12:48:09,396 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.34755482241939006, which is worse than previous iterations.\n",
      "2024-08-05 12:48:09,397 - base - recpack - INFO - Evaluation at end of 1 took 5.35 s.\n",
      "2024-08-05 12:48:14,300 - base - recpack - INFO - Processed epoch 2 in 4.90 s.Batch Training Loss = 0.3464\n",
      "2024-08-05 12:48:19,662 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.3439939441167738, which is worse than previous iterations.\n",
      "2024-08-05 12:48:19,663 - base - recpack - INFO - Evaluation at end of 2 took 5.36 s.\n",
      "2024-08-05 12:48:24,474 - base - recpack - INFO - Processed epoch 3 in 4.81 s.Batch Training Loss = 0.3463\n",
      "2024-08-05 12:48:29,824 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.3402817016756226, which is worse than previous iterations.\n",
      "2024-08-05 12:48:29,826 - base - recpack - INFO - Evaluation at end of 3 took 5.35 s.\n",
      "2024-08-05 12:48:34,599 - base - recpack - INFO - Processed epoch 4 in 4.77 s.Batch Training Loss = 0.3459\n",
      "2024-08-05 12:48:40,231 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.34731925502310146, which is worse than previous iterations.\n",
      "2024-08-05 12:48:40,232 - base - recpack - INFO - Evaluation at end of 4 took 5.63 s.\n",
      "2024-08-05 12:48:40,302 - base - recpack - INFO - Fitting PinSAGEAlgorithm complete - Took 51.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/recpack/algorithms/base.py:509: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.model_ = torch.load(self.best_model)\n",
      "/tmp/ipykernel_48313/2405251189.py:85: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  user_indices = torch.tensor(user_indices).to(self.device)\n",
      "/tmp/ipykernel_48313/2405251189.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  pos_item_indices = torch.tensor(pos_item_indices).to(self.device)\n",
      "/tmp/ipykernel_48313/2405251189.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  neg_item_indices = torch.tensor(neg_item_indices).to(self.device).squeeze()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-05 12:48:55,231 - base - recpack - INFO - Processed epoch 0 in 8.67 s.Batch Training Loss = 0.3560\n",
      "2024-08-05 12:49:00,304 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.351564450106292, which is better than previous iterations.\n",
      "2024-08-05 12:49:00,305 - base - recpack - INFO - Model improved. Storing better model.\n",
      "2024-08-05 12:49:00,571 - base - recpack - INFO - Evaluation at end of 0 took 5.34 s.\n",
      "2024-08-05 12:49:08,903 - base - recpack - INFO - Processed epoch 1 in 8.33 s.Batch Training Loss = 0.3494\n",
      "2024-08-05 12:49:14,359 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.34798375043697627, which is worse than previous iterations.\n",
      "2024-08-05 12:49:14,360 - base - recpack - INFO - Evaluation at end of 1 took 5.46 s.\n",
      "2024-08-05 12:49:22,617 - base - recpack - INFO - Processed epoch 2 in 8.25 s.Batch Training Loss = 0.3496\n",
      "2024-08-05 12:49:27,888 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.35345219419216556, which is worse than previous iterations.\n",
      "2024-08-05 12:49:27,890 - base - recpack - INFO - Evaluation at end of 2 took 5.27 s.\n",
      "2024-08-05 12:49:36,191 - base - recpack - INFO - Processed epoch 3 in 8.30 s.Batch Training Loss = 0.3493\n",
      "2024-08-05 12:49:41,696 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.35360890651728477, which is worse than previous iterations.\n",
      "2024-08-05 12:49:41,698 - base - recpack - INFO - Evaluation at end of 3 took 5.51 s.\n",
      "2024-08-05 12:49:49,932 - base - recpack - INFO - Processed epoch 4 in 8.23 s.Batch Training Loss = 0.3492\n",
      "2024-08-05 12:49:55,049 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.3545286304351437, which is worse than previous iterations.\n",
      "2024-08-05 12:49:55,050 - base - recpack - INFO - Evaluation at end of 4 took 5.12 s.\n",
      "2024-08-05 12:49:55,182 - base - recpack - INFO - Fitting PinSAGEAlgorithm complete - Took 69.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/recpack/algorithms/base.py:509: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.model_ = torch.load(self.best_model)\n",
      "/tmp/ipykernel_48313/2405251189.py:85: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  user_indices = torch.tensor(user_indices).to(self.device)\n",
      "/tmp/ipykernel_48313/2405251189.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  pos_item_indices = torch.tensor(pos_item_indices).to(self.device)\n",
      "/tmp/ipykernel_48313/2405251189.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  neg_item_indices = torch.tensor(neg_item_indices).to(self.device).squeeze()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-05 12:50:09,640 - base - recpack - INFO - Processed epoch 0 in 8.34 s.Batch Training Loss = 0.3551\n",
      "2024-08-05 12:50:15,177 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.3480909888841658, which is better than previous iterations.\n",
      "2024-08-05 12:50:15,178 - base - recpack - INFO - Model improved. Storing better model.\n",
      "2024-08-05 12:50:15,407 - base - recpack - INFO - Evaluation at end of 0 took 5.77 s.\n",
      "2024-08-05 12:50:23,833 - base - recpack - INFO - Processed epoch 1 in 8.42 s.Batch Training Loss = 0.3488\n",
      "2024-08-05 12:50:29,349 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.3480015743642531, which is worse than previous iterations.\n",
      "2024-08-05 12:50:29,351 - base - recpack - INFO - Evaluation at end of 1 took 5.52 s.\n",
      "2024-08-05 12:50:37,670 - base - recpack - INFO - Processed epoch 2 in 8.32 s.Batch Training Loss = 0.3487\n",
      "2024-08-05 12:50:43,355 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.3445628919766639, which is worse than previous iterations.\n",
      "2024-08-05 12:50:43,356 - base - recpack - INFO - Evaluation at end of 2 took 5.68 s.\n",
      "2024-08-05 12:50:51,565 - base - recpack - INFO - Processed epoch 3 in 8.21 s.Batch Training Loss = 0.3487\n",
      "2024-08-05 12:50:56,876 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.3500179092979586, which is worse than previous iterations.\n",
      "2024-08-05 12:50:56,877 - base - recpack - INFO - Evaluation at end of 3 took 5.31 s.\n",
      "2024-08-05 12:51:05,213 - base - recpack - INFO - Processed epoch 4 in 8.33 s.Batch Training Loss = 0.3487\n",
      "2024-08-05 12:51:10,632 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.3473765502880068, which is worse than previous iterations.\n",
      "2024-08-05 12:51:10,633 - base - recpack - INFO - Evaluation at end of 4 took 5.42 s.\n",
      "2024-08-05 12:51:10,761 - base - recpack - INFO - Fitting PinSAGEAlgorithm complete - Took 69.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/recpack/algorithms/base.py:509: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.model_ = torch.load(self.best_model)\n",
      "/tmp/ipykernel_48313/2405251189.py:85: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  user_indices = torch.tensor(user_indices).to(self.device)\n",
      "/tmp/ipykernel_48313/2405251189.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  pos_item_indices = torch.tensor(pos_item_indices).to(self.device)\n",
      "/tmp/ipykernel_48313/2405251189.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  neg_item_indices = torch.tensor(neg_item_indices).to(self.device).squeeze()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-05 12:51:25,363 - base - recpack - INFO - Processed epoch 0 in 8.31 s.Batch Training Loss = 0.3791\n",
      "2024-08-05 12:51:30,789 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.3457646494530692, which is better than previous iterations.\n",
      "2024-08-05 12:51:30,790 - base - recpack - INFO - Model improved. Storing better model.\n",
      "2024-08-05 12:51:31,025 - base - recpack - INFO - Evaluation at end of 0 took 5.66 s.\n",
      "2024-08-05 12:51:39,354 - base - recpack - INFO - Processed epoch 1 in 8.33 s.Batch Training Loss = 0.3460\n",
      "2024-08-05 12:51:44,822 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.3458843552140195, which is worse than previous iterations.\n",
      "2024-08-05 12:51:44,824 - base - recpack - INFO - Evaluation at end of 1 took 5.47 s.\n",
      "2024-08-05 12:51:53,250 - base - recpack - INFO - Processed epoch 2 in 8.42 s.Batch Training Loss = 0.3461\n",
      "2024-08-05 12:51:58,869 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.34396781254829917, which is worse than previous iterations.\n",
      "2024-08-05 12:51:58,870 - base - recpack - INFO - Evaluation at end of 2 took 5.62 s.\n",
      "2024-08-05 12:52:07,181 - base - recpack - INFO - Processed epoch 3 in 8.31 s.Batch Training Loss = 0.3456\n",
      "2024-08-05 12:52:12,431 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.34343276551744045, which is worse than previous iterations.\n",
      "2024-08-05 12:52:12,432 - base - recpack - INFO - Evaluation at end of 3 took 5.25 s.\n",
      "2024-08-05 12:52:21,018 - base - recpack - INFO - Processed epoch 4 in 8.59 s.Batch Training Loss = 0.3457\n",
      "2024-08-05 12:52:26,511 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.34613378501545344, which is worse than previous iterations.\n",
      "2024-08-05 12:52:26,512 - base - recpack - INFO - Evaluation at end of 4 took 5.49 s.\n",
      "2024-08-05 12:52:26,638 - base - recpack - INFO - Fitting PinSAGEAlgorithm complete - Took 70.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/recpack/algorithms/base.py:509: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.model_ = torch.load(self.best_model)\n",
      "/tmp/ipykernel_48313/2405251189.py:85: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  user_indices = torch.tensor(user_indices).to(self.device)\n",
      "/tmp/ipykernel_48313/2405251189.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  pos_item_indices = torch.tensor(pos_item_indices).to(self.device)\n",
      "/tmp/ipykernel_48313/2405251189.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  neg_item_indices = torch.tensor(neg_item_indices).to(self.device).squeeze()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-05 12:52:51,168 - base - recpack - INFO - Processed epoch 0 in 17.38 s.Batch Training Loss = 0.3541\n",
      "2024-08-05 12:52:56,950 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.3515977799177479, which is better than previous iterations.\n",
      "2024-08-05 12:52:56,952 - base - recpack - INFO - Model improved. Storing better model.\n",
      "2024-08-05 12:52:57,402 - base - recpack - INFO - Evaluation at end of 0 took 6.23 s.\n",
      "2024-08-05 12:53:14,618 - base - recpack - INFO - Processed epoch 1 in 17.21 s.Batch Training Loss = 0.3478\n",
      "2024-08-05 12:53:20,191 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.3492195281172738, which is worse than previous iterations.\n",
      "2024-08-05 12:53:20,192 - base - recpack - INFO - Evaluation at end of 1 took 5.57 s.\n",
      "2024-08-05 12:53:37,300 - base - recpack - INFO - Processed epoch 2 in 17.11 s.Batch Training Loss = 0.3474\n",
      "2024-08-05 12:53:43,084 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.3478622281935664, which is worse than previous iterations.\n",
      "2024-08-05 12:53:43,085 - base - recpack - INFO - Evaluation at end of 2 took 5.78 s.\n",
      "2024-08-05 12:54:00,093 - base - recpack - INFO - Processed epoch 3 in 17.01 s.Batch Training Loss = 0.3471\n",
      "2024-08-05 12:54:05,445 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.34421893512125235, which is worse than previous iterations.\n",
      "2024-08-05 12:54:05,446 - base - recpack - INFO - Evaluation at end of 3 took 5.35 s.\n",
      "2024-08-05 12:54:22,553 - base - recpack - INFO - Processed epoch 4 in 17.11 s.Batch Training Loss = 0.3473\n",
      "2024-08-05 12:54:28,101 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.34581510705986923, which is worse than previous iterations.\n",
      "2024-08-05 12:54:28,102 - base - recpack - INFO - Evaluation at end of 4 took 5.55 s.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/recpack/algorithms/base.py:509: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.model_ = torch.load(self.best_model)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-05 12:54:28,347 - base - recpack - INFO - Fitting PinSAGEAlgorithm complete - Took 1.16e+02s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_48313/2405251189.py:85: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  user_indices = torch.tensor(user_indices).to(self.device)\n",
      "/tmp/ipykernel_48313/2405251189.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  pos_item_indices = torch.tensor(pos_item_indices).to(self.device)\n",
      "/tmp/ipykernel_48313/2405251189.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  neg_item_indices = torch.tensor(neg_item_indices).to(self.device).squeeze()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-05 12:54:52,268 - base - recpack - INFO - Processed epoch 0 in 17.00 s.Batch Training Loss = 0.3555\n",
      "2024-08-05 12:54:57,905 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.34775198419924425, which is better than previous iterations.\n",
      "2024-08-05 12:54:57,906 - base - recpack - INFO - Model improved. Storing better model.\n",
      "2024-08-05 12:54:58,376 - base - recpack - INFO - Evaluation at end of 0 took 6.11 s.\n",
      "2024-08-05 12:55:15,421 - base - recpack - INFO - Processed epoch 1 in 17.04 s.Batch Training Loss = 0.3499\n",
      "2024-08-05 12:55:20,902 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.3453304449524385, which is worse than previous iterations.\n",
      "2024-08-05 12:55:20,903 - base - recpack - INFO - Evaluation at end of 1 took 5.48 s.\n",
      "2024-08-05 12:55:37,953 - base - recpack - INFO - Processed epoch 2 in 17.05 s.Batch Training Loss = 0.3495\n",
      "2024-08-05 12:55:43,784 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.35028683658891696, which is worse than previous iterations.\n",
      "2024-08-05 12:55:43,785 - base - recpack - INFO - Evaluation at end of 2 took 5.83 s.\n",
      "2024-08-05 12:56:00,772 - base - recpack - INFO - Processed epoch 3 in 16.99 s.Batch Training Loss = 0.3490\n",
      "2024-08-05 12:56:06,138 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.35144979790269754, which is worse than previous iterations.\n",
      "2024-08-05 12:56:06,139 - base - recpack - INFO - Evaluation at end of 3 took 5.36 s.\n",
      "2024-08-05 12:56:23,264 - base - recpack - INFO - Processed epoch 4 in 17.12 s.Batch Training Loss = 0.3490\n",
      "2024-08-05 12:56:28,747 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.3518378279063322, which is worse than previous iterations.\n",
      "2024-08-05 12:56:28,748 - base - recpack - INFO - Evaluation at end of 4 took 5.48 s.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/recpack/algorithms/base.py:509: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.model_ = torch.load(self.best_model)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-05 12:56:29,015 - base - recpack - INFO - Fitting PinSAGEAlgorithm complete - Took 1.15e+02s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_48313/2405251189.py:85: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  user_indices = torch.tensor(user_indices).to(self.device)\n",
      "/tmp/ipykernel_48313/2405251189.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  pos_item_indices = torch.tensor(pos_item_indices).to(self.device)\n",
      "/tmp/ipykernel_48313/2405251189.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  neg_item_indices = torch.tensor(neg_item_indices).to(self.device).squeeze()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-05 12:56:52,903 - base - recpack - INFO - Processed epoch 0 in 17.03 s.Batch Training Loss = 0.3680\n",
      "2024-08-05 12:56:58,433 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.3432293250050444, which is better than previous iterations.\n",
      "2024-08-05 12:56:58,434 - base - recpack - INFO - Model improved. Storing better model.\n",
      "2024-08-05 12:56:58,868 - base - recpack - INFO - Evaluation at end of 0 took 5.96 s.\n",
      "2024-08-05 12:57:15,906 - base - recpack - INFO - Processed epoch 1 in 17.04 s.Batch Training Loss = 0.3462\n",
      "2024-08-05 12:57:21,347 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.3477680399982715, which is worse than previous iterations.\n",
      "2024-08-05 12:57:21,348 - base - recpack - INFO - Evaluation at end of 1 took 5.44 s.\n",
      "2024-08-05 12:57:38,429 - base - recpack - INFO - Processed epoch 2 in 17.08 s.Batch Training Loss = 0.3464\n",
      "2024-08-05 12:57:44,169 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.3476134541993885, which is worse than previous iterations.\n",
      "2024-08-05 12:57:44,170 - base - recpack - INFO - Evaluation at end of 2 took 5.74 s.\n",
      "2024-08-05 12:58:01,201 - base - recpack - INFO - Processed epoch 3 in 17.03 s.Batch Training Loss = 0.3461\n",
      "2024-08-05 12:58:06,454 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.34501433918867197, which is worse than previous iterations.\n",
      "2024-08-05 12:58:06,455 - base - recpack - INFO - Evaluation at end of 3 took 5.25 s.\n",
      "2024-08-05 12:58:23,557 - base - recpack - INFO - Processed epoch 4 in 17.10 s.Batch Training Loss = 0.3457\n",
      "2024-08-05 12:58:29,006 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.3471352070084681, which is worse than previous iterations.\n",
      "2024-08-05 12:58:29,007 - base - recpack - INFO - Evaluation at end of 4 took 5.45 s.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/recpack/algorithms/base.py:509: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.model_ = torch.load(self.best_model)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-05 12:58:29,250 - base - recpack - INFO - Fitting PinSAGEAlgorithm complete - Took 1.14e+02s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_48313/2405251189.py:85: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  user_indices = torch.tensor(user_indices).to(self.device)\n",
      "/tmp/ipykernel_48313/2405251189.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  pos_item_indices = torch.tensor(pos_item_indices).to(self.device)\n",
      "/tmp/ipykernel_48313/2405251189.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  neg_item_indices = torch.tensor(neg_item_indices).to(self.device).squeeze()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-05 12:58:53,131 - base - recpack - INFO - Processed epoch 0 in 17.09 s.Batch Training Loss = 0.3686\n",
      "2024-08-05 12:58:58,644 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.34280674934427957, which is better than previous iterations.\n",
      "2024-08-05 12:58:58,646 - base - recpack - INFO - Model improved. Storing better model.\n",
      "2024-08-05 12:58:59,080 - base - recpack - INFO - Evaluation at end of 0 took 5.95 s.\n",
      "2024-08-05 12:59:16,156 - base - recpack - INFO - Processed epoch 1 in 17.07 s.Batch Training Loss = 0.3461\n",
      "2024-08-05 12:59:21,631 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.3416774193412492, which is worse than previous iterations.\n",
      "2024-08-05 12:59:21,632 - base - recpack - INFO - Evaluation at end of 1 took 5.47 s.\n",
      "2024-08-05 12:59:38,693 - base - recpack - INFO - Processed epoch 2 in 17.06 s.Batch Training Loss = 0.3460\n",
      "2024-08-05 12:59:44,415 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.3500267981325347, which is worse than previous iterations.\n",
      "2024-08-05 12:59:44,417 - base - recpack - INFO - Evaluation at end of 2 took 5.72 s.\n",
      "2024-08-05 13:00:01,536 - base - recpack - INFO - Processed epoch 3 in 17.12 s.Batch Training Loss = 0.3460\n",
      "2024-08-05 13:00:06,909 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.34845245725440255, which is worse than previous iterations.\n",
      "2024-08-05 13:00:06,910 - base - recpack - INFO - Evaluation at end of 3 took 5.37 s.\n",
      "2024-08-05 13:00:24,017 - base - recpack - INFO - Processed epoch 4 in 17.11 s.Batch Training Loss = 0.3456\n",
      "2024-08-05 13:00:29,489 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.3432798677639178, which is worse than previous iterations.\n",
      "2024-08-05 13:00:29,490 - base - recpack - INFO - Evaluation at end of 4 took 5.47 s.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/recpack/algorithms/base.py:509: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.model_ = torch.load(self.best_model)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-05 13:00:29,749 - base - recpack - INFO - Fitting PinSAGEAlgorithm complete - Took 1.15e+02s\n"
     ]
    }
   ],
   "source": [
    "pipeline_builder = PipelineBuilder()\n",
    "ok = (scenario._validation_data_in, scenario._validation_data_out)\n",
    "pipeline_builder.set_data_from_scenario(scenario)\n",
    "\n",
    "\n",
    "# Add the baseline algorithms\n",
    "#pipeline_builder.add_algorithm('ItemKNN', grid={'K': [100, 200, 400, 800]})\n",
    "#pipeline_builder.add_algorithm('EASE', grid={'l2': [10, 100, 1000], 'alpha': [0, 0.1, 0.5]})\n",
    "\n",
    "# Add our LightGCN algorithm\n",
    "pipeline_builder.add_algorithm(\n",
    "    'PinSAGEAlgorithm2',\n",
    "    grid={\n",
    "        'learning_rate': [0.1, 0.01, 0.001],\n",
    "        'embedding_dim': [100, 200, 400]\n",
    "    },\n",
    "    params={\n",
    "        'max_epochs': 5,\n",
    "        'batch_size': 1024,\n",
    "        'n_layers': 3\n",
    "    }\n",
    ")\n",
    "\n",
    "# Add NDCG, Recall, and HR metrics to be evaluated at 10, 20, and 50\n",
    "pipeline_builder.add_metric('NDCGK', [10, 20, 50])\n",
    "pipeline_builder.add_metric('RecallK', [10, 20, 50])\n",
    "pipeline_builder.add_metric('HitK', [10, 20, 50])\n",
    "\n",
    "# Set the optimisation metric\n",
    "pipeline_builder.set_optimisation_metric('RecallK', 20)\n",
    "\n",
    "# Construct pipeline\n",
    "pipeline = pipeline_builder.build()\n",
    "\n",
    "# Debugging: Output the shape of the training data\n",
    "#print(f\"Training data shape: {im.shape}\")\n",
    "\n",
    "# Run pipeline, will first do optimisation, and then evaluation\n",
    "pipeline.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34e4dfc2-9991-4c99-a7cb-49c98ace709f",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e80f2784-1ed9-4d93-9883-4c34213d62ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NDCGK_10</th>\n",
       "      <th>NDCGK_20</th>\n",
       "      <th>NDCGK_50</th>\n",
       "      <th>RecallK_10</th>\n",
       "      <th>RecallK_20</th>\n",
       "      <th>RecallK_50</th>\n",
       "      <th>HitK_10</th>\n",
       "      <th>HitK_20</th>\n",
       "      <th>HitK_50</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>PinSAGEAlgorithm(batch_size=1024,dropout=0.1,embedding_dim=400,grad_clip=1.0,keep_last=False,learning_rate=0.001,max_epochs=5,max_iter_no_change=5,min_improvement=0.01,n_layers=3,predict_topK=None,save_best_to_file=False,seed=415478342,stop_early=True,stopping_criterion=&lt;recpack.algorithms.stopping_criterion.StoppingCriterion object at 0x7fea4ac61750&gt;,validation_sample_size=None)</th>\n",
       "      <td>0.15005</td>\n",
       "      <td>0.180657</td>\n",
       "      <td>0.228494</td>\n",
       "      <td>0.294181</td>\n",
       "      <td>0.411581</td>\n",
       "      <td>0.640654</td>\n",
       "      <td>0.347747</td>\n",
       "      <td>0.493605</td>\n",
       "      <td>0.774665</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    NDCGK_10  NDCGK_20  \\\n",
       "PinSAGEAlgorithm(batch_size=1024,dropout=0.1,em...   0.15005  0.180657   \n",
       "\n",
       "                                                    NDCGK_50  RecallK_10  \\\n",
       "PinSAGEAlgorithm(batch_size=1024,dropout=0.1,em...  0.228494    0.294181   \n",
       "\n",
       "                                                    RecallK_20  RecallK_50  \\\n",
       "PinSAGEAlgorithm(batch_size=1024,dropout=0.1,em...    0.411581    0.640654   \n",
       "\n",
       "                                                     HitK_10   HitK_20  \\\n",
       "PinSAGEAlgorithm(batch_size=1024,dropout=0.1,em...  0.347747  0.493605   \n",
       "\n",
       "                                                     HitK_50  \n",
       "PinSAGEAlgorithm(batch_size=1024,dropout=0.1,em...  0.774665  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.get_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06eb89bb-82dc-4982-8025-327b4e25fddb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
