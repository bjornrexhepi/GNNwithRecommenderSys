{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "93067af5-1059-47c8-87e4-0375ff8d5253",
   "metadata": {},
   "source": [
    "# NGCF with MSD Dataset and StrongGeneralization Scenario"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eac09989-218d-4d33-bf18-2e777aed21a2",
   "metadata": {},
   "source": [
    "In this notebook, the implementation of NGCF in RecPack and the experimental part to generate the results of the algorithm will be presented. \n",
    "The notebook contains:\n",
    "1. The implementation of NGCF in RecPack.\n",
    "2. The 10% of MSD Dataset from RecPack and the StrongGeneralization Scenario has been used to split the data.\n",
    "3. The StrongGeneralization Scenario to split the data.\n",
    "4. The RecPack Pipeline Builder to run the experiments, including the splitted dataset, the algorithms and metrics to run. Hyperparameter has been performed in the Pipeline.\n",
    "\n",
    "Please make sure you have installed all the latest libraries in your Python environment, in order to have a successful run of the code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "866b2b7e-2fe0-42c8-9bcb-4923357cfa79",
   "metadata": {},
   "source": [
    "## NGCF implementation in RecPack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c7dc8a2-fbb5-4309-bb75-7274fd8fd280",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch_sparse import SparseTensor, matmul\n",
    "from typing import List, Tuple, Optional\n",
    "from recpack.algorithms.base import TorchMLAlgorithm\n",
    "from recpack.matrix.interaction_matrix import InteractionMatrix\n",
    "from recpack.algorithms.loss_functions import bpr_loss\n",
    "from recpack.algorithms.samplers import PositiveNegativeSampler\n",
    "from scipy.sparse import csr_matrix\n",
    "import logging\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Neural Graph Collaborative Filtering (NGCF) model implementation\n",
    "class NGCF(nn.Module):\n",
    "    def __init__(self, num_users, num_items, embedding_dim=64, n_layers=3, dropout=0.0, node_dropout=0.0, message_dropout=0.0):\n",
    "        \"\"\"\n",
    "        Initialize the NGCF model with user and item embeddings.\n",
    "\n",
    "        Args:\n",
    "            num_users (int): Number of users.\n",
    "            num_items (int): Number of items.\n",
    "            embedding_dim (int): Dimension of the embedding vectors.\n",
    "            n_layers (int): Number of hidden layers.\n",
    "            dropout (float): Dropout rate for layers.\n",
    "            node_dropout (float): Dropout rate applied to node embeddings.\n",
    "            message_dropout (float): Dropout rate applied during message passing.\n",
    "        \"\"\"\n",
    "        super(NGCF, self).__init__()\n",
    "        self.num_users = num_users\n",
    "        self.num_items = num_items\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.n_layers = n_layers\n",
    "        self.dropout = dropout\n",
    "        self.node_dropout = node_dropout\n",
    "        self.message_dropout = message_dropout\n",
    "\n",
    "        # Initialize user and item embeddings\n",
    "        self.user_embedding = nn.Embedding(num_users, embedding_dim)\n",
    "        self.item_embedding = nn.Embedding(num_items, embedding_dim)\n",
    "        \n",
    "        # Define a list of linear layers for each propagation layer\n",
    "        self.layers = nn.ModuleList([nn.Linear(embedding_dim, embedding_dim) for _ in range(n_layers)])\n",
    "        \n",
    "        # Dropout layer for regularization\n",
    "        self.dropout_layer = nn.Dropout(dropout)\n",
    "        \n",
    "        # Initialize the parameters of the model\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        \"\"\"\n",
    "        Initialize model parameters using Xavier uniform initialization.\n",
    "        \"\"\"\n",
    "        nn.init.xavier_uniform_(self.user_embedding.weight)\n",
    "        nn.init.xavier_uniform_(self.item_embedding.weight)\n",
    "        for layer in self.layers:\n",
    "            nn.init.xavier_uniform_(layer.weight)\n",
    "\n",
    "    def message_dropout_func(self, graph):\n",
    "        \"\"\"\n",
    "        Apply message dropout during graph convolution.\n",
    "\n",
    "        Args:\n",
    "            graph (SparseTensor): The graph's sparse adjacency matrix.\n",
    "\n",
    "        Returns:\n",
    "            SparseTensor: The adjacency matrix after applying message dropout.\n",
    "        \"\"\"\n",
    "        if self.message_dropout > 0:\n",
    "            row, col, value = graph.coo()\n",
    "            mask = torch.rand(row.size(0)) > self.message_dropout\n",
    "            row, col, value = row[mask], col[mask], value[mask]\n",
    "            graph = SparseTensor(row=row, col=col, value=value, sparse_sizes=graph.sparse_sizes())\n",
    "        return graph\n",
    "\n",
    "    def node_dropout_func(self, embeddings):\n",
    "        \"\"\"\n",
    "        Apply node dropout to the embeddings.\n",
    "\n",
    "        Args:\n",
    "            embeddings (torch.Tensor): The node embeddings.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: The embeddings after applying node dropout.\n",
    "        \"\"\"\n",
    "        if self.node_dropout > 0:\n",
    "            mask = (torch.rand(embeddings.size(0)) > self.node_dropout).float().to(embeddings.device)\n",
    "            embeddings = embeddings * mask.unsqueeze(1)\n",
    "        return embeddings\n",
    "\n",
    "    def forward(self, graph):\n",
    "        \"\"\"\n",
    "        Forward pass for the NGCF model.\n",
    "\n",
    "        Args:\n",
    "            graph (SparseTensor): The graph's sparse adjacency matrix.\n",
    "\n",
    "        Returns:\n",
    "            Tuple[torch.Tensor, torch.Tensor]: Final user and item embeddings.\n",
    "        \"\"\"\n",
    "        user_emb = self.user_embedding.weight\n",
    "        item_emb = self.item_embedding.weight\n",
    "        \n",
    "        # Apply node dropout to user and item embeddings\n",
    "        user_emb = self.node_dropout_func(user_emb)\n",
    "        item_emb = self.node_dropout_func(item_emb)\n",
    "        \n",
    "        # Concatenate user and item embeddings\n",
    "        all_emb = torch.cat([user_emb, item_emb], dim=0)\n",
    "        embs = [all_emb]\n",
    "\n",
    "        # Perform message passing and propagate embeddings through layers\n",
    "        for layer in self.layers:\n",
    "            graph = self.message_dropout_func(graph)\n",
    "            # Preventing CUDA/Library version error\n",
    "            try:\n",
    "                all_emb = matmul(graph, all_emb)\n",
    "            except RuntimeError as e:\n",
    "                break\n",
    "            all_emb = layer(all_emb)\n",
    "            all_emb = torch.relu(all_emb)\n",
    "            all_emb = self.dropout_layer(all_emb)\n",
    "            embs.append(all_emb)\n",
    "\n",
    "        # Compute the final embeddings by averaging the embeddings across layers\n",
    "        final_embedding = torch.mean(torch.stack(embs, dim=1), dim=1)\n",
    "        \n",
    "        # Split the final embeddings back into user and item embeddings\n",
    "        user_emb_final, item_emb_final = torch.split(final_embedding, [self.num_users, self.num_items])\n",
    "\n",
    "        return user_emb_final, item_emb_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "383f2777-5652-4d39-a111-9f8f71865f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from recpack.algorithms.base import TorchMLAlgorithm\n",
    "from recpack.matrix import Matrix\n",
    "from recpack.matrix.interaction_matrix import InteractionMatrix\n",
    "from recpack.algorithms.loss_functions import bpr_loss\n",
    "from recpack.algorithms.samplers import PositiveNegativeSampler\n",
    "from recpack.algorithms.stopping_criterion import (\n",
    "    EarlyStoppingException,\n",
    "    StoppingCriterion,\n",
    ")\n",
    "from typing import List, Tuple, Optional\n",
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix, lil_matrix, coo_matrix\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import tempfile\n",
    "import time\n",
    "import logging\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# NGCFAlgorithm: An implementation of the NGCF algorithm using TorchMLAlgorithm as a base class\n",
    "class NGCFAlgorithm(TorchMLAlgorithm):\n",
    "    def __init__(\n",
    "        self,\n",
    "        batch_size: int = 256,\n",
    "        max_epochs: int = 100,\n",
    "        learning_rate: float = 0.001,\n",
    "        embedding_dim: int = 64,\n",
    "        n_layers: int = 3,\n",
    "        dropout: float = 0.1,\n",
    "        node_dropout: float = 0.0,\n",
    "        message_dropout: float = 0.0,\n",
    "        stopping_criterion: str = \"bpr\",\n",
    "        stop_early: bool = True,\n",
    "        max_iter_no_change: int = 5,\n",
    "        min_improvement: float = 0.01,\n",
    "        seed: Optional[int] = None,\n",
    "        save_best_to_file: bool = False,\n",
    "        keep_last: bool = False,\n",
    "        predict_topK: Optional[int] = None,\n",
    "        validation_sample_size: Optional[int] = None,\n",
    "        grad_clip: float = 1.0,  # Gradient clipping value\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Initialize the NGCFAlgorithm with various hyperparameters.\n",
    "\n",
    "        Args:\n",
    "            batch_size (int): Number of samples per batch.\n",
    "            max_epochs (int): Maximum number of training epochs.\n",
    "            learning_rate (float): Learning rate for the optimizer.\n",
    "            embedding_dim (int): Dimension of the embedding vectors.\n",
    "            n_layers (int): Number of hidden layers in the NGCF model.\n",
    "            dropout (float): Dropout rate for regularization.\n",
    "            node_dropout (float): Dropout rate applied to node embeddings.\n",
    "            message_dropout (float): Dropout rate applied during message passing.\n",
    "            stopping_criterion (str): Criterion to stop training early.\n",
    "            stop_early (bool): Whether to enable early stopping.\n",
    "            max_iter_no_change (int): Maximum iterations with no improvement for early stopping.\n",
    "            min_improvement (float): Minimum improvement required for early stopping.\n",
    "            seed (Optional[int]): Random seed for reproducibility.\n",
    "            save_best_to_file (bool): Whether to save the best model to a file.\n",
    "            keep_last (bool): Whether to keep the last model.\n",
    "            predict_topK (Optional[int]): Number of top-K predictions to consider.\n",
    "            validation_sample_size (Optional[int]): Size of the validation sample.\n",
    "            grad_clip (float): Maximum gradient norm for clipping.\n",
    "        \"\"\"\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.n_layers = n_layers\n",
    "        self.dropout = dropout\n",
    "        self.node_dropout = node_dropout\n",
    "        self.message_dropout = message_dropout\n",
    "        self.grad_clip = grad_clip\n",
    "        super().__init__(\n",
    "            batch_size=batch_size,\n",
    "            max_epochs=max_epochs,\n",
    "            learning_rate=learning_rate,\n",
    "            stopping_criterion=stopping_criterion,\n",
    "            stop_early=stop_early,\n",
    "            max_iter_no_change=max_iter_no_change,\n",
    "            min_improvement=min_improvement,\n",
    "            seed=seed,\n",
    "            save_best_to_file=save_best_to_file,\n",
    "            keep_last=keep_last,\n",
    "            predict_topK=predict_topK,\n",
    "            validation_sample_size=validation_sample_size,\n",
    "        )\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    def _init_model(self, train: InteractionMatrix) -> None:\n",
    "        \"\"\"\n",
    "        Initialize the NGCF model and optimizer.\n",
    "\n",
    "        Args:\n",
    "            train (InteractionMatrix): The training interaction matrix.\n",
    "        \"\"\"\n",
    "        num_users, num_items = train.shape\n",
    "        self.model_ = NGCF(num_users, num_items, self.embedding_dim, self.n_layers, self.dropout, self.node_dropout, self.message_dropout).to(self.device)\n",
    "        self.optimizer = optim.Adam(self.model_.parameters(), lr=self.learning_rate)\n",
    "\n",
    "    def _create_sparse_graph(self, interaction_matrix: csr_matrix, num_users: int, num_items: int) -> SparseTensor:\n",
    "        \"\"\"\n",
    "        Create a sparse graph from the interaction matrix.\n",
    "\n",
    "        Args:\n",
    "            interaction_matrix (csr_matrix): The interaction matrix in CSR format.\n",
    "            num_users (int): Number of users.\n",
    "            num_items (int): Number of items.\n",
    "\n",
    "        Returns:\n",
    "            SparseTensor: A sparse tensor representing the graph.\n",
    "        \"\"\"\n",
    "        coo = interaction_matrix.tocoo()\n",
    "        row = torch.tensor(coo.row, dtype=torch.long)\n",
    "        col = torch.tensor(coo.col, dtype=torch.long)\n",
    "        value = torch.tensor(coo.data, dtype=torch.float32)\n",
    "        shape = (num_users + num_items, num_users + num_items)\n",
    "        graph = SparseTensor(row=row, col=col, value=value, sparse_sizes=shape).to(self.device)\n",
    "        return graph\n",
    "\n",
    "    def _train_epoch(self, train: InteractionMatrix) -> List[float]:\n",
    "        \"\"\"\n",
    "        Train the model for one epoch.\n",
    "\n",
    "        Args:\n",
    "            train (InteractionMatrix): The training interaction matrix.\n",
    "\n",
    "        Returns:\n",
    "            List[float]: A list of losses for each batch.\n",
    "        \"\"\"\n",
    "        self.model_.train()\n",
    "        interaction_matrix = train  # Get the sparse matrix directly\n",
    "        graph = self._create_sparse_graph(interaction_matrix, train.shape[0], train.shape[1])\n",
    "        total_loss = 0\n",
    "        losses = []\n",
    "\n",
    "        sampler = PositiveNegativeSampler(num_negatives=1, batch_size=self.batch_size)\n",
    "\n",
    "        # Iterate over samples generated by the PositiveNegativeSampler\n",
    "        for user_indices, pos_item_indices, neg_item_indices in sampler.sample(interaction_matrix):\n",
    "            user_indices = torch.tensor(user_indices).to(self.device)\n",
    "            pos_item_indices = torch.tensor(pos_item_indices).to(self.device)\n",
    "            neg_item_indices = torch.tensor(neg_item_indices).to(self.device).squeeze()\n",
    "\n",
    "            self.optimizer.zero_grad()\n",
    "            user_emb_final, item_emb_final = self.model_(graph)  # Call model only once\n",
    "            pos_scores = user_emb_final[user_indices] @ item_emb_final[pos_item_indices].t()\n",
    "            neg_scores = user_emb_final[user_indices] @ item_emb_final[neg_item_indices].t()\n",
    "\n",
    "            loss = bpr_loss(pos_scores, neg_scores)\n",
    "\n",
    "            if torch.isnan(loss).any() or torch.isinf(loss).any():\n",
    "                continue\n",
    "\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(self.model_.parameters(), max_norm=self.grad_clip)  # Gradient clipping\n",
    "            self.optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            losses.append(loss.item())\n",
    "\n",
    "        if len(losses) == 0:\n",
    "            return [float('nan')]\n",
    "\n",
    "        return losses\n",
    "\n",
    "    def _batch_predict(self, X: InteractionMatrix, users: List[int]) -> csr_matrix:\n",
    "        \"\"\"\n",
    "        Make batch predictions for a list of users.\n",
    "\n",
    "        Args:\n",
    "            X (InteractionMatrix): The interaction matrix.\n",
    "            users (List[int]): List of user indices to make predictions for.\n",
    "\n",
    "        Returns:\n",
    "            csr_matrix: A sparse matrix with the prediction scores.\n",
    "        \"\"\"\n",
    "        self.model_.eval()\n",
    "        graph = self._create_sparse_graph(X, X.shape[0], X.shape[1])\n",
    "        user_indices = torch.tensor(users).to(self.device)\n",
    "        item_indices = torch.arange(X.shape[1]).to(self.device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            user_emb_final, item_emb_final = self.model_(graph)\n",
    "            scores = user_emb_final[user_indices] @ item_emb_final.t()\n",
    "            scores = scores.cpu().numpy()\n",
    "        \n",
    "        result = lil_matrix((X.shape[0], X.shape[1]))\n",
    "        for i, user in enumerate(users):\n",
    "            result[user] = scores[i]\n",
    "        \n",
    "        return result.tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e87fd90c-f8ae-4fcc-a455-90fb8f2335c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from recpack.datasets import Netflix, DummyDataset\n",
    "from recpack.pipelines import PipelineBuilder\n",
    "from recpack.scenarios import StrongGeneralization\n",
    "from recpack.pipelines import ALGORITHM_REGISTRY\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "03a047ff-a58e-4ffb-bb09-247622834b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "ALGORITHM_REGISTRY.register(\"NGCFAlgorithm\", NGCFAlgorithm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e9e22ff-b273-402c-90ec-5c0bf79bf1ee",
   "metadata": {},
   "source": [
    "## RecPack Dataset Importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "288305e2-e570-4286-8468-c902e9d7ca25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from recpack.datasets import MillionSongDataset\n",
    "dataset = MillionSongDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9c73499f-1c14-4241-a0bd-e3412b4efd34",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.fetch_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "25bb2d15-0f4f-4142-8d5d-e06a6ea3c024",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<recpack.datasets.million_song_dataset.MillionSongDataset at 0x7fd431e55250>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a290f199-0a3d-4c2b-bc30-c82b5254ab34",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dataset._load_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2416707-181d-454a-ab2d-3ed48c915b59",
   "metadata": {},
   "source": [
    "## Datasets without Timestamps sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1a8f89ff-2a37-4298-84ac-aab75885b0f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count interactions per user and per song\n",
    "user_interactions = df['userId'].value_counts().reset_index()\n",
    "user_interactions.columns = ['userId', 'user_interactions']\n",
    "\n",
    "song_interactions = df['songId'].value_counts().reset_index()\n",
    "song_interactions.columns = ['songId', 'song_interactions']\n",
    "\n",
    "# Merge the interaction counts back to the original dataframe\n",
    "df = df.merge(user_interactions, on='userId')\n",
    "df = df.merge(song_interactions, on='songId')\n",
    "\n",
    "# Calculate a combined interaction score\n",
    "df['interaction_score'] = df['user_interactions'] + df['song_interactions']\n",
    "\n",
    "# Rank based on the interaction score\n",
    "df['rank'] = df['interaction_score'].rank(method='first', ascending=False)\n",
    "\n",
    "# Select the top 10%\n",
    "filtered_df = df[df['rank'] <= len(df) * 0.1]\n",
    "\n",
    "# Drop helper columns\n",
    "filtered_df = filtered_df.drop(columns=['user_interactions', 'song_interactions', 'interaction_score', 'rank'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "877cfa8a-c9d3-4436-8a74-5009b026f266",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>songId</th>\n",
       "      <th>user_interactions</th>\n",
       "      <th>song_interactions</th>\n",
       "      <th>interaction_score</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b80344d063b5ccb3212f76538f3d9e43d87dca9e</td>\n",
       "      <td>SOAKIMP12A8C130995</td>\n",
       "      <td>142</td>\n",
       "      <td>6698</td>\n",
       "      <td>6840</td>\n",
       "      <td>55439149.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b80344d063b5ccb3212f76538f3d9e43d87dca9e</td>\n",
       "      <td>SOAPDEY12A81C210A9</td>\n",
       "      <td>142</td>\n",
       "      <td>2012</td>\n",
       "      <td>2154</td>\n",
       "      <td>91117622.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b80344d063b5ccb3212f76538f3d9e43d87dca9e</td>\n",
       "      <td>SOBBMDR12A8C13253B</td>\n",
       "      <td>142</td>\n",
       "      <td>6383</td>\n",
       "      <td>6525</td>\n",
       "      <td>56840187.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b80344d063b5ccb3212f76538f3d9e43d87dca9e</td>\n",
       "      <td>SOBBMDR12A8C13253B</td>\n",
       "      <td>142</td>\n",
       "      <td>6383</td>\n",
       "      <td>6525</td>\n",
       "      <td>56840188.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b80344d063b5ccb3212f76538f3d9e43d87dca9e</td>\n",
       "      <td>SOBFNSP12AF72A0E22</td>\n",
       "      <td>142</td>\n",
       "      <td>687</td>\n",
       "      <td>829</td>\n",
       "      <td>117735248.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138680238</th>\n",
       "      <td>b7815dbb206eb2831ce0fe040d0aa537e2e800f7</td>\n",
       "      <td>SOUSMXX12AB0185C24</td>\n",
       "      <td>56</td>\n",
       "      <td>155529</td>\n",
       "      <td>155585</td>\n",
       "      <td>6266409.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138680239</th>\n",
       "      <td>b7815dbb206eb2831ce0fe040d0aa537e2e800f7</td>\n",
       "      <td>SOWYSKH12AF72A303A</td>\n",
       "      <td>56</td>\n",
       "      <td>3306</td>\n",
       "      <td>3362</td>\n",
       "      <td>77443084.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138680240</th>\n",
       "      <td>b7815dbb206eb2831ce0fe040d0aa537e2e800f7</td>\n",
       "      <td>SOWYSKH12AF72A303A</td>\n",
       "      <td>56</td>\n",
       "      <td>3306</td>\n",
       "      <td>3362</td>\n",
       "      <td>77443085.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138680241</th>\n",
       "      <td>b7815dbb206eb2831ce0fe040d0aa537e2e800f7</td>\n",
       "      <td>SOWYSKH12AF72A303A</td>\n",
       "      <td>56</td>\n",
       "      <td>3306</td>\n",
       "      <td>3362</td>\n",
       "      <td>77443086.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138680242</th>\n",
       "      <td>b7815dbb206eb2831ce0fe040d0aa537e2e800f7</td>\n",
       "      <td>SOYYFLV12A58A7A88F</td>\n",
       "      <td>56</td>\n",
       "      <td>11180</td>\n",
       "      <td>11236</td>\n",
       "      <td>41942670.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>138680243 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             userId              songId  \\\n",
       "0          b80344d063b5ccb3212f76538f3d9e43d87dca9e  SOAKIMP12A8C130995   \n",
       "1          b80344d063b5ccb3212f76538f3d9e43d87dca9e  SOAPDEY12A81C210A9   \n",
       "2          b80344d063b5ccb3212f76538f3d9e43d87dca9e  SOBBMDR12A8C13253B   \n",
       "3          b80344d063b5ccb3212f76538f3d9e43d87dca9e  SOBBMDR12A8C13253B   \n",
       "4          b80344d063b5ccb3212f76538f3d9e43d87dca9e  SOBFNSP12AF72A0E22   \n",
       "...                                             ...                 ...   \n",
       "138680238  b7815dbb206eb2831ce0fe040d0aa537e2e800f7  SOUSMXX12AB0185C24   \n",
       "138680239  b7815dbb206eb2831ce0fe040d0aa537e2e800f7  SOWYSKH12AF72A303A   \n",
       "138680240  b7815dbb206eb2831ce0fe040d0aa537e2e800f7  SOWYSKH12AF72A303A   \n",
       "138680241  b7815dbb206eb2831ce0fe040d0aa537e2e800f7  SOWYSKH12AF72A303A   \n",
       "138680242  b7815dbb206eb2831ce0fe040d0aa537e2e800f7  SOYYFLV12A58A7A88F   \n",
       "\n",
       "           user_interactions  song_interactions  interaction_score  \\\n",
       "0                        142               6698               6840   \n",
       "1                        142               2012               2154   \n",
       "2                        142               6383               6525   \n",
       "3                        142               6383               6525   \n",
       "4                        142                687                829   \n",
       "...                      ...                ...                ...   \n",
       "138680238                 56             155529             155585   \n",
       "138680239                 56               3306               3362   \n",
       "138680240                 56               3306               3362   \n",
       "138680241                 56               3306               3362   \n",
       "138680242                 56              11180              11236   \n",
       "\n",
       "                  rank  \n",
       "0           55439149.0  \n",
       "1           91117622.0  \n",
       "2           56840187.0  \n",
       "3           56840188.0  \n",
       "4          117735248.0  \n",
       "...                ...  \n",
       "138680238    6266409.0  \n",
       "138680239   77443084.0  \n",
       "138680240   77443085.0  \n",
       "138680241   77443086.0  \n",
       "138680242   41942670.0  \n",
       "\n",
       "[138680243 rows x 6 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "75315c82-bb45-4090-8d92-87e16d42f204",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>songId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>b80344d063b5ccb3212f76538f3d9e43d87dca9e</td>\n",
       "      <td>SOFRQTD12A81C233C0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>b80344d063b5ccb3212f76538f3d9e43d87dca9e</td>\n",
       "      <td>SOMGIYR12AB0187973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>b80344d063b5ccb3212f76538f3d9e43d87dca9e</td>\n",
       "      <td>SOMGIYR12AB0187973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>b80344d063b5ccb3212f76538f3d9e43d87dca9e</td>\n",
       "      <td>SOMGIYR12AB0187973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>b80344d063b5ccb3212f76538f3d9e43d87dca9e</td>\n",
       "      <td>SOMGIYR12AB0187973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138680210</th>\n",
       "      <td>b7815dbb206eb2831ce0fe040d0aa537e2e800f7</td>\n",
       "      <td>SOOFYTN12A6D4F9B35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138680211</th>\n",
       "      <td>b7815dbb206eb2831ce0fe040d0aa537e2e800f7</td>\n",
       "      <td>SOOFYTN12A6D4F9B35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138680212</th>\n",
       "      <td>b7815dbb206eb2831ce0fe040d0aa537e2e800f7</td>\n",
       "      <td>SOOFYTN12A6D4F9B35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138680237</th>\n",
       "      <td>b7815dbb206eb2831ce0fe040d0aa537e2e800f7</td>\n",
       "      <td>SOUJVIT12A8C1451C1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138680238</th>\n",
       "      <td>b7815dbb206eb2831ce0fe040d0aa537e2e800f7</td>\n",
       "      <td>SOUSMXX12AB0185C24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13868024 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             userId              songId\n",
       "28         b80344d063b5ccb3212f76538f3d9e43d87dca9e  SOFRQTD12A81C233C0\n",
       "59         b80344d063b5ccb3212f76538f3d9e43d87dca9e  SOMGIYR12AB0187973\n",
       "60         b80344d063b5ccb3212f76538f3d9e43d87dca9e  SOMGIYR12AB0187973\n",
       "61         b80344d063b5ccb3212f76538f3d9e43d87dca9e  SOMGIYR12AB0187973\n",
       "62         b80344d063b5ccb3212f76538f3d9e43d87dca9e  SOMGIYR12AB0187973\n",
       "...                                             ...                 ...\n",
       "138680210  b7815dbb206eb2831ce0fe040d0aa537e2e800f7  SOOFYTN12A6D4F9B35\n",
       "138680211  b7815dbb206eb2831ce0fe040d0aa537e2e800f7  SOOFYTN12A6D4F9B35\n",
       "138680212  b7815dbb206eb2831ce0fe040d0aa537e2e800f7  SOOFYTN12A6D4F9B35\n",
       "138680237  b7815dbb206eb2831ce0fe040d0aa537e2e800f7  SOUJVIT12A8C1451C1\n",
       "138680238  b7815dbb206eb2831ce0fe040d0aa537e2e800f7  SOUSMXX12AB0185C24\n",
       "\n",
       "[13868024 rows x 2 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e34cbc4-7331-4e55-897a-720d01d0a7d4",
   "metadata": {},
   "source": [
    "## Dataset Preprocessing to Interaction Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7224c285-27bf-40e5-b0a6-b1dca7431d16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "705811746dde49f8a428ae353bb654b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13868024 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e90f0572a524456cb0fa80113088e84c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13868024 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from recpack.matrix import InteractionMatrix\n",
    "from recpack.preprocessing.preprocessors import DataFramePreprocessor\n",
    "item_ix = 'songId'\n",
    "user_ix = 'userId'\n",
    "\n",
    "preprocessor = DataFramePreprocessor(item_ix=item_ix, user_ix=user_ix)\n",
    "interaction_matrix = preprocessor.process(filtered_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74fff232-c1ec-4649-97d0-194cda1907d3",
   "metadata": {},
   "source": [
    "## StrongGeneralization Scenario Splitting of Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "aa72bb09-e745-4c5f-b4b3-88785f8a96b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02cfa8d95a88423c9a1ed2fe3e8e88a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7267cdbe6b004faa911e62c4133dac8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "scenario = StrongGeneralization(frac_users_train=0.7, frac_interactions_in=0.8, validation=True)\n",
    "scenario.split(interaction_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a6e657d-1a70-4bae-84a5-972aa35d1e5f",
   "metadata": {},
   "source": [
    "## Experimental RecPack Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "51e133b8-daff-4e2a-a3b6-9747347f3425",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/recpack/pipelines/pipeline_builder.py:145: UserWarning: Grid parameter for add_algorithm function will be deprecated in favour of optimisation_info.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f7d82a5476b4fb38cdc6bf9b2d96869",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_22261/1947374894.py:89: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  user_indices = torch.tensor(user_indices).to(self.device)\n",
      "/tmp/ipykernel_22261/1947374894.py:90: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  pos_item_indices = torch.tensor(pos_item_indices).to(self.device)\n",
      "/tmp/ipykernel_22261/1947374894.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  neg_item_indices = torch.tensor(neg_item_indices).to(self.device).squeeze()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-31 19:34:49,846 - base - recpack - INFO - Processed epoch 0 in 20.36 s.Batch Training Loss = 0.6367\n",
      "2024-07-31 19:37:43,609 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.6931591869917388, which is better than previous iterations.\n",
      "2024-07-31 19:37:43,612 - base - recpack - INFO - Evaluation at end of 0 took 173.76 s.\n",
      "2024-07-31 19:37:50,432 - base - recpack - INFO - Processed epoch 1 in 6.82 s.Batch Training Loss = 0.9321\n",
      "2024-07-31 19:40:52,663 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.6931874539860765, which is worse than previous iterations.\n",
      "2024-07-31 19:40:52,666 - base - recpack - INFO - Evaluation at end of 1 took 182.23 s.\n",
      "2024-07-31 19:40:59,759 - base - recpack - INFO - Processed epoch 2 in 7.09 s.Batch Training Loss = 0.7992\n",
      "2024-07-31 19:44:03,072 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.6931576623125174, which is worse than previous iterations.\n",
      "2024-07-31 19:44:03,074 - base - recpack - INFO - Evaluation at end of 2 took 183.31 s.\n",
      "2024-07-31 19:44:09,975 - base - recpack - INFO - Processed epoch 3 in 6.90 s.Batch Training Loss = 3.9052\n",
      "2024-07-31 19:47:13,875 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.6931560429574181, which is worse than previous iterations.\n",
      "2024-07-31 19:47:13,878 - base - recpack - INFO - Evaluation at end of 3 took 183.90 s.\n",
      "2024-07-31 19:47:20,697 - base - recpack - INFO - Processed epoch 4 in 6.82 s.Batch Training Loss = 1.4158\n",
      "2024-07-31 19:50:26,563 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.6931699669987792, which is worse than previous iterations.\n",
      "2024-07-31 19:50:26,565 - base - recpack - INFO - Evaluation at end of 4 took 185.87 s.\n",
      "2024-07-31 19:50:27,255 - base - recpack - INFO - Fitting NGCFAlgorithm complete - Took 9.59e+02s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_22261/1947374894.py:89: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  user_indices = torch.tensor(user_indices).to(self.device)\n",
      "/tmp/ipykernel_22261/1947374894.py:90: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  pos_item_indices = torch.tensor(pos_item_indices).to(self.device)\n",
      "/tmp/ipykernel_22261/1947374894.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  neg_item_indices = torch.tensor(neg_item_indices).to(self.device).squeeze()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-31 19:53:59,205 - base - recpack - INFO - Processed epoch 0 in 20.78 s.Batch Training Loss = 0.5572\n",
      "2024-07-31 19:57:06,346 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.6931514638177617, which is better than previous iterations.\n",
      "2024-07-31 19:57:06,349 - base - recpack - INFO - Evaluation at end of 0 took 187.14 s.\n",
      "2024-07-31 19:57:27,712 - base - recpack - INFO - Processed epoch 1 in 21.36 s.Batch Training Loss = 0.5309\n",
      "2024-07-31 20:00:34,255 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.6931341606943303, which is worse than previous iterations.\n",
      "2024-07-31 20:00:34,257 - base - recpack - INFO - Evaluation at end of 1 took 186.54 s.\n",
      "2024-07-31 20:00:55,931 - base - recpack - INFO - Processed epoch 2 in 21.67 s.Batch Training Loss = 0.5281\n",
      "2024-07-31 20:04:04,748 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.6931276807848411, which is worse than previous iterations.\n",
      "2024-07-31 20:04:04,750 - base - recpack - INFO - Evaluation at end of 2 took 188.82 s.\n",
      "2024-07-31 20:04:25,638 - base - recpack - INFO - Processed epoch 3 in 20.89 s.Batch Training Loss = 0.5278\n",
      "2024-07-31 20:07:33,852 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.6931266444128548, which is worse than previous iterations.\n",
      "2024-07-31 20:07:33,855 - base - recpack - INFO - Evaluation at end of 3 took 188.21 s.\n",
      "2024-07-31 20:07:54,300 - base - recpack - INFO - Processed epoch 4 in 20.44 s.Batch Training Loss = 0.5254\n",
      "2024-07-31 20:11:02,913 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.6931541302329216, which is worse than previous iterations.\n",
      "2024-07-31 20:11:02,916 - base - recpack - INFO - Evaluation at end of 4 took 188.61 s.\n",
      "2024-07-31 20:11:03,676 - base - recpack - INFO - Fitting NGCFAlgorithm complete - Took 1.05e+03s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_22261/1947374894.py:89: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  user_indices = torch.tensor(user_indices).to(self.device)\n",
      "/tmp/ipykernel_22261/1947374894.py:90: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  pos_item_indices = torch.tensor(pos_item_indices).to(self.device)\n",
      "/tmp/ipykernel_22261/1947374894.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  neg_item_indices = torch.tensor(neg_item_indices).to(self.device).squeeze()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-31 20:14:40,246 - base - recpack - INFO - Processed epoch 0 in 20.88 s.Batch Training Loss = 0.5731\n",
      "2024-07-31 20:17:45,747 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.6931688405041898, which is better than previous iterations.\n",
      "2024-07-31 20:17:45,751 - base - recpack - INFO - Evaluation at end of 0 took 185.50 s.\n",
      "2024-07-31 20:18:06,209 - base - recpack - INFO - Processed epoch 1 in 20.46 s.Batch Training Loss = 0.5275\n",
      "2024-07-31 20:21:14,022 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.6931765630724335, which is worse than previous iterations.\n",
      "2024-07-31 20:21:14,025 - base - recpack - INFO - Evaluation at end of 1 took 187.81 s.\n",
      "2024-07-31 20:21:34,326 - base - recpack - INFO - Processed epoch 2 in 20.30 s.Batch Training Loss = 0.5247\n",
      "2024-07-31 20:24:40,946 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.6931704202228989, which is worse than previous iterations.\n",
      "2024-07-31 20:24:40,949 - base - recpack - INFO - Evaluation at end of 2 took 186.62 s.\n",
      "2024-07-31 20:25:01,417 - base - recpack - INFO - Processed epoch 3 in 20.47 s.Batch Training Loss = 0.5238\n",
      "2024-07-31 20:28:08,385 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.6932028980747051, which is worse than previous iterations.\n",
      "2024-07-31 20:28:08,388 - base - recpack - INFO - Evaluation at end of 3 took 186.97 s.\n",
      "2024-07-31 20:28:29,342 - base - recpack - INFO - Processed epoch 4 in 20.95 s.Batch Training Loss = 0.5236\n",
      "2024-07-31 20:31:35,707 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.6931934861716599, which is worse than previous iterations.\n",
      "2024-07-31 20:31:35,709 - base - recpack - INFO - Evaluation at end of 4 took 186.36 s.\n",
      "2024-07-31 20:31:36,417 - base - recpack - INFO - Fitting NGCFAlgorithm complete - Took 1.04e+03s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_22261/1947374894.py:89: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  user_indices = torch.tensor(user_indices).to(self.device)\n",
      "/tmp/ipykernel_22261/1947374894.py:90: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  pos_item_indices = torch.tensor(pos_item_indices).to(self.device)\n",
      "/tmp/ipykernel_22261/1947374894.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  neg_item_indices = torch.tensor(neg_item_indices).to(self.device).squeeze()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-31 20:35:09,198 - base - recpack - INFO - Processed epoch 0 in 21.30 s.Batch Training Loss = 0.6325\n",
      "2024-07-31 20:38:15,028 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.6931999929876389, which is better than previous iterations.\n",
      "2024-07-31 20:38:15,031 - base - recpack - INFO - Evaluation at end of 0 took 185.83 s.\n",
      "2024-07-31 20:38:22,349 - base - recpack - INFO - Processed epoch 1 in 7.32 s.Batch Training Loss = 0.7512\n",
      "2024-07-31 20:41:28,326 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.6931906824336803, which is worse than previous iterations.\n",
      "2024-07-31 20:41:28,328 - base - recpack - INFO - Evaluation at end of 1 took 185.98 s.\n",
      "2024-07-31 20:41:35,555 - base - recpack - INFO - Processed epoch 2 in 7.23 s.Batch Training Loss = nan\n",
      "2024-07-31 20:44:42,391 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.6931914418503827, which is worse than previous iterations.\n",
      "2024-07-31 20:44:42,393 - base - recpack - INFO - Evaluation at end of 2 took 186.84 s.\n",
      "2024-07-31 20:44:49,519 - base - recpack - INFO - Processed epoch 3 in 7.12 s.Batch Training Loss = 0.5530\n",
      "2024-07-31 20:47:56,084 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.6931636273792917, which is worse than previous iterations.\n",
      "2024-07-31 20:47:56,087 - base - recpack - INFO - Evaluation at end of 3 took 186.57 s.\n",
      "2024-07-31 20:48:03,125 - base - recpack - INFO - Processed epoch 4 in 7.04 s.Batch Training Loss = 0.9747\n",
      "2024-07-31 20:51:08,316 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.6931808329883654, which is worse than previous iterations.\n",
      "2024-07-31 20:51:08,318 - base - recpack - INFO - Evaluation at end of 4 took 185.19 s.\n",
      "2024-07-31 20:51:08,995 - base - recpack - INFO - Fitting NGCFAlgorithm complete - Took 9.82e+02s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_22261/1947374894.py:89: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  user_indices = torch.tensor(user_indices).to(self.device)\n",
      "/tmp/ipykernel_22261/1947374894.py:90: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  pos_item_indices = torch.tensor(pos_item_indices).to(self.device)\n",
      "/tmp/ipykernel_22261/1947374894.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  neg_item_indices = torch.tensor(neg_item_indices).to(self.device).squeeze()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-31 20:54:40,331 - base - recpack - INFO - Processed epoch 0 in 20.89 s.Batch Training Loss = 0.5576\n",
      "2024-07-31 20:57:47,175 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.6931292418260323, which is better than previous iterations.\n",
      "2024-07-31 20:57:47,177 - base - recpack - INFO - Evaluation at end of 0 took 186.84 s.\n",
      "2024-07-31 20:58:08,128 - base - recpack - INFO - Processed epoch 1 in 20.95 s.Batch Training Loss = 0.5311\n",
      "2024-07-31 21:01:13,510 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.6931056038968073, which is worse than previous iterations.\n",
      "2024-07-31 21:01:13,513 - base - recpack - INFO - Evaluation at end of 1 took 185.38 s.\n",
      "2024-07-31 21:01:34,018 - base - recpack - INFO - Processed epoch 2 in 20.50 s.Batch Training Loss = 0.5279\n",
      "2024-07-31 21:04:40,576 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.693120298879582, which is worse than previous iterations.\n",
      "2024-07-31 21:04:40,579 - base - recpack - INFO - Evaluation at end of 2 took 186.56 s.\n",
      "2024-07-31 21:05:01,219 - base - recpack - INFO - Processed epoch 3 in 20.64 s.Batch Training Loss = 0.5274\n",
      "2024-07-31 21:08:06,591 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.693132464336142, which is worse than previous iterations.\n",
      "2024-07-31 21:08:06,597 - base - recpack - INFO - Evaluation at end of 3 took 185.38 s.\n",
      "2024-07-31 21:08:27,457 - base - recpack - INFO - Processed epoch 4 in 20.86 s.Batch Training Loss = 0.5264\n",
      "2024-07-31 21:11:34,110 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.6931512807457451, which is worse than previous iterations.\n",
      "2024-07-31 21:11:34,112 - base - recpack - INFO - Evaluation at end of 4 took 186.65 s.\n",
      "2024-07-31 21:11:34,829 - base - recpack - INFO - Fitting NGCFAlgorithm complete - Took 1.04e+03s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_22261/1947374894.py:89: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  user_indices = torch.tensor(user_indices).to(self.device)\n",
      "/tmp/ipykernel_22261/1947374894.py:90: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  pos_item_indices = torch.tensor(pos_item_indices).to(self.device)\n",
      "/tmp/ipykernel_22261/1947374894.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  neg_item_indices = torch.tensor(neg_item_indices).to(self.device).squeeze()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-31 21:15:10,068 - base - recpack - INFO - Processed epoch 0 in 20.87 s.Batch Training Loss = 0.5735\n",
      "2024-07-31 21:18:14,744 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.6931524677199823, which is better than previous iterations.\n",
      "2024-07-31 21:18:14,747 - base - recpack - INFO - Evaluation at end of 0 took 184.68 s.\n",
      "2024-07-31 21:18:36,046 - base - recpack - INFO - Processed epoch 1 in 21.30 s.Batch Training Loss = 0.5275\n",
      "2024-07-31 21:21:43,644 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.693139799592038, which is worse than previous iterations.\n",
      "2024-07-31 21:21:43,646 - base - recpack - INFO - Evaluation at end of 1 took 187.60 s.\n",
      "2024-07-31 21:22:05,261 - base - recpack - INFO - Processed epoch 2 in 21.61 s.Batch Training Loss = 0.5239\n",
      "2024-07-31 21:25:12,388 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.6931604858544702, which is worse than previous iterations.\n",
      "2024-07-31 21:25:12,391 - base - recpack - INFO - Evaluation at end of 2 took 187.13 s.\n",
      "2024-07-31 21:25:33,553 - base - recpack - INFO - Processed epoch 3 in 21.16 s.Batch Training Loss = 0.5234\n",
      "2024-07-31 21:28:40,274 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.6931590134463281, which is worse than previous iterations.\n",
      "2024-07-31 21:28:40,276 - base - recpack - INFO - Evaluation at end of 3 took 186.72 s.\n",
      "2024-07-31 21:29:01,054 - base - recpack - INFO - Processed epoch 4 in 20.78 s.Batch Training Loss = 0.5239\n",
      "2024-07-31 21:32:06,676 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.6931769852711003, which is worse than previous iterations.\n",
      "2024-07-31 21:32:06,678 - base - recpack - INFO - Evaluation at end of 4 took 185.62 s.\n",
      "2024-07-31 21:32:07,403 - base - recpack - INFO - Fitting NGCFAlgorithm complete - Took 1.04e+03s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_22261/1947374894.py:89: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  user_indices = torch.tensor(user_indices).to(self.device)\n",
      "/tmp/ipykernel_22261/1947374894.py:90: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  pos_item_indices = torch.tensor(pos_item_indices).to(self.device)\n",
      "/tmp/ipykernel_22261/1947374894.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  neg_item_indices = torch.tensor(neg_item_indices).to(self.device).squeeze()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-31 21:35:41,013 - base - recpack - INFO - Processed epoch 0 in 21.13 s.Batch Training Loss = 0.6392\n",
      "2024-07-31 21:38:47,296 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.6931647181427589, which is better than previous iterations.\n",
      "2024-07-31 21:38:47,299 - base - recpack - INFO - Evaluation at end of 0 took 186.28 s.\n",
      "2024-07-31 21:38:54,605 - base - recpack - INFO - Processed epoch 1 in 7.31 s.Batch Training Loss = 0.9943\n",
      "2024-07-31 21:42:02,473 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.6931770050752495, which is worse than previous iterations.\n",
      "2024-07-31 21:42:02,475 - base - recpack - INFO - Evaluation at end of 1 took 187.87 s.\n",
      "2024-07-31 21:42:09,315 - base - recpack - INFO - Processed epoch 2 in 6.84 s.Batch Training Loss = 5.3003\n",
      "2024-07-31 21:45:16,838 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.693171817214475, which is worse than previous iterations.\n",
      "2024-07-31 21:45:16,840 - base - recpack - INFO - Evaluation at end of 2 took 187.52 s.\n",
      "2024-07-31 21:45:23,756 - base - recpack - INFO - Processed epoch 3 in 6.91 s.Batch Training Loss = 1.6747\n",
      "2024-07-31 21:48:29,811 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.6931928328677712, which is worse than previous iterations.\n",
      "2024-07-31 21:48:29,814 - base - recpack - INFO - Evaluation at end of 3 took 186.06 s.\n",
      "2024-07-31 21:48:36,915 - base - recpack - INFO - Processed epoch 4 in 7.10 s.Batch Training Loss = 2.4868\n",
      "2024-07-31 21:51:45,776 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.6931991278794802, which is worse than previous iterations.\n",
      "2024-07-31 21:51:45,780 - base - recpack - INFO - Evaluation at end of 4 took 188.86 s.\n",
      "2024-07-31 21:51:46,484 - base - recpack - INFO - Fitting NGCFAlgorithm complete - Took 9.88e+02s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_22261/1947374894.py:89: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  user_indices = torch.tensor(user_indices).to(self.device)\n",
      "/tmp/ipykernel_22261/1947374894.py:90: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  pos_item_indices = torch.tensor(pos_item_indices).to(self.device)\n",
      "/tmp/ipykernel_22261/1947374894.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  neg_item_indices = torch.tensor(neg_item_indices).to(self.device).squeeze()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-31 21:55:20,478 - base - recpack - INFO - Processed epoch 0 in 20.87 s.Batch Training Loss = 0.5574\n",
      "2024-07-31 21:58:26,602 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.6931645683413428, which is better than previous iterations.\n",
      "2024-07-31 21:58:26,605 - base - recpack - INFO - Evaluation at end of 0 took 186.12 s.\n",
      "2024-07-31 21:58:46,937 - base - recpack - INFO - Processed epoch 1 in 20.33 s.Batch Training Loss = 0.5309\n",
      "2024-07-31 22:01:53,224 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.6931382097047518, which is worse than previous iterations.\n",
      "2024-07-31 22:01:53,227 - base - recpack - INFO - Evaluation at end of 1 took 186.29 s.\n",
      "2024-07-31 22:02:14,019 - base - recpack - INFO - Processed epoch 2 in 20.79 s.Batch Training Loss = 0.5284\n",
      "2024-07-31 22:05:20,329 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.6931323749614252, which is worse than previous iterations.\n",
      "2024-07-31 22:05:20,332 - base - recpack - INFO - Evaluation at end of 2 took 186.31 s.\n",
      "2024-07-31 22:05:41,436 - base - recpack - INFO - Processed epoch 3 in 21.10 s.Batch Training Loss = 0.5276\n",
      "2024-07-31 22:08:47,225 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.6931421542115478, which is worse than previous iterations.\n",
      "2024-07-31 22:08:47,228 - base - recpack - INFO - Evaluation at end of 3 took 185.79 s.\n",
      "2024-07-31 22:09:07,869 - base - recpack - INFO - Processed epoch 4 in 20.64 s.Batch Training Loss = 0.5262\n",
      "2024-07-31 22:12:13,663 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.6931658817953472, which is worse than previous iterations.\n",
      "2024-07-31 22:12:13,666 - base - recpack - INFO - Evaluation at end of 4 took 185.79 s.\n",
      "2024-07-31 22:12:14,404 - base - recpack - INFO - Fitting NGCFAlgorithm complete - Took 1.04e+03s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_22261/1947374894.py:89: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  user_indices = torch.tensor(user_indices).to(self.device)\n",
      "/tmp/ipykernel_22261/1947374894.py:90: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  pos_item_indices = torch.tensor(pos_item_indices).to(self.device)\n",
      "/tmp/ipykernel_22261/1947374894.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  neg_item_indices = torch.tensor(neg_item_indices).to(self.device).squeeze()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-31 22:15:48,088 - base - recpack - INFO - Processed epoch 0 in 20.60 s.Batch Training Loss = 0.5736\n",
      "2024-07-31 22:18:54,167 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.6931282562395807, which is better than previous iterations.\n",
      "2024-07-31 22:18:54,171 - base - recpack - INFO - Evaluation at end of 0 took 186.08 s.\n",
      "2024-07-31 22:19:15,168 - base - recpack - INFO - Processed epoch 1 in 21.00 s.Batch Training Loss = 0.5271\n",
      "2024-07-31 22:22:21,066 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.6931282122325959, which is worse than previous iterations.\n",
      "2024-07-31 22:22:21,070 - base - recpack - INFO - Evaluation at end of 1 took 185.90 s.\n",
      "2024-07-31 22:22:41,831 - base - recpack - INFO - Processed epoch 2 in 20.76 s.Batch Training Loss = 0.5240\n",
      "2024-07-31 22:25:47,075 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.6931483843051541, which is worse than previous iterations.\n",
      "2024-07-31 22:25:47,081 - base - recpack - INFO - Evaluation at end of 2 took 185.25 s.\n",
      "2024-07-31 22:26:07,859 - base - recpack - INFO - Processed epoch 3 in 20.78 s.Batch Training Loss = 0.5235\n",
      "2024-07-31 22:29:13,464 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.69316713833437, which is worse than previous iterations.\n",
      "2024-07-31 22:29:13,472 - base - recpack - INFO - Evaluation at end of 3 took 185.61 s.\n",
      "2024-07-31 22:29:34,204 - base - recpack - INFO - Processed epoch 4 in 20.73 s.Batch Training Loss = 0.5237\n",
      "2024-07-31 22:32:40,536 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.693162755379271, which is worse than previous iterations.\n",
      "2024-07-31 22:32:40,538 - base - recpack - INFO - Evaluation at end of 4 took 186.33 s.\n",
      "2024-07-31 22:32:41,303 - base - recpack - INFO - Fitting NGCFAlgorithm complete - Took 1.04e+03s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_22261/1947374894.py:89: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  user_indices = torch.tensor(user_indices).to(self.device)\n",
      "/tmp/ipykernel_22261/1947374894.py:90: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  pos_item_indices = torch.tensor(pos_item_indices).to(self.device)\n",
      "/tmp/ipykernel_22261/1947374894.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  neg_item_indices = torch.tensor(neg_item_indices).to(self.device).squeeze()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-31 22:36:14,717 - base - recpack - INFO - Processed epoch 0 in 21.05 s.Batch Training Loss = 0.5579\n",
      "2024-07-31 22:39:21,114 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.6931708111444905, which is better than previous iterations.\n",
      "2024-07-31 22:39:21,117 - base - recpack - INFO - Evaluation at end of 0 took 186.40 s.\n",
      "2024-07-31 22:39:41,727 - base - recpack - INFO - Processed epoch 1 in 20.61 s.Batch Training Loss = 0.5309\n",
      "2024-07-31 22:42:48,701 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.6931616392749403, which is worse than previous iterations.\n",
      "2024-07-31 22:42:48,704 - base - recpack - INFO - Evaluation at end of 1 took 186.97 s.\n",
      "2024-07-31 22:43:09,666 - base - recpack - INFO - Processed epoch 2 in 20.96 s.Batch Training Loss = 0.5284\n",
      "2024-07-31 22:46:15,694 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.6931613852865922, which is worse than previous iterations.\n",
      "2024-07-31 22:46:15,696 - base - recpack - INFO - Evaluation at end of 2 took 186.03 s.\n",
      "2024-07-31 22:46:36,245 - base - recpack - INFO - Processed epoch 3 in 20.55 s.Batch Training Loss = 0.5274\n",
      "2024-07-31 22:49:42,600 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.6931597736757671, which is worse than previous iterations.\n",
      "2024-07-31 22:49:42,603 - base - recpack - INFO - Evaluation at end of 3 took 186.35 s.\n",
      "2024-07-31 22:50:04,548 - base - recpack - INFO - Processed epoch 4 in 21.94 s.Batch Training Loss = 0.5258\n",
      "2024-07-31 22:53:10,498 - stopping_criterion - recpack - INFO - StoppingCriterion has value 0.6931623600195616, which is worse than previous iterations.\n",
      "2024-07-31 22:53:10,501 - base - recpack - INFO - Evaluation at end of 4 took 185.95 s.\n",
      "2024-07-31 22:53:11,281 - base - recpack - INFO - Fitting NGCFAlgorithm complete - Took 1.04e+03s\n"
     ]
    }
   ],
   "source": [
    "pipeline_builder = PipelineBuilder()\n",
    "ok = (scenario._validation_data_in, scenario._validation_data_out)\n",
    "pipeline_builder.set_data_from_scenario(scenario)\n",
    "\n",
    "\n",
    "# Add the baseline algorithms\n",
    "#pipeline_builder.add_algorithm('ItemKNN', grid={'K': [100, 200, 400, 800]})\n",
    "#pipeline_builder.add_algorithm('EASE', grid={'l2': [10, 100, 1000], 'alpha': [0, 0.1, 0.5]})\n",
    "\n",
    "# Add our LightGCN algorithm\n",
    "pipeline_builder.add_algorithm(\n",
    "    'NGCFAlgorithm',\n",
    "    grid={\n",
    "        'learning_rate': [0.1, 0.01, 0.001],\n",
    "        'dropout': [0.0, 0.1, 0.2]\n",
    "    },\n",
    "    params={\n",
    "        'max_epochs': 5,\n",
    "        'batch_size': 1024,\n",
    "        'n_layers': 3,\n",
    "        'stop_early': True,\n",
    "        'max_iter_no_change': 5,\n",
    "        'min_improvement': 0.01,\n",
    "        'save_best_to_file': True,\n",
    "        'keep_last': True\n",
    "    }\n",
    ")\n",
    "\n",
    "# Add NDCG, Recall, and HR metrics to be evaluated at 10, 20, and 50\n",
    "pipeline_builder.add_metric('NDCGK', [10, 20, 50])\n",
    "pipeline_builder.add_metric('RecallK', [10, 20, 50])\n",
    "pipeline_builder.add_metric('HitK', [10, 20, 50])\n",
    "\n",
    "# Set the optimisation metric\n",
    "pipeline_builder.set_optimisation_metric('RecallK', 20)\n",
    "\n",
    "# Construct pipeline\n",
    "pipeline = pipeline_builder.build()\n",
    "\n",
    "# Debugging: Output the shape of the training data\n",
    "#print(f\"Training data shape: {im.shape}\")\n",
    "\n",
    "# Run pipeline, will first do optimisation, and then evaluation\n",
    "pipeline.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ce9a51a-a42e-4058-a2ef-b667046c27d6",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e80f2784-1ed9-4d93-9883-4c34213d62ed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NDCGK_10</th>\n",
       "      <th>NDCGK_20</th>\n",
       "      <th>NDCGK_50</th>\n",
       "      <th>RecallK_10</th>\n",
       "      <th>RecallK_20</th>\n",
       "      <th>RecallK_50</th>\n",
       "      <th>HitK_10</th>\n",
       "      <th>HitK_20</th>\n",
       "      <th>HitK_50</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NGCFAlgorithm(batch_size=1024,dropout=0.1,embedding_dim=64,grad_clip=1.0,keep_last=True,learning_rate=0.01,max_epochs=5,max_iter_no_change=5,message_dropout=0.0,min_improvement=0.01,n_layers=3,node_dropout=0.0,predict_topK=None,save_best_to_file=True,seed=1009965771,stop_early=True,stopping_criterion=&lt;recpack.algorithms.stopping_criterion.StoppingCriterion object at 0x7fd44b231090&gt;,validation_sample_size=None)</th>\n",
       "      <td>0.01494</td>\n",
       "      <td>0.019542</td>\n",
       "      <td>0.032195</td>\n",
       "      <td>0.021574</td>\n",
       "      <td>0.036233</td>\n",
       "      <td>0.084923</td>\n",
       "      <td>0.067487</td>\n",
       "      <td>0.116263</td>\n",
       "      <td>0.276654</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    NDCGK_10  NDCGK_20  \\\n",
       "NGCFAlgorithm(batch_size=1024,dropout=0.1,embed...   0.01494  0.019542   \n",
       "\n",
       "                                                    NDCGK_50  RecallK_10  \\\n",
       "NGCFAlgorithm(batch_size=1024,dropout=0.1,embed...  0.032195    0.021574   \n",
       "\n",
       "                                                    RecallK_20  RecallK_50  \\\n",
       "NGCFAlgorithm(batch_size=1024,dropout=0.1,embed...    0.036233    0.084923   \n",
       "\n",
       "                                                     HitK_10   HitK_20  \\\n",
       "NGCFAlgorithm(batch_size=1024,dropout=0.1,embed...  0.067487  0.116263   \n",
       "\n",
       "                                                     HitK_50  \n",
       "NGCFAlgorithm(batch_size=1024,dropout=0.1,embed...  0.276654  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.get_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f5e2dde-f629-46ec-b8b9-660b536341c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
